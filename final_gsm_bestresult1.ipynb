{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DIPANJAN001/Forecasting-Solar-Energy/blob/master/final_gsm_bestresult1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzs_vH9vlX74",
        "outputId": "c048cf1d-7f50-4713-9e4b-46bbcc66b6af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Boruta in /usr/local/lib/python3.8/dist-packages (0.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.17.1->Boruta) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.17.1->Boruta) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install Boruta\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from boruta import BorutaPy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import concatenate\n",
        "from keras import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Bidirectional\n",
        "from keras import layers\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import load_model\n",
        "from keras.layers import Input\n",
        "from sklearn.decomposition import PCA "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "lDilv4v2lz-w"
      },
      "outputs": [],
      "source": [
        "def lstm_data_transform(x_data, y_data, num_steps):\n",
        "    \"\"\" Changes data to the format for LSTM training \n",
        "for sliding window approach \"\"\"\n",
        "    # Prepare the list for the transformed data\n",
        "    X, y = list(), list()\n",
        "    # Loop of the entire data set\n",
        "    for i in range(x_data.shape[0]):\n",
        "        # compute a new (sliding window) index\n",
        "        end_ix = i + num_steps\n",
        "        # if index is larger than the size of the dataset, we stop\n",
        "        if end_ix >= x_data.shape[0]:\n",
        "            break\n",
        "        # Get a sequence of data for x\n",
        "        seq_X = x_data[i:end_ix]\n",
        "        # Get only the last element of the sequency for y\n",
        "        seq_y = y_data[end_ix]\n",
        "        # Append the list with sequencies\n",
        "        X.append(seq_X)\n",
        "        y.append(seq_y)\n",
        "    # Make final arrays\n",
        "    x_array = np.array(X)\n",
        "    y_array = np.array(y)\n",
        "    return x_array, y_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "iQt_oZP7QczL"
      },
      "outputs": [],
      "source": [
        "df=pd.read_excel(\"/content/pv_08.xlsx\")\n",
        "weather_input1=df.drop('power_normed',axis=1)\n",
        "weather_input=weather_input1.drop('time_idx',axis=1)\n",
        "solpow=df['power_normed']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoPnMw4oQQlc",
        "outputId": "735d9e16-3ebb-40e6-8376-cdd20e6b9a37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: \t1 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t2 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t3 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t4 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t5 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t6 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t7 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t8 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t15\n",
            "Rejected: \t26\n",
            "Iteration: \t9 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t15\n",
            "Rejected: \t26\n",
            "Iteration: \t10 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t15\n",
            "Rejected: \t26\n",
            "Iteration: \t11 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t15\n",
            "Rejected: \t26\n",
            "Iteration: \t12 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t10\n",
            "Rejected: \t31\n",
            "Iteration: \t13 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t10\n",
            "Rejected: \t31\n",
            "Iteration: \t14 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t10\n",
            "Rejected: \t31\n",
            "Iteration: \t15 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t10\n",
            "Rejected: \t31\n",
            "Iteration: \t16 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t9\n",
            "Rejected: \t32\n",
            "Iteration: \t17 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t9\n",
            "Rejected: \t32\n",
            "Iteration: \t18 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t9\n",
            "Rejected: \t32\n",
            "Iteration: \t19 / 100\n",
            "Confirmed: \t9\n",
            "Tentative: \t7\n",
            "Rejected: \t33\n",
            "Iteration: \t20 / 100\n",
            "Confirmed: \t9\n",
            "Tentative: \t7\n",
            "Rejected: \t33\n",
            "Iteration: \t21 / 100\n",
            "Confirmed: \t9\n",
            "Tentative: \t7\n",
            "Rejected: \t33\n",
            "Iteration: \t22 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t33\n",
            "Iteration: \t23 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t33\n",
            "Iteration: \t24 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t33\n",
            "Iteration: \t25 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t33\n",
            "Iteration: \t26 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t33\n",
            "Iteration: \t27 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t33\n",
            "Iteration: \t28 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t33\n",
            "Iteration: \t29 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t33\n",
            "Iteration: \t30 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t33\n",
            "Iteration: \t31 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t33\n",
            "Iteration: \t32 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t33\n",
            "Iteration: \t33 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t33\n",
            "Iteration: \t34 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t35 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t36 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t37 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t38 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t39 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t40 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t41 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t42 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t43 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t44 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t45 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t46 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t47 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t48 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t49 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t50 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t51 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t52 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t53 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t54 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t55 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t56 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t57 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t58 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t59 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t60 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t61 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t62 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t63 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t64 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t65 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t66 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t67 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t68 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t69 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t70 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t71 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t72 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t73 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t74 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t75 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t76 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t77 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t78 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t79 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t80 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t81 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t82 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t83 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t84 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t85 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t86 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t87 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t88 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t89 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t90 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t91 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t92 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t93 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t94 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t95 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t96 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t97 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t98 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t99 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "\n",
            "\n",
            "BorutaPy finished running.\n",
            "\n",
            "Iteration: \t100 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BorutaPy(estimator=RandomForestRegressor(max_depth=7, n_estimators=80,\n",
              "                                         random_state=RandomState(MT19937) at 0x7F0367646740),\n",
              "         n_estimators='auto',\n",
              "         random_state=RandomState(MT19937) at 0x7F0367646740, verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "rfc = RandomForestRegressor(random_state=1, n_estimators=1000, max_depth=7)\n",
        "boruta_selector = BorutaPy(rfc, n_estimators='auto', verbose=2, random_state=1)\n",
        "boruta_selector.fit(np.array(weather_input), np.array(solpow)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "u2NoSDCGUFNU"
      },
      "outputs": [],
      "source": [
        "X_important_train = boruta_selector.transform(np.array(weather_input))\n",
        "num_steps = 3\n",
        "# training set\n",
        "(x_transformed_train,\n",
        " y_transformed_train) = lstm_data_transform(X_important_train,solpow , num_steps=num_steps)\n",
        "assert x_transformed_train.shape[0] == y_transformed_train.shape[0]\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_transformed_train,y_transformed_train,test_size=0.33, random_state=42,shuffle=False)\n",
        "#X_train_,X_val,y_train_,y_val=train_test_split(X_train,y_train,test_size=0.2, random_state=42,shuffle=False)\n",
        "inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdKjqiCK5m_T",
        "outputId": "0053dcb7-99b9-4621-dd56-173fdcd9ebab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 3, 12) dtype=float32 (created by layer 'input_2')>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "inputs1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "V27z-GjNapD4"
      },
      "outputs": [],
      "source": [
        "from keras import optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "uxD0diT8a4c2"
      },
      "outputs": [],
      "source": [
        "opt=optimizers.Adam(learning_rate=0.003)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "YM0Epc0yvWnJ"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "t0f48T0zsiAs"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "class HalvAdam(Adam):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.prev_gradients = None\n",
        "\n",
        "    @tf.function\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [math_ops.cast(x, \"float32\") for x in grads]\n",
        "\n",
        "        if self.prev_gradients is not None:\n",
        "            for i in range(len(grads)):\n",
        "                if (grads[i] * self.prev_gradients[i] < 0):\n",
        "                    self.updates[i] = self.updates[i] / 2\n",
        "\n",
        "        self.prev_gradients = grads\n",
        "        return self.updates"
      ],
      "metadata": {
        "id": "MpStRslgCRBO"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "cSM9vzEq3G3U"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "nq9ZwBIrI_qj"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "18n5dRvpuI5T"
      },
      "outputs": [],
      "source": [
        "def define_model():\n",
        "\n",
        "\n",
        "  fe2_0 = Bidirectional(LSTM(256, activation='relu',return_sequences = True))(inputs1)\n",
        "  fe2_1 = Dropout(0.6)(fe2_0)\n",
        "  fe2_2 = Bidirectional(LSTM(64, activation='relu',return_sequences = True))(fe2_1)\n",
        "  fe2_3= Dropout(0.5)(fe2_2)\n",
        "  fe2_4=Bidirectional(LSTM(4, activation='relu'))(fe2_3)\n",
        "  out2_1=Dense(1, activation='relu')(fe2_4)\n",
        "\n",
        "  fe3_0 =Bidirectional(LSTM(128, activation='relu',return_sequences = True))(inputs1)\n",
        "  fe3_1 = Dropout(0.6)(fe3_0)\n",
        "  fe3_2 = Bidirectional(LSTM(96, activation='relu',return_sequences = True))(fe3_1)\n",
        "  fe3_3= Dropout(0.5)(fe3_2)\n",
        "  fe3_4=Bidirectional(LSTM(8, activation='relu'))(fe3_3)#16\n",
        "  out3_1=Dense(1, activation='relu')(fe3_4)\n",
        " \n",
        " \n",
        "\n",
        "  output = layers.average([out2_1, out3_1])\n",
        "  #merged3 = concatenate([out2_1,out3_1], name='concat3')\n",
        "  #output = Dense(1, activation='relu')( merged3)\n",
        "  \n",
        "\n",
        "  model = Model(inputs=[inputs1], outputs=[output])\n",
        "  \n",
        " \n",
        "  return model\n",
        "mdl=define_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss=[]"
      ],
      "metadata": {
        "id": "P5UqekV1_q7F"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import clone_model"
      ],
      "metadata": {
        "id": "9zy5UX8p_zSl"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "dAICp2p5OCER"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "9iwWrmDs0z7O"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GlobalMinimaSearch(weights):\n",
        "  if len(loss)>9:\n",
        "   return\n",
        "  \n",
        "  initial_weights =weights\n",
        "  model=clone_model(mdl)\n",
        "  model.set_weights(weights)\n",
        "  model.compile(optimizer=HalvAdam(learning_rate=0.002), loss='mean_squared_error')\n",
        "  model.fit(X_train, y_train, epochs=75, batch_size=64)\n",
        "  y= model.predict(X_test)\n",
        "  loss.append(np.sqrt(mean_squared_error(y,y_test)))\n",
        "  best_weights= model.get_weights()\n",
        "\n",
        "\n",
        "  params_2 =[final_weight - (final_weight - initial_weight) for initial_weight, final_weight in zip(initial_weights, best_weights)]\n",
        "  GlobalMinimaSearch(params_2)\n",
        "  \n",
        " "
      ],
      "metadata": {
        "id": "FxpviTJb_nUR"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GlobalMinimaSearch(mdl.get_weights())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuddmGCf_1dR",
        "outputId": "683f5fc6-04a5-4a68-ddc8-3d12a45e1f73"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "66/66 [==============================] - 24s 90ms/step - loss: 0.0271\n",
            "Epoch 2/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0112\n",
            "Epoch 3/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0107\n",
            "Epoch 4/75\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 0.0103\n",
            "Epoch 5/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0097\n",
            "Epoch 6/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0090\n",
            "Epoch 7/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0093\n",
            "Epoch 8/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0092\n",
            "Epoch 9/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0084\n",
            "Epoch 10/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0084\n",
            "Epoch 11/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0083\n",
            "Epoch 12/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0082\n",
            "Epoch 13/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0078\n",
            "Epoch 14/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0081\n",
            "Epoch 15/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0081\n",
            "Epoch 16/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0078\n",
            "Epoch 17/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0077\n",
            "Epoch 18/75\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 0.0079\n",
            "Epoch 19/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0076\n",
            "Epoch 20/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0075\n",
            "Epoch 21/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0078\n",
            "Epoch 22/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0076\n",
            "Epoch 23/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0074\n",
            "Epoch 24/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0076\n",
            "Epoch 25/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0077\n",
            "Epoch 26/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0077\n",
            "Epoch 27/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0074\n",
            "Epoch 28/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0076\n",
            "Epoch 29/75\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 0.0077\n",
            "Epoch 30/75\n",
            "66/66 [==============================] - 8s 120ms/step - loss: 0.0071\n",
            "Epoch 31/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0074\n",
            "Epoch 32/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0076\n",
            "Epoch 33/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0073\n",
            "Epoch 34/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0072\n",
            "Epoch 35/75\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 0.0074\n",
            "Epoch 36/75\n",
            "66/66 [==============================] - 7s 98ms/step - loss: 0.0074\n",
            "Epoch 37/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0071\n",
            "Epoch 38/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0070\n",
            "Epoch 39/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0073\n",
            "Epoch 40/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0075\n",
            "Epoch 41/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0071\n",
            "Epoch 42/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0071\n",
            "Epoch 43/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0073\n",
            "Epoch 44/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0073\n",
            "Epoch 45/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0073\n",
            "Epoch 46/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0068\n",
            "Epoch 47/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0070\n",
            "Epoch 48/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0071\n",
            "Epoch 49/75\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 0.0071\n",
            "Epoch 50/75\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 0.0072\n",
            "Epoch 51/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0069\n",
            "Epoch 52/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0071\n",
            "Epoch 53/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0071\n",
            "Epoch 54/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0067\n",
            "Epoch 55/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0071\n",
            "Epoch 56/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0070\n",
            "Epoch 57/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0070\n",
            "Epoch 58/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0068\n",
            "Epoch 59/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0069\n",
            "Epoch 60/75\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 0.0068\n",
            "Epoch 61/75\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 0.0068\n",
            "Epoch 62/75\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 0.0069\n",
            "Epoch 63/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0067\n",
            "Epoch 64/75\n",
            "66/66 [==============================] - 8s 117ms/step - loss: 0.0066\n",
            "Epoch 65/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0066\n",
            "Epoch 66/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0068\n",
            "Epoch 67/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0066\n",
            "Epoch 68/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0069\n",
            "Epoch 69/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0069\n",
            "Epoch 70/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0067\n",
            "Epoch 71/75\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 0.0067\n",
            "Epoch 72/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0066\n",
            "Epoch 73/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0066\n",
            "Epoch 74/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0068\n",
            "Epoch 75/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0066\n",
            "65/65 [==============================] - 3s 18ms/step\n",
            "Epoch 1/75\n",
            "66/66 [==============================] - 23s 93ms/step - loss: 0.0264\n",
            "Epoch 2/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0116\n",
            "Epoch 3/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0109\n",
            "Epoch 4/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0099\n",
            "Epoch 5/75\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 0.0094\n",
            "Epoch 6/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0099\n",
            "Epoch 7/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0084\n",
            "Epoch 8/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0096\n",
            "Epoch 9/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0085\n",
            "Epoch 10/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0081\n",
            "Epoch 11/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0085\n",
            "Epoch 12/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0084\n",
            "Epoch 13/75\n",
            "66/66 [==============================] - 7s 107ms/step - loss: 0.0079\n",
            "Epoch 14/75\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 0.0079\n",
            "Epoch 15/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0080\n",
            "Epoch 16/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0080\n",
            "Epoch 17/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0077\n",
            "Epoch 18/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0077\n",
            "Epoch 19/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0078\n",
            "Epoch 20/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0075\n",
            "Epoch 21/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0080\n",
            "Epoch 22/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0076\n",
            "Epoch 23/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0079\n",
            "Epoch 24/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0075\n",
            "Epoch 25/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0077\n",
            "Epoch 26/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0073\n",
            "Epoch 27/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0076\n",
            "Epoch 28/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0073\n",
            "Epoch 29/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0075\n",
            "Epoch 30/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0075\n",
            "Epoch 31/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0075\n",
            "Epoch 32/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0073\n",
            "Epoch 33/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0080\n",
            "Epoch 34/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0072\n",
            "Epoch 35/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0075\n",
            "Epoch 36/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0074\n",
            "Epoch 37/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0074\n",
            "Epoch 38/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0070\n",
            "Epoch 39/75\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 0.0070\n",
            "Epoch 40/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0069\n",
            "Epoch 41/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0071\n",
            "Epoch 42/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0070\n",
            "Epoch 43/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0073\n",
            "Epoch 44/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0071\n",
            "Epoch 45/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0073\n",
            "Epoch 46/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0071\n",
            "Epoch 47/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0070\n",
            "Epoch 48/75\n",
            "66/66 [==============================] - 8s 115ms/step - loss: 0.0072\n",
            "Epoch 49/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0071\n",
            "Epoch 50/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0067\n",
            "Epoch 51/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0069\n",
            "Epoch 52/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0070\n",
            "Epoch 53/75\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 0.0069\n",
            "Epoch 54/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0072\n",
            "Epoch 55/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0068\n",
            "Epoch 56/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0066\n",
            "Epoch 57/75\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 0.0074\n",
            "Epoch 58/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0068\n",
            "Epoch 59/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0066\n",
            "Epoch 60/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0068\n",
            "Epoch 61/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0067\n",
            "Epoch 62/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0067\n",
            "Epoch 63/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0068\n",
            "Epoch 64/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0066\n",
            "Epoch 65/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0068\n",
            "Epoch 66/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0069\n",
            "Epoch 67/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0068\n",
            "Epoch 68/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0066\n",
            "Epoch 69/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0066\n",
            "Epoch 70/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0069\n",
            "Epoch 71/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0065\n",
            "Epoch 72/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0068\n",
            "Epoch 73/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0066\n",
            "Epoch 74/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0066\n",
            "Epoch 75/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0067\n",
            "65/65 [==============================] - 3s 19ms/step\n",
            "Epoch 1/75\n",
            "66/66 [==============================] - 26s 92ms/step - loss: 0.0262\n",
            "Epoch 2/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0117\n",
            "Epoch 3/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0108\n",
            "Epoch 4/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0099\n",
            "Epoch 5/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0102\n",
            "Epoch 6/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0088\n",
            "Epoch 7/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0097\n",
            "Epoch 8/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0086\n",
            "Epoch 9/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0085\n",
            "Epoch 10/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0084\n",
            "Epoch 11/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0080\n",
            "Epoch 12/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0083\n",
            "Epoch 13/75\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 0.0085\n",
            "Epoch 14/75\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 0.0079\n",
            "Epoch 15/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0080\n",
            "Epoch 16/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0078\n",
            "Epoch 17/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0080\n",
            "Epoch 18/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0079\n",
            "Epoch 19/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0077\n",
            "Epoch 20/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0081\n",
            "Epoch 21/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0077\n",
            "Epoch 22/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0077\n",
            "Epoch 23/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0077\n",
            "Epoch 24/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0075\n",
            "Epoch 25/75\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 0.0073\n",
            "Epoch 26/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0075\n",
            "Epoch 27/75\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 0.0076\n",
            "Epoch 28/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0072\n",
            "Epoch 29/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0076\n",
            "Epoch 30/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0073\n",
            "Epoch 31/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0074\n",
            "Epoch 32/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0075\n",
            "Epoch 33/75\n",
            "66/66 [==============================] - 7s 113ms/step - loss: 0.0076\n",
            "Epoch 34/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0072\n",
            "Epoch 35/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0074\n",
            "Epoch 36/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0072\n",
            "Epoch 37/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0071\n",
            "Epoch 38/75\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 0.0072\n",
            "Epoch 39/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0072\n",
            "Epoch 40/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0074\n",
            "Epoch 41/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0072\n",
            "Epoch 42/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0072\n",
            "Epoch 43/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0078\n",
            "Epoch 44/75\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 0.0072\n",
            "Epoch 45/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0069\n",
            "Epoch 46/75\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 0.0071\n",
            "Epoch 47/75\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 0.0071\n",
            "Epoch 48/75\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 0.0071\n",
            "Epoch 49/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0068\n",
            "Epoch 50/75\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 0.0069\n",
            "Epoch 51/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0070\n",
            "Epoch 52/75\n",
            "66/66 [==============================] - 7s 105ms/step - loss: 0.0069\n",
            "Epoch 53/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0068\n",
            "Epoch 54/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0071\n",
            "Epoch 55/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0069\n",
            "Epoch 56/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0070\n",
            "Epoch 57/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0067\n",
            "Epoch 58/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0069\n",
            "Epoch 59/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0067\n",
            "Epoch 60/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0069\n",
            "Epoch 61/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0067\n",
            "Epoch 62/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0068\n",
            "Epoch 63/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0069\n",
            "Epoch 64/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0070\n",
            "Epoch 65/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0069\n",
            "Epoch 66/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0070\n",
            "Epoch 67/75\n",
            "66/66 [==============================] - 7s 113ms/step - loss: 0.0066\n",
            "Epoch 68/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0067\n",
            "Epoch 69/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0066\n",
            "Epoch 70/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0067\n",
            "Epoch 71/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0067\n",
            "Epoch 72/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0067\n",
            "Epoch 73/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0067\n",
            "Epoch 74/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0102\n",
            "Epoch 75/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0072\n",
            "65/65 [==============================] - 3s 19ms/step\n",
            "Epoch 1/75\n",
            "66/66 [==============================] - 22s 91ms/step - loss: 0.0261\n",
            "Epoch 2/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0117\n",
            "Epoch 3/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0107\n",
            "Epoch 4/75\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 0.0097\n",
            "Epoch 5/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0093\n",
            "Epoch 6/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0090\n",
            "Epoch 7/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0090\n",
            "Epoch 8/75\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 0.0089\n",
            "Epoch 9/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0084\n",
            "Epoch 10/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0088\n",
            "Epoch 11/75\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 0.0081\n",
            "Epoch 12/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0087\n",
            "Epoch 13/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0082\n",
            "Epoch 14/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0078\n",
            "Epoch 15/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0079\n",
            "Epoch 16/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0083\n",
            "Epoch 17/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0079\n",
            "Epoch 18/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0077\n",
            "Epoch 19/75\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 0.0081\n",
            "Epoch 20/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0077\n",
            "Epoch 21/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0075\n",
            "Epoch 22/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0076\n",
            "Epoch 23/75\n",
            "66/66 [==============================] - 7s 112ms/step - loss: 0.0078\n",
            "Epoch 24/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0075\n",
            "Epoch 25/75\n",
            "66/66 [==============================] - 7s 98ms/step - loss: 0.0075\n",
            "Epoch 26/75\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 0.0076\n",
            "Epoch 27/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0072\n",
            "Epoch 28/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0071\n",
            "Epoch 29/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0073\n",
            "Epoch 30/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0071\n",
            "Epoch 31/75\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 0.0075\n",
            "Epoch 32/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0072\n",
            "Epoch 33/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0072\n",
            "Epoch 34/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0074\n",
            "Epoch 35/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0071\n",
            "Epoch 36/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0073\n",
            "Epoch 37/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0072\n",
            "Epoch 38/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0073\n",
            "Epoch 39/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0075\n",
            "Epoch 40/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0073\n",
            "Epoch 41/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0072\n",
            "Epoch 42/75\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 0.0071\n",
            "Epoch 43/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0071\n",
            "Epoch 44/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0074\n",
            "Epoch 45/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0071\n",
            "Epoch 46/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0069\n",
            "Epoch 47/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0070\n",
            "Epoch 48/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0068\n",
            "Epoch 49/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0073\n",
            "Epoch 50/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0069\n",
            "Epoch 51/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0069\n",
            "Epoch 52/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0071\n",
            "Epoch 53/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0070\n",
            "Epoch 54/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0069\n",
            "Epoch 55/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0070\n",
            "Epoch 56/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0067\n",
            "Epoch 57/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0069\n",
            "Epoch 58/75\n",
            "66/66 [==============================] - 8s 114ms/step - loss: 0.0069\n",
            "Epoch 59/75\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 0.0068\n",
            "Epoch 60/75\n",
            "66/66 [==============================] - 7s 98ms/step - loss: 0.0067\n",
            "Epoch 61/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0068\n",
            "Epoch 62/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0067\n",
            "Epoch 63/75\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 0.0070\n",
            "Epoch 64/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0067\n",
            "Epoch 65/75\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 0.0068\n",
            "Epoch 66/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0066\n",
            "Epoch 67/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0066\n",
            "Epoch 68/75\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 0.0070\n",
            "Epoch 69/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0067\n",
            "Epoch 70/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0068\n",
            "Epoch 71/75\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 0.0068\n",
            "Epoch 72/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0067\n",
            "Epoch 73/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0068\n",
            "Epoch 74/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0069\n",
            "Epoch 75/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0065\n",
            "65/65 [==============================] - 3s 21ms/step\n",
            "Epoch 1/75\n",
            "66/66 [==============================] - 23s 95ms/step - loss: 0.0271\n",
            "Epoch 2/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0115\n",
            "Epoch 3/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0108\n",
            "Epoch 4/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0106\n",
            "Epoch 5/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0096\n",
            "Epoch 6/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0093\n",
            "Epoch 7/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0089\n",
            "Epoch 8/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0085\n",
            "Epoch 9/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0086\n",
            "Epoch 10/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0088\n",
            "Epoch 11/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0082\n",
            "Epoch 12/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0086\n",
            "Epoch 13/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0089\n",
            "Epoch 14/75\n",
            "66/66 [==============================] - 8s 114ms/step - loss: 0.0081\n",
            "Epoch 15/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0080\n",
            "Epoch 16/75\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 0.0080\n",
            "Epoch 17/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0077\n",
            "Epoch 18/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0075\n",
            "Epoch 19/75\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 0.0076\n",
            "Epoch 20/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0076\n",
            "Epoch 21/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0076\n",
            "Epoch 22/75\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 0.0077\n",
            "Epoch 23/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0074\n",
            "Epoch 24/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0075\n",
            "Epoch 25/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0075\n",
            "Epoch 26/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0072\n",
            "Epoch 27/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0073\n",
            "Epoch 28/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0077\n",
            "Epoch 29/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0076\n",
            "Epoch 30/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0076\n",
            "Epoch 31/75\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 0.0073\n",
            "Epoch 32/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0071\n",
            "Epoch 33/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0071\n",
            "Epoch 34/75\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 0.0072\n",
            "Epoch 35/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0072\n",
            "Epoch 36/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0071\n",
            "Epoch 37/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0070\n",
            "Epoch 38/75\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 0.0073\n",
            "Epoch 39/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0071\n",
            "Epoch 40/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0072\n",
            "Epoch 41/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0072\n",
            "Epoch 42/75\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 0.0075\n",
            "Epoch 43/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0069\n",
            "Epoch 44/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0071\n",
            "Epoch 45/75\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 0.0070\n",
            "Epoch 46/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0072\n",
            "Epoch 47/75\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 0.0071\n",
            "Epoch 48/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0069\n",
            "Epoch 49/75\n",
            "66/66 [==============================] - 8s 121ms/step - loss: 0.0070\n",
            "Epoch 50/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0068\n",
            "Epoch 51/75\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 0.0070\n",
            "Epoch 52/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0069\n",
            "Epoch 53/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0068\n",
            "Epoch 54/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0069\n",
            "Epoch 55/75\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 0.0071\n",
            "Epoch 56/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0067\n",
            "Epoch 57/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0067\n",
            "Epoch 58/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0069\n",
            "Epoch 59/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0065\n",
            "Epoch 60/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0067\n",
            "Epoch 61/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0066\n",
            "Epoch 62/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0069\n",
            "Epoch 63/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0066\n",
            "Epoch 64/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0070\n",
            "Epoch 65/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0069\n",
            "Epoch 66/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0066\n",
            "Epoch 67/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0069\n",
            "Epoch 68/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0066\n",
            "Epoch 69/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0069\n",
            "Epoch 70/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0068\n",
            "Epoch 71/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0066\n",
            "Epoch 72/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0066\n",
            "Epoch 73/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0071\n",
            "Epoch 74/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0066\n",
            "Epoch 75/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0069\n",
            "65/65 [==============================] - 3s 19ms/step\n",
            "Epoch 1/75\n",
            "66/66 [==============================] - 22s 92ms/step - loss: 0.0265\n",
            "Epoch 2/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0114\n",
            "Epoch 3/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0101\n",
            "Epoch 4/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0101\n",
            "Epoch 5/75\n",
            "66/66 [==============================] - 7s 107ms/step - loss: 0.0096\n",
            "Epoch 6/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0098\n",
            "Epoch 7/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0095\n",
            "Epoch 8/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0085\n",
            "Epoch 9/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0087\n",
            "Epoch 10/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0086\n",
            "Epoch 11/75\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 0.0084\n",
            "Epoch 12/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0082\n",
            "Epoch 13/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0081\n",
            "Epoch 14/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0080\n",
            "Epoch 15/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0083\n",
            "Epoch 16/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0079\n",
            "Epoch 17/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0077\n",
            "Epoch 18/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0078\n",
            "Epoch 19/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0077\n",
            "Epoch 20/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0074\n",
            "Epoch 21/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0081\n",
            "Epoch 22/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0076\n",
            "Epoch 23/75\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 0.0078\n",
            "Epoch 24/75\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 0.0073\n",
            "Epoch 25/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0074\n",
            "Epoch 26/75\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 0.0074\n",
            "Epoch 27/75\n",
            "66/66 [==============================] - 7s 98ms/step - loss: 0.0075\n",
            "Epoch 28/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0078\n",
            "Epoch 29/75\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 0.0075\n",
            "Epoch 30/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0073\n",
            "Epoch 31/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0076\n",
            "Epoch 32/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0079\n",
            "Epoch 33/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0074\n",
            "Epoch 34/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0077\n",
            "Epoch 35/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0073\n",
            "Epoch 36/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0072\n",
            "Epoch 37/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0073\n",
            "Epoch 38/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0074\n",
            "Epoch 39/75\n",
            "66/66 [==============================] - 8s 115ms/step - loss: 0.0072\n",
            "Epoch 40/75\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 0.0071\n",
            "Epoch 41/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0071\n",
            "Epoch 42/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0073\n",
            "Epoch 43/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0069\n",
            "Epoch 44/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0071\n",
            "Epoch 45/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0070\n",
            "Epoch 46/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0070\n",
            "Epoch 47/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0072\n",
            "Epoch 48/75\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 0.0069\n",
            "Epoch 49/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0069\n",
            "Epoch 50/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0074\n",
            "Epoch 51/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0069\n",
            "Epoch 52/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0068\n",
            "Epoch 53/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0071\n",
            "Epoch 54/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0067\n",
            "Epoch 55/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0069\n",
            "Epoch 56/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0068\n",
            "Epoch 57/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0072\n",
            "Epoch 58/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0067\n",
            "Epoch 59/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0069\n",
            "Epoch 60/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0069\n",
            "Epoch 61/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0067\n",
            "Epoch 62/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0068\n",
            "Epoch 63/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0065\n",
            "Epoch 64/75\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 0.0070\n",
            "Epoch 65/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0068\n",
            "Epoch 66/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0067\n",
            "Epoch 67/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0070\n",
            "Epoch 68/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0067\n",
            "Epoch 69/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0066\n",
            "Epoch 70/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0068\n",
            "Epoch 71/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0067\n",
            "Epoch 72/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0068\n",
            "Epoch 73/75\n",
            "66/66 [==============================] - 8s 119ms/step - loss: 0.0066\n",
            "Epoch 74/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0067\n",
            "Epoch 75/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0066\n",
            "65/65 [==============================] - 4s 20ms/step\n",
            "Epoch 1/75\n",
            "66/66 [==============================] - 22s 93ms/step - loss: 0.0270\n",
            "Epoch 2/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0122\n",
            "Epoch 3/75\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 0.0109\n",
            "Epoch 4/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0105\n",
            "Epoch 5/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0094\n",
            "Epoch 6/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0088\n",
            "Epoch 7/75\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 0.0088\n",
            "Epoch 8/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0091\n",
            "Epoch 9/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0085\n",
            "Epoch 10/75\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 0.0084\n",
            "Epoch 11/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0082\n",
            "Epoch 12/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0079\n",
            "Epoch 13/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0082\n",
            "Epoch 14/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0080\n",
            "Epoch 15/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0078\n",
            "Epoch 16/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0082\n",
            "Epoch 17/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0078\n",
            "Epoch 18/75\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 0.0077\n",
            "Epoch 19/75\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 0.0076\n",
            "Epoch 20/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0077\n",
            "Epoch 21/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0079\n",
            "Epoch 22/75\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 0.0078\n",
            "Epoch 23/75\n",
            "66/66 [==============================] - 7s 104ms/step - loss: 0.0079\n",
            "Epoch 24/75\n",
            "66/66 [==============================] - 7s 109ms/step - loss: 0.0075\n",
            "Epoch 25/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0077\n",
            "Epoch 26/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0074\n",
            "Epoch 27/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0076\n",
            "Epoch 28/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0074\n",
            "Epoch 29/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0074\n",
            "Epoch 30/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0075\n",
            "Epoch 31/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0072\n",
            "Epoch 32/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0073\n",
            "Epoch 33/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0074\n",
            "Epoch 34/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0071\n",
            "Epoch 35/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0074\n",
            "Epoch 36/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0073\n",
            "Epoch 37/75\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 0.0073\n",
            "Epoch 38/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0073\n",
            "Epoch 39/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0072\n",
            "Epoch 40/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0075\n",
            "Epoch 41/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0073\n",
            "Epoch 42/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0072\n",
            "Epoch 43/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0071\n",
            "Epoch 44/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0070\n",
            "Epoch 45/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0071\n",
            "Epoch 46/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0070\n",
            "Epoch 47/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0070\n",
            "Epoch 48/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0070\n",
            "Epoch 49/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0070\n",
            "Epoch 50/75\n",
            "66/66 [==============================] - 7s 98ms/step - loss: 0.0068\n",
            "Epoch 51/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0072\n",
            "Epoch 52/75\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 0.0068\n",
            "Epoch 53/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0070\n",
            "Epoch 54/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0072\n",
            "Epoch 55/75\n",
            "66/66 [==============================] - 7s 98ms/step - loss: 0.0067\n",
            "Epoch 56/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0066\n",
            "Epoch 57/75\n",
            "66/66 [==============================] - 8s 123ms/step - loss: 0.0068\n",
            "Epoch 58/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0068\n",
            "Epoch 59/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0069\n",
            "Epoch 60/75\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 0.0068\n",
            "Epoch 61/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0067\n",
            "Epoch 62/75\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 0.0070\n",
            "Epoch 63/75\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 0.0068\n",
            "Epoch 64/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0068\n",
            "Epoch 65/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0069\n",
            "Epoch 66/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0069\n",
            "Epoch 67/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0066\n",
            "Epoch 68/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0067\n",
            "Epoch 69/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0068\n",
            "Epoch 70/75\n",
            "66/66 [==============================] - 7s 104ms/step - loss: 0.0067\n",
            "Epoch 71/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0068\n",
            "Epoch 72/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0076\n",
            "Epoch 73/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0069\n",
            "Epoch 74/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0065\n",
            "Epoch 75/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0067\n",
            "65/65 [==============================] - 3s 19ms/step\n",
            "Epoch 1/75\n",
            "66/66 [==============================] - 23s 98ms/step - loss: 0.0249\n",
            "Epoch 2/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0118\n",
            "Epoch 3/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0113\n",
            "Epoch 4/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0098\n",
            "Epoch 5/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0096\n",
            "Epoch 6/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0096\n",
            "Epoch 7/75\n",
            "66/66 [==============================] - 8s 121ms/step - loss: 0.0087\n",
            "Epoch 8/75\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 0.0085\n",
            "Epoch 9/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0085\n",
            "Epoch 10/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0084\n",
            "Epoch 11/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0083\n",
            "Epoch 12/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0081\n",
            "Epoch 13/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0082\n",
            "Epoch 14/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0079\n",
            "Epoch 15/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0078\n",
            "Epoch 16/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0080\n",
            "Epoch 17/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0078\n",
            "Epoch 18/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0077\n",
            "Epoch 19/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0077\n",
            "Epoch 20/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0077\n",
            "Epoch 21/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0073\n",
            "Epoch 22/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0076\n",
            "Epoch 23/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0076\n",
            "Epoch 24/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0079\n",
            "Epoch 25/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0078\n",
            "Epoch 26/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0076\n",
            "Epoch 27/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0078\n",
            "Epoch 28/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0074\n",
            "Epoch 29/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0074\n",
            "Epoch 30/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0078\n",
            "Epoch 31/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0074\n",
            "Epoch 32/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0070\n",
            "Epoch 33/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0074\n",
            "Epoch 34/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0072\n",
            "Epoch 35/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0073\n",
            "Epoch 36/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0075\n",
            "Epoch 37/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0071\n",
            "Epoch 38/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0072\n",
            "Epoch 39/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0075\n",
            "Epoch 40/75\n",
            "66/66 [==============================] - 8s 115ms/step - loss: 0.0071\n",
            "Epoch 41/75\n",
            "66/66 [==============================] - 7s 98ms/step - loss: 0.0072\n",
            "Epoch 42/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0071\n",
            "Epoch 43/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0070\n",
            "Epoch 44/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0071\n",
            "Epoch 45/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0067\n",
            "Epoch 46/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0072\n",
            "Epoch 47/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0070\n",
            "Epoch 48/75\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 0.0070\n",
            "Epoch 49/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0072\n",
            "Epoch 50/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0070\n",
            "Epoch 51/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0073\n",
            "Epoch 52/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0067\n",
            "Epoch 53/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0068\n",
            "Epoch 54/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0069\n",
            "Epoch 55/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0071\n",
            "Epoch 56/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0070\n",
            "Epoch 57/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0068\n",
            "Epoch 58/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0069\n",
            "Epoch 59/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0067\n",
            "Epoch 60/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0070\n",
            "Epoch 61/75\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 0.0068\n",
            "Epoch 62/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0067\n",
            "Epoch 63/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0068\n",
            "Epoch 64/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0069\n",
            "Epoch 65/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0069\n",
            "Epoch 66/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0068\n",
            "Epoch 67/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0068\n",
            "Epoch 68/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0067\n",
            "Epoch 69/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0069\n",
            "Epoch 70/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0069\n",
            "Epoch 71/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0066\n",
            "Epoch 72/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0066\n",
            "Epoch 73/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0067\n",
            "Epoch 74/75\n",
            "66/66 [==============================] - 8s 117ms/step - loss: 0.0066\n",
            "Epoch 75/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0066\n",
            "65/65 [==============================] - 3s 20ms/step\n",
            "Epoch 1/75\n",
            "66/66 [==============================] - 26s 102ms/step - loss: 0.0272\n",
            "Epoch 2/75\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 0.0115\n",
            "Epoch 3/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0106\n",
            "Epoch 4/75\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 0.0099\n",
            "Epoch 5/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0098\n",
            "Epoch 6/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0088\n",
            "Epoch 7/75\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 0.0097\n",
            "Epoch 8/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0086\n",
            "Epoch 9/75\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 0.0085\n",
            "Epoch 10/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0080\n",
            "Epoch 11/75\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 0.0084\n",
            "Epoch 12/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0085\n",
            "Epoch 13/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0082\n",
            "Epoch 14/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0082\n",
            "Epoch 15/75\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 0.0081\n",
            "Epoch 16/75\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 0.0079\n",
            "Epoch 17/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0076\n",
            "Epoch 18/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0074\n",
            "Epoch 19/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0080\n",
            "Epoch 20/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0082\n",
            "Epoch 21/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0083\n",
            "Epoch 22/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0077\n",
            "Epoch 23/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0074\n",
            "Epoch 24/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0076\n",
            "Epoch 25/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0078\n",
            "Epoch 26/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0074\n",
            "Epoch 27/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0072\n",
            "Epoch 28/75\n",
            "66/66 [==============================] - 8s 116ms/step - loss: 0.0074\n",
            "Epoch 29/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0076\n",
            "Epoch 30/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0074\n",
            "Epoch 31/75\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 0.0073\n",
            "Epoch 32/75\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 0.0075\n",
            "Epoch 33/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0076\n",
            "Epoch 34/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0073\n",
            "Epoch 35/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0070\n",
            "Epoch 36/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0075\n",
            "Epoch 37/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0076\n",
            "Epoch 38/75\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 0.0072\n",
            "Epoch 39/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0071\n",
            "Epoch 40/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0072\n",
            "Epoch 41/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0071\n",
            "Epoch 42/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0070\n",
            "Epoch 43/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0069\n",
            "Epoch 44/75\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 0.0071\n",
            "Epoch 45/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0071\n",
            "Epoch 46/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0069\n",
            "Epoch 47/75\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 0.0068\n",
            "Epoch 48/75\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 0.0072\n",
            "Epoch 49/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0072\n",
            "Epoch 50/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0069\n",
            "Epoch 51/75\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 0.0068\n",
            "Epoch 52/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0073\n",
            "Epoch 53/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0070\n",
            "Epoch 54/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0068\n",
            "Epoch 55/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0070\n",
            "Epoch 56/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0071\n",
            "Epoch 57/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0068\n",
            "Epoch 58/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0068\n",
            "Epoch 59/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0067\n",
            "Epoch 60/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0069\n",
            "Epoch 61/75\n",
            "66/66 [==============================] - 8s 126ms/step - loss: 0.0073\n",
            "Epoch 62/75\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 0.0069\n",
            "Epoch 63/75\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 0.0070\n",
            "Epoch 64/75\n",
            "66/66 [==============================] - 7s 104ms/step - loss: 0.0069\n",
            "Epoch 65/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0068\n",
            "Epoch 66/75\n",
            "66/66 [==============================] - 7s 104ms/step - loss: 0.0067\n",
            "Epoch 67/75\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 0.0068\n",
            "Epoch 68/75\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 0.0064\n",
            "Epoch 69/75\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 0.0066\n",
            "Epoch 70/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0067\n",
            "Epoch 71/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0068\n",
            "Epoch 72/75\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 0.0069\n",
            "Epoch 73/75\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 0.0066\n",
            "Epoch 74/75\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 0.0066\n",
            "Epoch 75/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0067\n",
            "65/65 [==============================] - 4s 22ms/step\n",
            "Epoch 1/75\n",
            "66/66 [==============================] - 24s 100ms/step - loss: 0.0272\n",
            "Epoch 2/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0119\n",
            "Epoch 3/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0110\n",
            "Epoch 4/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0099\n",
            "Epoch 5/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0090\n",
            "Epoch 6/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0092\n",
            "Epoch 7/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0088\n",
            "Epoch 8/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0082\n",
            "Epoch 9/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0085\n",
            "Epoch 10/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0085\n",
            "Epoch 11/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0083\n",
            "Epoch 12/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0089\n",
            "Epoch 13/75\n",
            "66/66 [==============================] - 8s 114ms/step - loss: 0.0081\n",
            "Epoch 14/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0085\n",
            "Epoch 15/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0078\n",
            "Epoch 16/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0080\n",
            "Epoch 17/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0082\n",
            "Epoch 18/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0081\n",
            "Epoch 19/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0079\n",
            "Epoch 20/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0076\n",
            "Epoch 21/75\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 0.0078\n",
            "Epoch 22/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0076\n",
            "Epoch 23/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0074\n",
            "Epoch 24/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0077\n",
            "Epoch 25/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0076\n",
            "Epoch 26/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0085\n",
            "Epoch 27/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0076\n",
            "Epoch 28/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0071\n",
            "Epoch 29/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0076\n",
            "Epoch 30/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0073\n",
            "Epoch 31/75\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 0.0072\n",
            "Epoch 32/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0071\n",
            "Epoch 33/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0072\n",
            "Epoch 34/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0073\n",
            "Epoch 35/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0071\n",
            "Epoch 36/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0073\n",
            "Epoch 37/75\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 0.0072\n",
            "Epoch 38/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0074\n",
            "Epoch 39/75\n",
            "66/66 [==============================] - 7s 104ms/step - loss: 0.0076\n",
            "Epoch 40/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0072\n",
            "Epoch 41/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0070\n",
            "Epoch 42/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0070\n",
            "Epoch 43/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0070\n",
            "Epoch 44/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0071\n",
            "Epoch 45/75\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 0.0072\n",
            "Epoch 46/75\n",
            "66/66 [==============================] - 8s 122ms/step - loss: 0.0076\n",
            "Epoch 47/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0072\n",
            "Epoch 48/75\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 0.0070\n",
            "Epoch 49/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0072\n",
            "Epoch 50/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0069\n",
            "Epoch 51/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0070\n",
            "Epoch 52/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0069\n",
            "Epoch 53/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0068\n",
            "Epoch 54/75\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 0.0069\n",
            "Epoch 55/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0068\n",
            "Epoch 56/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0068\n",
            "Epoch 57/75\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 0.0068\n",
            "Epoch 58/75\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 0.0067\n",
            "Epoch 59/75\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 0.0069\n",
            "Epoch 60/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0070\n",
            "Epoch 61/75\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 0.0071\n",
            "Epoch 62/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0067\n",
            "Epoch 63/75\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 0.0068\n",
            "Epoch 64/75\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 0.0070\n",
            "Epoch 65/75\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 0.0066\n",
            "Epoch 66/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0068\n",
            "Epoch 67/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0068\n",
            "Epoch 68/75\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 0.0068\n",
            "Epoch 69/75\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 0.0071\n",
            "Epoch 70/75\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 0.0068\n",
            "Epoch 71/75\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 0.0067\n",
            "Epoch 72/75\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 0.0066\n",
            "Epoch 73/75\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 0.0065\n",
            "Epoch 74/75\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 0.0071\n",
            "Epoch 75/75\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 0.0069\n",
            "65/65 [==============================] - 4s 24ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss)"
      ],
      "metadata": {
        "id": "MnuUdKWaqgaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a35d22e4-0658-4240-c516-41309356373a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.10576285679832545, 0.10567594720994858, 0.09949342603583622, 0.1011629400606091, 0.10890970749717584, 0.10129485019506967, 0.1062493900121043, 0.10767389157430125, 0.10412835782971527, 0.10675838984694194]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(min(loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56ykd7kawkvX",
        "outputId": "6a9ccb04-8ffd-41fc-fc42-aa94bd2d5c4b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.09949342603583622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "5KwbVjdXKn01"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss)"
      ],
      "metadata": {
        "id": "O622nEj3Krt7",
        "outputId": "72e9c5aa-5d44-40d9-9418-a85c55a3d2e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f034b8a5910>]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}