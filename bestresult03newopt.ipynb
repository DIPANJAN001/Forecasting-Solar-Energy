{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DIPANJAN001/Forecasting-Solar-Energy/blob/master/bestresult03newopt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzs_vH9vlX74",
        "outputId": "3057e8ec-4a43-490a-d923-2189293108f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Boruta in /usr/local/lib/python3.8/dist-packages (0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.0.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.17.1->Boruta) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.17.1->Boruta) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install Boruta\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from boruta import BorutaPy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import concatenate\n",
        "from keras import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Bidirectional\n",
        "from keras import layers\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import load_model\n",
        "from keras.layers import Input\n",
        "from sklearn.decomposition import PCA "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDilv4v2lz-w"
      },
      "outputs": [],
      "source": [
        "def lstm_data_transform(x_data, y_data, num_steps):\n",
        "    \"\"\" Changes data to the format for LSTM training \n",
        "for sliding window approach \"\"\"\n",
        "    # Prepare the list for the transformed data\n",
        "    X, y = list(), list()\n",
        "    # Loop of the entire data set\n",
        "    for i in range(x_data.shape[0]):\n",
        "        # compute a new (sliding window) index\n",
        "        end_ix = i + num_steps\n",
        "        # if index is larger than the size of the dataset, we stop\n",
        "        if end_ix >= x_data.shape[0]:\n",
        "            break\n",
        "        # Get a sequence of data for x\n",
        "        seq_X = x_data[i:end_ix]\n",
        "        # Get only the last element of the sequency for y\n",
        "        seq_y = y_data[end_ix]\n",
        "        # Append the list with sequencies\n",
        "        X.append(seq_X)\n",
        "        y.append(seq_y)\n",
        "    # Make final arrays\n",
        "    x_array = np.array(X)\n",
        "    y_array = np.array(y)\n",
        "    return x_array, y_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQt_oZP7QczL"
      },
      "outputs": [],
      "source": [
        "df=pd.read_excel(\"/content/pv_03.xlsx\")\n",
        "weather_input1=df.drop('power_normed',axis=1)\n",
        "weather_input=weather_input1.drop('time_idx',axis=1)\n",
        "solpow=df['power_normed']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoPnMw4oQQlc",
        "outputId": "81decbb0-8b14-47dc-ba81-81f4f9b77d84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: \t1 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t2 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t3 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t4 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t5 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t6 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t7 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t8 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t8\n",
            "Rejected: \t30\n",
            "Iteration: \t9 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t8\n",
            "Rejected: \t30\n",
            "Iteration: \t10 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t8\n",
            "Rejected: \t30\n",
            "Iteration: \t11 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t8\n",
            "Rejected: \t30\n",
            "Iteration: \t12 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t8\n",
            "Rejected: \t30\n",
            "Iteration: \t13 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t7\n",
            "Rejected: \t31\n",
            "Iteration: \t14 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t7\n",
            "Rejected: \t31\n",
            "Iteration: \t15 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t7\n",
            "Rejected: \t31\n",
            "Iteration: \t16 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t17 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t18 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t19 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t20 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t21 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t22 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t23 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t24 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t25 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t26 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t27 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t28 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t29 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t30 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t31 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t32 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t33 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t34 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t35 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t36 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t37 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t38 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t39 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t40 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t41 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t42 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t43 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t44 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t45 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t46 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t47 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t48 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t49 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t50 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t51 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t52 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t53 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t54 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t55 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t56 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t57 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t58 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t59 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t60 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t61 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t62 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t63 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t64 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t65 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t66 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t67 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t68 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t69 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t70 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t71 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t72 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t73 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t74 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t75 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t76 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t77 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t78 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t79 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t80 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t81 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t82 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t83 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t84 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t85 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t86 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t87 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t88 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t89 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t90 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t91 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t92 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n",
            "Iteration: \t93 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t2\n",
            "Rejected: \t33\n",
            "Iteration: \t94 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t2\n",
            "Rejected: \t33\n",
            "Iteration: \t95 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t2\n",
            "Rejected: \t33\n",
            "Iteration: \t96 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t2\n",
            "Rejected: \t33\n",
            "Iteration: \t97 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t2\n",
            "Rejected: \t33\n",
            "Iteration: \t98 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t2\n",
            "Rejected: \t33\n",
            "Iteration: \t99 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t2\n",
            "Rejected: \t33\n",
            "\n",
            "\n",
            "BorutaPy finished running.\n",
            "\n",
            "Iteration: \t100 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t1\n",
            "Rejected: \t33\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BorutaPy(estimator=RandomForestRegressor(max_depth=7, n_estimators=80,\n",
              "                                         random_state=RandomState(MT19937) at 0x7F95BF980840),\n",
              "         n_estimators='auto',\n",
              "         random_state=RandomState(MT19937) at 0x7F95BF980840, verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "rfc = RandomForestRegressor(random_state=1, n_estimators=1000, max_depth=7)\n",
        "boruta_selector = BorutaPy(rfc, n_estimators='auto', verbose=2, random_state=1)\n",
        "boruta_selector.fit(np.array(weather_input), np.array(solpow)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2NoSDCGUFNU"
      },
      "outputs": [],
      "source": [
        "X_important_train = boruta_selector.transform(np.array(weather_input))\n",
        "num_steps = 3\n",
        "# training set\n",
        "(x_transformed_train,\n",
        " y_transformed_train) = lstm_data_transform(X_important_train,solpow , num_steps=num_steps)\n",
        "assert x_transformed_train.shape[0] == y_transformed_train.shape[0]\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_transformed_train,y_transformed_train,test_size=0.25, random_state=42,shuffle=False)\n",
        "#X_train_,X_val,y_train_,y_val=train_test_split(X_train,y_train,test_size=0.2, random_state=42,shuffle=False)\n",
        "inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdKjqiCK5m_T",
        "outputId": "04085ed9-b8a9-4938-bae4-a9febb75b615"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 3, 14) dtype=float32 (created by layer 'input_4')>"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "inputs1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V27z-GjNapD4"
      },
      "outputs": [],
      "source": [
        "from keras import optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxD0diT8a4c2"
      },
      "outputs": [],
      "source": [
        "opt=optimizers.Adam(learning_rate=0.003)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YM0Epc0yvWnJ"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "\n",
        "class CustomAdam(optimizers.Adam):\n",
        "    def __init__(self, new_idea_param=0.1, *args, **kwargs):\n",
        "        self.new_idea_param = new_idea_param\n",
        "        super(CustomAdam, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [K.update_add(self.iterations, 1)]\n",
        "\n",
        "        lr = self.lr\n",
        "        if self.initial_decay > 0:\n",
        "            lr *= (1. / (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n",
        "\n",
        "        t = K.cast(self.iterations, K.floatx()) + 1\n",
        "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        new_idea_t = self.new_idea_param * (K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        self.weights = [self.iterations] + ms + vs\n",
        "\n",
        "        for p, g, m, v in zip(params, grads, ms, vs):\n",
        "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
        "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
        "            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon) - new_idea_t * g\n",
        "\n",
        "            self.updates.append(K.update(m, m_t))\n",
        "            self.updates.append(K.update(v, v_t))\n",
        "            self.updates.append(K.update(p, p_t))\n",
        "        return self.updates"
      ],
      "metadata": {
        "id": "g8F6yCGl21Sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "\n",
        "class GradientAdam(optimizers.Adam):\n",
        "    def __init__(self, gradient_param=0.1, *args, **kwargs):\n",
        "        self.gradient_param = gradient_param\n",
        "        super(GradientAdam, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [K.update_add(self.iterations, 1)]\n",
        "\n",
        "        lr = self.lr\n",
        "        if self.initial_decay > 0:\n",
        "            lr *= (1. / (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n",
        "\n",
        "        t = K.cast(self.iterations, K.floatx()) + 1\n",
        "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        gradient_t = self.gradient_param * grads\n",
        "\n",
        "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        self.weights = [self.iterations] + ms + vs\n",
        "\n",
        "        for p, g, m, v, g_t in zip(params, grads, ms, vs, gradient_t):\n",
        "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
        "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
        "            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon) + g_t\n",
        "\n",
        "            self.updates.append(K.update(m, m_t))\n",
        "            self.updates.append(K.update(v, v_t))\n",
        "            self.updates.append(K.update(p, p_t))\n",
        "        return self.updates\n"
      ],
      "metadata": {
        "id": "J_gyZaJU8f4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "t0f48T0zsiAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "class HalvAdam(Adam):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.prev_gradients = None\n",
        "\n",
        "    @tf.function\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [math_ops.cast(x, \"float32\") for x in grads]\n",
        "\n",
        "        if self.prev_gradients is not None:\n",
        "            for i in range(len(grads)):\n",
        "                if (grads[i] * self.prev_gradients[i] < 0):\n",
        "                    self.updates[i] = self.updates[i] / 2\n",
        "\n",
        "        self.prev_gradients = grads\n",
        "        return self.updates"
      ],
      "metadata": {
        "id": "MpStRslgCRBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "class AvgAdam(Adam):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.prev_gradients = None\n",
        "        self.prev_weights = None\n",
        "\n",
        "    @tf.function\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [math_ops.cast(x, \"float32\") for x in grads]\n",
        "\n",
        "        if self.prev_gradients is not None and self.prev_weights is not None:\n",
        "            for i in range(len(grads)):\n",
        "                if (grads[i] * self.prev_gradients[i] < 0):\n",
        "                    self.updates[i] = (self.updates[i] + self.prev_weights[i]) / 2\n",
        "\n",
        "        self.prev_gradients = grads\n",
        "        self.prev_weights = self.get_weights()\n",
        "        return self.updates\n"
      ],
      "metadata": {
        "id": "8VEOOUJDE2MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "class AdaptiveAdam(Adam):\n",
        "    def __init__(self, *args, factor=0.5, patience=5, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.wait = 0\n",
        "        self.best_loss = float('inf')\n",
        "        self.best_weights = None\n",
        "\n",
        "    @tf.function\n",
        "    def get_updates(self, loss, params):\n",
        "        current_loss = loss()\n",
        "        if current_loss < self.best_loss:\n",
        "            self.best_loss = current_loss\n",
        "            self.best_weights = params\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.wait = 0\n",
        "                self.lr = self.lr * self.factor\n",
        "                params = self.best_weights\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [math_ops.cast(g, \"float32\") for g in grads]\n",
        "        return self.updates\n"
      ],
      "metadata": {
        "id": "PmHcGR7JJLo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "class MomentumAdam(Adam):\n",
        "    def __init__(self, *args, momentum=0.9, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.momentum = momentum\n",
        "        self.velocities = [tf.Variable(tf.zeros_like(p), trainable=False) for p in self.weights]\n",
        "\n",
        "    @tf.function\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = []\n",
        "        for p, g, v in zip(params, grads, self.velocities):\n",
        "            v_t = self.momentum * v - self.lr * g\n",
        "            p_t = p + v_t\n",
        "            self.updates.append(p_t)\n",
        "            self.updates.append(v_t)\n",
        "        return self.updates\n"
      ],
      "metadata": {
        "id": "Zqo9SvzjbTtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "cSM9vzEq3G3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "nq9ZwBIrI_qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18n5dRvpuI5T"
      },
      "outputs": [],
      "source": [
        "def define_model():\n",
        "\n",
        "\n",
        "  fe2_0 = Bidirectional(LSTM(256, activation='LeakyReLU',return_sequences = True))(inputs1)\n",
        "  fe2_1 = Dropout(0.6)(fe2_0)\n",
        "  fe2_2 = Bidirectional(LSTM(64, activation='LeakyReLU',return_sequences = True))(fe2_1)\n",
        "  fe2_3= Dropout(0.5)(fe2_2)\n",
        "  fe2_4=Bidirectional(LSTM(4, activation='LeakyReLU'))(fe2_3)\n",
        "  out2_1=Dense(1, activation='relu')(fe2_4)\n",
        "\n",
        "  fe3_0 =Bidirectional(LSTM(128, activation='LeakyReLU',return_sequences = True))(inputs1)\n",
        "  fe3_1 = Dropout(0.6)(fe3_0)\n",
        "  fe3_2 = Bidirectional(LSTM(96, activation='LeakyReLU',return_sequences = True))(fe3_1)\n",
        "  fe3_3= Dropout(0.5)(fe3_2)\n",
        "  fe3_4=Bidirectional(LSTM(8, activation='LeakyReLU'))(fe3_3)#16\n",
        "  out3_1=Dense(1, activation='relu')(fe3_4)\n",
        " \n",
        " \n",
        "\n",
        "  output = layers.average([out2_1, out3_1])\n",
        "  #merged3 = concatenate([out2_1,out3_1], name='concat3')\n",
        "  #output = Dense(1, activation='relu')( merged3)\n",
        "  \n",
        "\n",
        "  model = Model(inputs=[inputs1], outputs=[output])\n",
        "  \n",
        " \n",
        "  return model\n",
        "mdl=define_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss=[]"
      ],
      "metadata": {
        "id": "P5UqekV1_q7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import clone_model"
      ],
      "metadata": {
        "id": "9zy5UX8p_zSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "dAICp2p5OCER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "9iwWrmDs0z7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GlobalMinimaSearch(weights):\n",
        "  if len(loss)>9:\n",
        "   return\n",
        "  \n",
        "  initial_weights =weights\n",
        "  model=clone_model(mdl)\n",
        "  model.set_weights(weights)\n",
        "  model.compile(optimizer=AvgAdam(learning_rate=0.003), loss='mean_squared_error')\n",
        "  model.fit(X_train, y_train, epochs=75, batch_size=128)\n",
        "  y= model.predict(X_test)\n",
        "  loss.append(np.sqrt(mean_squared_error(y,y_test)))\n",
        "  best_weights= model.get_weights()\n",
        "  \n",
        "\n",
        "     \n",
        "\n",
        "  params_1 =[final_weight + (final_weight - initial_weight) for initial_weight, final_weight in zip(initial_weights, best_weights)]\n",
        "  #GlobalMinimaSearch(params_1)\n",
        "\n",
        "\n",
        "  params_2 =[final_weight - (final_weight - initial_weight) for initial_weight, final_weight in zip(initial_weights, best_weights)]\n",
        "  GlobalMinimaSearch(params_2)\n",
        "  \n",
        " "
      ],
      "metadata": {
        "id": "FxpviTJb_nUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GlobalMinimaSearch(mdl.get_weights())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuddmGCf_1dR",
        "outputId": "844794ad-1ca5-4c8a-e263-044daff23abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "37/37 [==============================] - 16s 126ms/step - loss: 0.0136\n",
            "Epoch 2/75\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0053\n",
            "Epoch 3/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0043\n",
            "Epoch 4/75\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0037\n",
            "Epoch 5/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0039\n",
            "Epoch 6/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0033\n",
            "Epoch 7/75\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0032\n",
            "Epoch 8/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0033\n",
            "Epoch 9/75\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.0032\n",
            "Epoch 10/75\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0031\n",
            "Epoch 11/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0030\n",
            "Epoch 12/75\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0030\n",
            "Epoch 13/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0029\n",
            "Epoch 14/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0030\n",
            "Epoch 15/75\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0032\n",
            "Epoch 16/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0026\n",
            "Epoch 17/75\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0029\n",
            "Epoch 18/75\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0028\n",
            "Epoch 19/75\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0028\n",
            "Epoch 20/75\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 0.0028\n",
            "Epoch 21/75\n",
            "37/37 [==============================] - 4s 113ms/step - loss: 0.0027\n",
            "Epoch 22/75\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0026\n",
            "Epoch 23/75\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0025\n",
            "Epoch 24/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0028\n",
            "Epoch 25/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0026\n",
            "Epoch 26/75\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0026\n",
            "Epoch 27/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0028\n",
            "Epoch 28/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0027\n",
            "Epoch 29/75\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0026\n",
            "Epoch 30/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0025\n",
            "Epoch 31/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0025\n",
            "Epoch 32/75\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0024\n",
            "Epoch 33/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0025\n",
            "Epoch 34/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0025\n",
            "Epoch 35/75\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0026\n",
            "Epoch 36/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0026\n",
            "Epoch 37/75\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0024\n",
            "Epoch 38/75\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0024\n",
            "Epoch 39/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0025\n",
            "Epoch 40/75\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0025\n",
            "Epoch 41/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0025\n",
            "Epoch 42/75\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0023\n",
            "Epoch 43/75\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0024\n",
            "Epoch 44/75\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0024\n",
            "Epoch 45/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0024\n",
            "Epoch 46/75\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0024\n",
            "Epoch 47/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0025\n",
            "Epoch 48/75\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0024\n",
            "Epoch 49/75\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0025\n",
            "Epoch 50/75\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0023\n",
            "Epoch 51/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0025\n",
            "Epoch 52/75\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0024\n",
            "Epoch 53/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0025\n",
            "Epoch 54/75\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0024\n",
            "Epoch 55/75\n",
            "37/37 [==============================] - 4s 113ms/step - loss: 0.0023\n",
            "Epoch 56/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0023\n",
            "Epoch 57/75\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0025\n",
            "Epoch 58/75\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0024\n",
            "Epoch 59/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0028\n",
            "Epoch 60/75\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0023\n",
            "Epoch 61/75\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0023\n",
            "Epoch 62/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0024\n",
            "Epoch 63/75\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0023\n",
            "Epoch 64/75\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0023\n",
            "Epoch 65/75\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0023\n",
            "Epoch 66/75\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0022\n",
            "Epoch 67/75\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0023\n",
            "Epoch 68/75\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0023\n",
            "Epoch 69/75\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0022\n",
            "Epoch 70/75\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0025\n",
            "Epoch 71/75\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0024\n",
            "Epoch 72/75\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0022\n",
            "Epoch 73/75\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0022\n",
            "Epoch 74/75\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0023\n",
            "Epoch 75/75\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0023\n",
            "50/50 [==============================] - 2s 14ms/step\n",
            "Epoch 1/75\n",
            "37/37 [==============================] - 21s 123ms/step - loss: 0.0125\n",
            "Epoch 2/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0053\n",
            "Epoch 3/75\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0045\n",
            "Epoch 4/75\n",
            "37/37 [==============================] - 4s 113ms/step - loss: 0.0039\n",
            "Epoch 5/75\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0036\n",
            "Epoch 6/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0036\n",
            "Epoch 7/75\n",
            "37/37 [==============================] - 4s 112ms/step - loss: 0.0032\n",
            "Epoch 8/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0032\n",
            "Epoch 9/75\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0036\n",
            "Epoch 10/75\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0034\n",
            "Epoch 11/75\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0031\n",
            "Epoch 12/75\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0030\n",
            "Epoch 13/75\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0029\n",
            "Epoch 14/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0029\n",
            "Epoch 15/75\n",
            "37/37 [==============================] - 4s 122ms/step - loss: 0.0028\n",
            "Epoch 16/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0027\n",
            "Epoch 17/75\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0028\n",
            "Epoch 18/75\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0028\n",
            "Epoch 19/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0028\n",
            "Epoch 20/75\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.0030\n",
            "Epoch 21/75\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0029\n",
            "Epoch 22/75\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0027\n",
            "Epoch 23/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0028\n",
            "Epoch 24/75\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0026\n",
            "Epoch 25/75\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0026\n",
            "Epoch 26/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0026\n",
            "Epoch 27/75\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0027\n",
            "Epoch 28/75\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0024\n",
            "Epoch 29/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0025\n",
            "Epoch 30/75\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0026\n",
            "Epoch 31/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0027\n",
            "Epoch 32/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0028\n",
            "Epoch 33/75\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0026\n",
            "Epoch 34/75\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0026\n",
            "Epoch 35/75\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.0026\n",
            "Epoch 36/75\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0024\n",
            "Epoch 37/75\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0024\n",
            "Epoch 38/75\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0024\n",
            "Epoch 39/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0024\n",
            "Epoch 40/75\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0024\n",
            "Epoch 41/75\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0024\n",
            "Epoch 42/75\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.0024\n",
            "Epoch 43/75\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0025\n",
            "Epoch 44/75\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0025\n",
            "Epoch 45/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0026\n",
            "Epoch 46/75\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.0025\n",
            "Epoch 47/75\n",
            "37/37 [==============================] - 4s 122ms/step - loss: 0.0024\n",
            "Epoch 48/75\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.0024\n",
            "Epoch 49/75\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0025\n",
            "Epoch 50/75\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0023\n",
            "Epoch 51/75\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.0023\n",
            "Epoch 52/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0024\n",
            "Epoch 53/75\n",
            "37/37 [==============================] - 4s 122ms/step - loss: 0.0026\n",
            "Epoch 54/75\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0024\n",
            "Epoch 55/75\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0023\n",
            "Epoch 56/75\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0025\n",
            "Epoch 57/75\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.0023\n",
            "Epoch 58/75\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.0026\n",
            "Epoch 59/75\n",
            "37/37 [==============================] - 4s 111ms/step - loss: 0.0024\n",
            "Epoch 60/75\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.0023\n",
            "Epoch 61/75\n",
            "37/37 [==============================] - 4s 113ms/step - loss: 0.0025\n",
            "Epoch 62/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0024\n",
            "Epoch 63/75\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0022\n",
            "Epoch 64/75\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0023\n",
            "Epoch 65/75\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0026\n",
            "Epoch 66/75\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0023\n",
            "Epoch 67/75\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0022\n",
            "Epoch 68/75\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0022\n",
            "Epoch 69/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0022\n",
            "Epoch 70/75\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0023\n",
            "Epoch 71/75\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0023\n",
            "Epoch 72/75\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.0023\n",
            "Epoch 73/75\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0022\n",
            "Epoch 74/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0024\n",
            "Epoch 75/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0025\n",
            "50/50 [==============================] - 2s 14ms/step\n",
            "Epoch 1/75\n",
            "37/37 [==============================] - 15s 112ms/step - loss: 0.0144\n",
            "Epoch 2/75\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0059\n",
            "Epoch 3/75\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0043\n",
            "Epoch 4/75\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.0042\n",
            "Epoch 5/75\n",
            "37/37 [==============================] - 4s 110ms/step - loss: 0.0039\n",
            "Epoch 6/75\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0034\n",
            "Epoch 7/75\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0032\n",
            "Epoch 8/75\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0030\n",
            "Epoch 9/75\n",
            "37/37 [==============================] - 3s 94ms/step - loss: 0.0032\n",
            "Epoch 10/75\n",
            "37/37 [==============================] - 3s 94ms/step - loss: 0.0031\n",
            "Epoch 11/75\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0030\n",
            "Epoch 12/75\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0029\n",
            "Epoch 13/75\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0030\n",
            "Epoch 14/75\n",
            "37/37 [==============================] - 4s 117ms/step - loss: 0.0031\n",
            "Epoch 15/75\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.0028\n",
            "Epoch 16/75\n",
            "37/37 [==============================] - 3s 93ms/step - loss: 0.0029\n",
            "Epoch 17/75\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0027\n",
            "Epoch 18/75\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.0027\n",
            "Epoch 19/75\n",
            "37/37 [==============================] - 3s 94ms/step - loss: 0.0034\n",
            "Epoch 20/75\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0029\n",
            "Epoch 21/75\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.0026\n",
            "Epoch 22/75\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.0027\n",
            "Epoch 23/75\n",
            "37/37 [==============================] - 4s 113ms/step - loss: 0.0028\n",
            "Epoch 24/75\n",
            "37/37 [==============================] - 3s 94ms/step - loss: 0.0027\n",
            "Epoch 25/75\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.0026\n",
            "Epoch 26/75\n",
            "37/37 [==============================] - 4s 111ms/step - loss: 0.0025\n",
            "Epoch 27/75\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.0026\n",
            "Epoch 28/75\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0026\n",
            "Epoch 29/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0025\n",
            "Epoch 30/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0026\n",
            "Epoch 31/75\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.0026\n",
            "Epoch 32/75\n",
            "37/37 [==============================] - 3s 94ms/step - loss: 0.0026\n",
            "Epoch 33/75\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0025\n",
            "Epoch 34/75\n",
            "37/37 [==============================] - 3s 92ms/step - loss: 0.0026\n",
            "Epoch 35/75\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.0025\n",
            "Epoch 36/75\n",
            "37/37 [==============================] - 4s 113ms/step - loss: 0.0026\n",
            "Epoch 37/75\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0025\n",
            "Epoch 38/75\n",
            "37/37 [==============================] - 3s 94ms/step - loss: 0.0024\n",
            "Epoch 39/75\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0024\n",
            "Epoch 40/75\n",
            "37/37 [==============================] - 3s 94ms/step - loss: 0.0025\n",
            "Epoch 41/75\n",
            "37/37 [==============================] - 3s 94ms/step - loss: 0.0026\n",
            "Epoch 42/75\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0025\n",
            "Epoch 43/75\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0025\n",
            "Epoch 44/75\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0025\n",
            "Epoch 45/75\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0025\n",
            "Epoch 46/75\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0025\n",
            "Epoch 47/75\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0024\n",
            "Epoch 48/75\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0025\n",
            "Epoch 49/75\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.0026\n",
            "Epoch 50/75\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.0024\n",
            "Epoch 51/75\n",
            "37/37 [==============================] - 4s 117ms/step - loss: 0.0026\n",
            "Epoch 52/75\n",
            "37/37 [==============================] - 3s 94ms/step - loss: 0.0023\n",
            "Epoch 53/75\n",
            "37/37 [==============================] - 3s 94ms/step - loss: 0.0025\n",
            "Epoch 54/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0023\n",
            "Epoch 55/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0023\n",
            "Epoch 56/75\n",
            "37/37 [==============================] - 3s 94ms/step - loss: 0.0025\n",
            "Epoch 57/75\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0024\n",
            "Epoch 58/75\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0024\n",
            "Epoch 59/75\n",
            "37/37 [==============================] - 3s 94ms/step - loss: 0.0023\n",
            "Epoch 60/75\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.0023\n",
            "Epoch 61/75\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0023\n",
            "Epoch 62/75\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0023\n",
            "Epoch 63/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0023\n",
            "Epoch 64/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0023\n",
            "Epoch 65/75\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.0024\n",
            "Epoch 66/75\n",
            "37/37 [==============================] - 3s 92ms/step - loss: 0.0024\n",
            "Epoch 67/75\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0022\n",
            "Epoch 68/75\n",
            "37/37 [==============================] - 3s 94ms/step - loss: 0.0023\n",
            "Epoch 69/75\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0022\n",
            "Epoch 70/75\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0024\n",
            "Epoch 71/75\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0024\n",
            "Epoch 72/75\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.0023\n",
            "Epoch 73/75\n",
            "37/37 [==============================] - 4s 117ms/step - loss: 0.0023\n",
            "Epoch 74/75\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0023\n",
            "Epoch 75/75\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0026\n",
            "50/50 [==============================] - 2s 22ms/step\n",
            "Epoch 1/75\n",
            "37/37 [==============================] - 15s 90ms/step - loss: 0.0122\n",
            "Epoch 2/75\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 0.0052\n",
            "Epoch 3/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0044\n",
            "Epoch 4/75\n",
            "37/37 [==============================] - 4s 92ms/step - loss: 0.0038\n",
            "Epoch 5/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0036\n",
            "Epoch 6/75\n",
            "37/37 [==============================] - 3s 92ms/step - loss: 0.0033\n",
            "Epoch 7/75\n",
            "37/37 [==============================] - 4s 113ms/step - loss: 0.0033\n",
            "Epoch 8/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0030\n",
            "Epoch 9/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0031\n",
            "Epoch 10/75\n",
            "37/37 [==============================] - 4s 111ms/step - loss: 0.0033\n",
            "Epoch 11/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0034\n",
            "Epoch 12/75\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 0.0032\n",
            "Epoch 13/75\n",
            "37/37 [==============================] - 4s 112ms/step - loss: 0.0030\n",
            "Epoch 14/75\n",
            "37/37 [==============================] - 3s 92ms/step - loss: 0.0030\n",
            "Epoch 15/75\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 0.0030\n",
            "Epoch 16/75\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.0030\n",
            "Epoch 17/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0028\n",
            "Epoch 18/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0028\n",
            "Epoch 19/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0027\n",
            "Epoch 20/75\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.0027\n",
            "Epoch 21/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0028\n",
            "Epoch 22/75\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 0.0026\n",
            "Epoch 23/75\n",
            "37/37 [==============================] - 4s 112ms/step - loss: 0.0025\n",
            "Epoch 24/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0029\n",
            "Epoch 25/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0028\n",
            "Epoch 26/75\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.0026\n",
            "Epoch 27/75\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0025\n",
            "Epoch 28/75\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 0.0026\n",
            "Epoch 29/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0025\n",
            "Epoch 30/75\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.0026\n",
            "Epoch 31/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0026\n",
            "Epoch 32/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0025\n",
            "Epoch 33/75\n",
            "37/37 [==============================] - 4s 112ms/step - loss: 0.0026\n",
            "Epoch 34/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0024\n",
            "Epoch 35/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0025\n",
            "Epoch 36/75\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0024\n",
            "Epoch 37/75\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0025\n",
            "Epoch 38/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0026\n",
            "Epoch 39/75\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 0.0025\n",
            "Epoch 40/75\n",
            "37/37 [==============================] - 4s 112ms/step - loss: 0.0025\n",
            "Epoch 41/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0025\n",
            "Epoch 42/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0025\n",
            "Epoch 43/75\n",
            "37/37 [==============================] - 4s 113ms/step - loss: 0.0026\n",
            "Epoch 44/75\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 0.0024\n",
            "Epoch 45/75\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 0.0024\n",
            "Epoch 46/75\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0024\n",
            "Epoch 47/75\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 0.0024\n",
            "Epoch 48/75\n",
            "37/37 [==============================] - 3s 92ms/step - loss: 0.0023\n",
            "Epoch 49/75\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.0024\n",
            "Epoch 50/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0025\n",
            "Epoch 51/75\n",
            "37/37 [==============================] - 3s 92ms/step - loss: 0.0023\n",
            "Epoch 52/75\n",
            "37/37 [==============================] - 3s 95ms/step - loss: 0.0024\n",
            "Epoch 53/75\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0025\n",
            "Epoch 54/75\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 0.0025\n",
            "Epoch 55/75\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 0.0023\n",
            "Epoch 56/75\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0023\n",
            "Epoch 57/75\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 0.0024\n",
            "Epoch 58/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0024\n",
            "Epoch 59/75\n",
            "37/37 [==============================] - 4s 113ms/step - loss: 0.0024\n",
            "Epoch 60/75\n",
            "37/37 [==============================] - 3s 92ms/step - loss: 0.0024\n",
            "Epoch 61/75\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 0.0023\n",
            "Epoch 62/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0024\n",
            "Epoch 63/75\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.0022\n",
            "Epoch 64/75\n",
            "37/37 [==============================] - 3s 92ms/step - loss: 0.0023\n",
            "Epoch 65/75\n",
            "37/37 [==============================] - 3s 93ms/step - loss: 0.0023\n",
            "Epoch 66/75\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0023\n",
            "Epoch 67/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0022\n",
            "Epoch 68/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0022\n",
            "Epoch 69/75\n",
            "37/37 [==============================] - 4s 112ms/step - loss: 0.0024\n",
            "Epoch 70/75\n",
            "37/37 [==============================] - 3s 92ms/step - loss: 0.0023\n",
            "Epoch 71/75\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 0.0022\n",
            "Epoch 72/75\n",
            "37/37 [==============================] - 4s 113ms/step - loss: 0.0024\n",
            "Epoch 73/75\n",
            "37/37 [==============================] - 3s 92ms/step - loss: 0.0022\n",
            "Epoch 74/75\n",
            "37/37 [==============================] - 3s 92ms/step - loss: 0.0022\n",
            "Epoch 75/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0023\n",
            "50/50 [==============================] - 2s 13ms/step\n",
            "Epoch 1/75\n",
            "37/37 [==============================] - 15s 108ms/step - loss: 0.0131\n",
            "Epoch 2/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0053\n",
            "Epoch 3/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0046\n",
            "Epoch 4/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0037\n",
            "Epoch 5/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0039\n",
            "Epoch 6/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0034\n",
            "Epoch 7/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0033\n",
            "Epoch 8/75\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0034\n",
            "Epoch 9/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0031\n",
            "Epoch 10/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0031\n",
            "Epoch 11/75\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0029\n",
            "Epoch 12/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0030\n",
            "Epoch 13/75\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 0.0028\n",
            "Epoch 14/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0031\n",
            "Epoch 15/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0027\n",
            "Epoch 16/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0028\n",
            "Epoch 17/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0030\n",
            "Epoch 18/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0027\n",
            "Epoch 19/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0029\n",
            "Epoch 20/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0027\n",
            "Epoch 21/75\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 0.0028\n",
            "Epoch 22/75\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0027\n",
            "Epoch 23/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0026\n",
            "Epoch 24/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0026\n",
            "Epoch 25/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0024\n",
            "Epoch 26/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0025\n",
            "Epoch 27/75\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 0.0025\n",
            "Epoch 28/75\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.0028\n",
            "Epoch 29/75\n",
            "37/37 [==============================] - 3s 92ms/step - loss: 0.0026\n",
            "Epoch 30/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0024\n",
            "Epoch 31/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0025\n",
            "Epoch 32/75\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0026\n",
            "Epoch 33/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0024\n",
            "Epoch 34/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0024\n",
            "Epoch 35/75\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.0024\n",
            "Epoch 36/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0024\n",
            "Epoch 37/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0025\n",
            "Epoch 38/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0026\n",
            "Epoch 39/75\n",
            "37/37 [==============================] - 4s 110ms/step - loss: 0.0024\n",
            "Epoch 40/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0025\n",
            "Epoch 41/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0024\n",
            "Epoch 42/75\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0024\n",
            "Epoch 43/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0025\n",
            "Epoch 44/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0024\n",
            "Epoch 45/75\n",
            "37/37 [==============================] - 3s 92ms/step - loss: 0.0024\n",
            "Epoch 46/75\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0026\n",
            "Epoch 47/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0023\n",
            "Epoch 48/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0024\n",
            "Epoch 49/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0023\n",
            "Epoch 50/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0023\n",
            "Epoch 51/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0023\n",
            "Epoch 52/75\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0026\n",
            "Epoch 53/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0025\n",
            "Epoch 54/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0025\n",
            "Epoch 55/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0023\n",
            "Epoch 56/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0023\n",
            "Epoch 57/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0023\n",
            "Epoch 58/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0023\n",
            "Epoch 59/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0024\n",
            "Epoch 60/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0025\n",
            "Epoch 61/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0024\n",
            "Epoch 62/75\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 0.0023\n",
            "Epoch 63/75\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0023\n",
            "Epoch 64/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0023\n",
            "Epoch 65/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0024\n",
            "Epoch 66/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0023\n",
            "Epoch 67/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0023\n",
            "Epoch 68/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0021\n",
            "Epoch 69/75\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0023\n",
            "Epoch 70/75\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.0024\n",
            "Epoch 71/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 72/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0022\n",
            "Epoch 73/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0022\n",
            "Epoch 74/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 75/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "50/50 [==============================] - 2s 13ms/step\n",
            "Epoch 1/75\n",
            "37/37 [==============================] - 15s 86ms/step - loss: 0.0134\n",
            "Epoch 2/75\n",
            "37/37 [==============================] - 3s 84ms/step - loss: 0.0051\n",
            "Epoch 3/75\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.0041\n",
            "Epoch 4/75\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0041\n",
            "Epoch 5/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0035\n",
            "Epoch 6/75\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0039\n",
            "Epoch 7/75\n",
            "37/37 [==============================] - 3s 92ms/step - loss: 0.0031\n",
            "Epoch 8/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0032\n",
            "Epoch 9/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0030\n",
            "Epoch 10/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0032\n",
            "Epoch 11/75\n",
            "37/37 [==============================] - 3s 94ms/step - loss: 0.0033\n",
            "Epoch 12/75\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 0.0029\n",
            "Epoch 13/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0027\n",
            "Epoch 14/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0029\n",
            "Epoch 15/75\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 0.0033\n",
            "Epoch 16/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0027\n",
            "Epoch 17/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0028\n",
            "Epoch 18/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0028\n",
            "Epoch 19/75\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 0.0028\n",
            "Epoch 20/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0027\n",
            "Epoch 21/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0028\n",
            "Epoch 22/75\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 0.0027\n",
            "Epoch 23/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0026\n",
            "Epoch 24/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0025\n",
            "Epoch 25/75\n",
            "37/37 [==============================] - 3s 84ms/step - loss: 0.0025\n",
            "Epoch 26/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0026\n",
            "Epoch 27/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0027\n",
            "Epoch 28/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0027\n",
            "Epoch 29/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0026\n",
            "Epoch 30/75\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 0.0025\n",
            "Epoch 31/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0026\n",
            "Epoch 32/75\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 0.0025\n",
            "Epoch 33/75\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 0.0026\n",
            "Epoch 34/75\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0024\n",
            "Epoch 35/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0027\n",
            "Epoch 36/75\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 0.0025\n",
            "Epoch 37/75\n",
            "37/37 [==============================] - 3s 84ms/step - loss: 0.0024\n",
            "Epoch 38/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0024\n",
            "Epoch 39/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0024\n",
            "Epoch 40/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0025\n",
            "Epoch 41/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0025\n",
            "Epoch 42/75\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 0.0027\n",
            "Epoch 43/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0025\n",
            "Epoch 44/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0024\n",
            "Epoch 45/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0024\n",
            "Epoch 46/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0023\n",
            "Epoch 47/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0024\n",
            "Epoch 48/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0024\n",
            "Epoch 49/75\n",
            "37/37 [==============================] - 3s 84ms/step - loss: 0.0025\n",
            "Epoch 50/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0023\n",
            "Epoch 51/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0024\n",
            "Epoch 52/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0023\n",
            "Epoch 53/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0024\n",
            "Epoch 54/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0025\n",
            "Epoch 55/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0023\n",
            "Epoch 56/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0024\n",
            "Epoch 57/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0024\n",
            "Epoch 58/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0023\n",
            "Epoch 59/75\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0023\n",
            "Epoch 60/75\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 0.0026\n",
            "Epoch 61/75\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 0.0024\n",
            "Epoch 62/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0023\n",
            "Epoch 63/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0023\n",
            "Epoch 64/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0023\n",
            "Epoch 65/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0024\n",
            "Epoch 66/75\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0023\n",
            "Epoch 67/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 68/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0022\n",
            "Epoch 69/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0022\n",
            "Epoch 70/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0024\n",
            "Epoch 71/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0024\n",
            "Epoch 72/75\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.0023\n",
            "Epoch 73/75\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0023\n",
            "Epoch 74/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0023\n",
            "Epoch 75/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0023\n",
            "50/50 [==============================] - 2s 22ms/step\n",
            "Epoch 1/75\n",
            "37/37 [==============================] - 14s 86ms/step - loss: 0.0134\n",
            "Epoch 2/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0059\n",
            "Epoch 3/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0044\n",
            "Epoch 4/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0040\n",
            "Epoch 5/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0036\n",
            "Epoch 6/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0034\n",
            "Epoch 7/75\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0033\n",
            "Epoch 8/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0035\n",
            "Epoch 9/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0031\n",
            "Epoch 10/75\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.0030\n",
            "Epoch 11/75\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.0029\n",
            "Epoch 12/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0028\n",
            "Epoch 13/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0028\n",
            "Epoch 14/75\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.0029\n",
            "Epoch 15/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0027\n",
            "Epoch 16/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0028\n",
            "Epoch 17/75\n",
            "37/37 [==============================] - 4s 110ms/step - loss: 0.0030\n",
            "Epoch 18/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0028\n",
            "Epoch 19/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0026\n",
            "Epoch 20/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0027\n",
            "Epoch 21/75\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0029\n",
            "Epoch 22/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0027\n",
            "Epoch 23/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0027\n",
            "Epoch 24/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0026\n",
            "Epoch 25/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0025\n",
            "Epoch 26/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0026\n",
            "Epoch 27/75\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.0027\n",
            "Epoch 28/75\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.0027\n",
            "Epoch 29/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0027\n",
            "Epoch 30/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0025\n",
            "Epoch 31/75\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0026\n",
            "Epoch 32/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0026\n",
            "Epoch 33/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0025\n",
            "Epoch 34/75\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0025\n",
            "Epoch 35/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0025\n",
            "Epoch 36/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0025\n",
            "Epoch 37/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0026\n",
            "Epoch 38/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0024\n",
            "Epoch 39/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0024\n",
            "Epoch 40/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0024\n",
            "Epoch 41/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0025\n",
            "Epoch 42/75\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 0.0024\n",
            "Epoch 43/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0025\n",
            "Epoch 44/75\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0024\n",
            "Epoch 45/75\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0026\n",
            "Epoch 46/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0024\n",
            "Epoch 47/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0023\n",
            "Epoch 48/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0024\n",
            "Epoch 49/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0024\n",
            "Epoch 50/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0024\n",
            "Epoch 51/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0024\n",
            "Epoch 52/75\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 0.0023\n",
            "Epoch 53/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0023\n",
            "Epoch 54/75\n",
            "37/37 [==============================] - 3s 92ms/step - loss: 0.0023\n",
            "Epoch 55/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0023\n",
            "Epoch 56/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0023\n",
            "Epoch 57/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 58/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0023\n",
            "Epoch 59/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0023\n",
            "Epoch 60/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0022\n",
            "Epoch 61/75\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0023\n",
            "Epoch 62/75\n",
            "37/37 [==============================] - 4s 93ms/step - loss: 0.0022\n",
            "Epoch 63/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0024\n",
            "Epoch 64/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0023\n",
            "Epoch 65/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0023\n",
            "Epoch 66/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 67/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0023\n",
            "Epoch 68/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0025\n",
            "Epoch 69/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0023\n",
            "Epoch 70/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0022\n",
            "Epoch 71/75\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 0.0024\n",
            "Epoch 72/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0022\n",
            "Epoch 73/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0021\n",
            "Epoch 74/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0024\n",
            "Epoch 75/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0022\n",
            "50/50 [==============================] - 2s 13ms/step\n",
            "Epoch 1/75\n",
            "37/37 [==============================] - 14s 90ms/step - loss: 0.0134\n",
            "Epoch 2/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0060\n",
            "Epoch 3/75\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.0042\n",
            "Epoch 4/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0038\n",
            "Epoch 5/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0040\n",
            "Epoch 6/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0035\n",
            "Epoch 7/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0031\n",
            "Epoch 8/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0031\n",
            "Epoch 9/75\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 0.0035\n",
            "Epoch 10/75\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0029\n",
            "Epoch 11/75\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0032\n",
            "Epoch 12/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0031\n",
            "Epoch 13/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0029\n",
            "Epoch 14/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0032\n",
            "Epoch 15/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0027\n",
            "Epoch 16/75\n",
            "37/37 [==============================] - 4s 110ms/step - loss: 0.0027\n",
            "Epoch 17/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0028\n",
            "Epoch 18/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0028\n",
            "Epoch 19/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0026\n",
            "Epoch 20/75\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 0.0028\n",
            "Epoch 21/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0027\n",
            "Epoch 22/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0028\n",
            "Epoch 23/75\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.0028\n",
            "Epoch 24/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0026\n",
            "Epoch 25/75\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 0.0026\n",
            "Epoch 26/75\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.0025\n",
            "Epoch 27/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0026\n",
            "Epoch 28/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0026\n",
            "Epoch 29/75\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.0026\n",
            "Epoch 30/75\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.0025\n",
            "Epoch 31/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0024\n",
            "Epoch 32/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0025\n",
            "Epoch 33/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0025\n",
            "Epoch 34/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0026\n",
            "Epoch 35/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0025\n",
            "Epoch 36/75\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0027\n",
            "Epoch 37/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0024\n",
            "Epoch 38/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0024\n",
            "Epoch 39/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0025\n",
            "Epoch 40/75\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0025\n",
            "Epoch 41/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0024\n",
            "Epoch 42/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0024\n",
            "Epoch 43/75\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.0024\n",
            "Epoch 44/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0024\n",
            "Epoch 45/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0024\n",
            "Epoch 46/75\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0025\n",
            "Epoch 47/75\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.0024\n",
            "Epoch 48/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0023\n",
            "Epoch 49/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0024\n",
            "Epoch 50/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0026\n",
            "Epoch 51/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0024\n",
            "Epoch 52/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0024\n",
            "Epoch 53/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0023\n",
            "Epoch 54/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0023\n",
            "Epoch 55/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0022\n",
            "Epoch 56/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0024\n",
            "Epoch 57/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0024\n",
            "Epoch 58/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0023\n",
            "Epoch 59/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0022\n",
            "Epoch 60/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0024\n",
            "Epoch 61/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0024\n",
            "Epoch 62/75\n",
            "37/37 [==============================] - 3s 92ms/step - loss: 0.0023\n",
            "Epoch 63/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0023\n",
            "Epoch 64/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0023\n",
            "Epoch 65/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 66/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 67/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0023\n",
            "Epoch 68/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0024\n",
            "Epoch 69/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0022\n",
            "Epoch 70/75\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 0.0022\n",
            "Epoch 71/75\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.0024\n",
            "Epoch 72/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0024\n",
            "Epoch 73/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0023\n",
            "Epoch 74/75\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0022\n",
            "Epoch 75/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "50/50 [==============================] - 4s 14ms/step\n",
            "Epoch 1/75\n",
            "37/37 [==============================] - 14s 88ms/step - loss: 0.0130\n",
            "Epoch 2/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0054\n",
            "Epoch 3/75\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0045\n",
            "Epoch 4/75\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0038\n",
            "Epoch 5/75\n",
            "37/37 [==============================] - 3s 93ms/step - loss: 0.0035\n",
            "Epoch 6/75\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.0035\n",
            "Epoch 7/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0032\n",
            "Epoch 8/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0033\n",
            "Epoch 9/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0030\n",
            "Epoch 10/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0029\n",
            "Epoch 11/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0029\n",
            "Epoch 12/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0030\n",
            "Epoch 13/75\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.0033\n",
            "Epoch 14/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0029\n",
            "Epoch 15/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0029\n",
            "Epoch 16/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0028\n",
            "Epoch 17/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0028\n",
            "Epoch 18/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0030\n",
            "Epoch 19/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0027\n",
            "Epoch 20/75\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0027\n",
            "Epoch 21/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0026\n",
            "Epoch 22/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0026\n",
            "Epoch 23/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0029\n",
            "Epoch 24/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0026\n",
            "Epoch 25/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0026\n",
            "Epoch 26/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0026\n",
            "Epoch 27/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0025\n",
            "Epoch 28/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0025\n",
            "Epoch 29/75\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 0.0026\n",
            "Epoch 30/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0026\n",
            "Epoch 31/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0026\n",
            "Epoch 32/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0028\n",
            "Epoch 33/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0025\n",
            "Epoch 34/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0027\n",
            "Epoch 35/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0026\n",
            "Epoch 36/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0024\n",
            "Epoch 37/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0025\n",
            "Epoch 38/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0026\n",
            "Epoch 39/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0027\n",
            "Epoch 40/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0023\n",
            "Epoch 41/75\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0024\n",
            "Epoch 42/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0026\n",
            "Epoch 43/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0023\n",
            "Epoch 44/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0024\n",
            "Epoch 45/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0026\n",
            "Epoch 46/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0024\n",
            "Epoch 47/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0024\n",
            "Epoch 48/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0024\n",
            "Epoch 49/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0024\n",
            "Epoch 50/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0023\n",
            "Epoch 51/75\n",
            "37/37 [==============================] - 3s 92ms/step - loss: 0.0023\n",
            "Epoch 52/75\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.0024\n",
            "Epoch 53/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0025\n",
            "Epoch 54/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0023\n",
            "Epoch 55/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0024\n",
            "Epoch 56/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0023\n",
            "Epoch 57/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0023\n",
            "Epoch 58/75\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0022\n",
            "Epoch 59/75\n",
            "37/37 [==============================] - 4s 94ms/step - loss: 0.0023\n",
            "Epoch 60/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0024\n",
            "Epoch 61/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0025\n",
            "Epoch 62/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0023\n",
            "Epoch 63/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0023\n",
            "Epoch 64/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0022\n",
            "Epoch 65/75\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.0023\n",
            "Epoch 66/75\n",
            "37/37 [==============================] - 3s 93ms/step - loss: 0.0024\n",
            "Epoch 67/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0025\n",
            "Epoch 68/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0022\n",
            "Epoch 69/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0023\n",
            "Epoch 70/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 71/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0022\n",
            "Epoch 72/75\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0023\n",
            "Epoch 73/75\n",
            "37/37 [==============================] - 3s 92ms/step - loss: 0.0023\n",
            "Epoch 74/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0023\n",
            "Epoch 75/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0022\n",
            "50/50 [==============================] - 3s 21ms/step\n",
            "Epoch 1/75\n",
            "37/37 [==============================] - 14s 88ms/step - loss: 0.0125\n",
            "Epoch 2/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0056\n",
            "Epoch 3/75\n",
            "37/37 [==============================] - 3s 92ms/step - loss: 0.0045\n",
            "Epoch 4/75\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0040\n",
            "Epoch 5/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0038\n",
            "Epoch 6/75\n",
            "37/37 [==============================] - 3s 90ms/step - loss: 0.0037\n",
            "Epoch 7/75\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0033\n",
            "Epoch 8/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0033\n",
            "Epoch 9/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0035\n",
            "Epoch 10/75\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0029\n",
            "Epoch 11/75\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 0.0029\n",
            "Epoch 12/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0028\n",
            "Epoch 13/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0028\n",
            "Epoch 14/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0028\n",
            "Epoch 15/75\n",
            "37/37 [==============================] - 3s 89ms/step - loss: 0.0026\n",
            "Epoch 16/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0029\n",
            "Epoch 17/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0028\n",
            "Epoch 18/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0027\n",
            "Epoch 19/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0028\n",
            "Epoch 20/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0028\n",
            "Epoch 21/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0026\n",
            "Epoch 22/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0028\n",
            "Epoch 23/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0027\n",
            "Epoch 24/75\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0027\n",
            "Epoch 25/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0028\n",
            "Epoch 26/75\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0025\n",
            "Epoch 27/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0026\n",
            "Epoch 28/75\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0025\n",
            "Epoch 29/75\n",
            "37/37 [==============================] - 4s 113ms/step - loss: 0.0026\n",
            "Epoch 30/75\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 0.0026\n",
            "Epoch 31/75\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.0026\n",
            "Epoch 32/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0026\n",
            "Epoch 33/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0025\n",
            "Epoch 34/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0025\n",
            "Epoch 35/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0024\n",
            "Epoch 36/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0024\n",
            "Epoch 37/75\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.0025\n",
            "Epoch 38/75\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0024\n",
            "Epoch 39/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0025\n",
            "Epoch 40/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0028\n",
            "Epoch 41/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0025\n",
            "Epoch 42/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0024\n",
            "Epoch 43/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0024\n",
            "Epoch 44/75\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.0024\n",
            "Epoch 45/75\n",
            "37/37 [==============================] - 3s 92ms/step - loss: 0.0025\n",
            "Epoch 46/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0024\n",
            "Epoch 47/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0024\n",
            "Epoch 48/75\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0025\n",
            "Epoch 49/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0024\n",
            "Epoch 50/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0023\n",
            "Epoch 51/75\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0025\n",
            "Epoch 52/75\n",
            "37/37 [==============================] - 3s 93ms/step - loss: 0.0023\n",
            "Epoch 53/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0023\n",
            "Epoch 54/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0024\n",
            "Epoch 55/75\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0023\n",
            "Epoch 56/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0022\n",
            "Epoch 57/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0023\n",
            "Epoch 58/75\n",
            "37/37 [==============================] - 3s 93ms/step - loss: 0.0024\n",
            "Epoch 59/75\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0023\n",
            "Epoch 60/75\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 0.0025\n",
            "Epoch 61/75\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 0.0022\n",
            "Epoch 62/75\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.0022\n",
            "Epoch 63/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0023\n",
            "Epoch 64/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0024\n",
            "Epoch 65/75\n",
            "37/37 [==============================] - 3s 92ms/step - loss: 0.0022\n",
            "Epoch 66/75\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.0023\n",
            "Epoch 67/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0023\n",
            "Epoch 68/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0023\n",
            "Epoch 69/75\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0022\n",
            "Epoch 70/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0023\n",
            "Epoch 71/75\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 0.0024\n",
            "Epoch 72/75\n",
            "37/37 [==============================] - 3s 94ms/step - loss: 0.0023\n",
            "Epoch 73/75\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.0024\n",
            "Epoch 74/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0021\n",
            "Epoch 75/75\n",
            "37/37 [==============================] - 3s 87ms/step - loss: 0.0022\n",
            "50/50 [==============================] - 2s 21ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss)"
      ],
      "metadata": {
        "id": "MnuUdKWaqgaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02d9b9ec-0077-407b-cddb-4141b95e5d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.04916283249626215, 0.053573653379712885, 0.04866682767699833, 0.052005877610451216, 0.05052912744143249, 0.05375220214115492, 0.051438420328249315, 0.05329784055623884, 0.06149703147133293, 0.04986013423369591]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(min(loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56ykd7kawkvX",
        "outputId": "b5ea25c6-14ae-4faf-950c-655cbc68e835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.04866682767699833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "5KwbVjdXKn01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss)"
      ],
      "metadata": {
        "id": "O622nEj3Krt7",
        "outputId": "7bd250c3-4686-44a8-bcf1-2c25a8d8f68d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f95c1920640>]"
            ]
          },
          "metadata": {},
          "execution_count": 153
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}