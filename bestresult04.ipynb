{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DIPANJAN001/Forecasting-Solar-Energy/blob/master/bestresult04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzs_vH9vlX74",
        "outputId": "6f26c44d-cda4-4ce9-b9d6-6c7b66d8c888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Boruta in /usr/local/lib/python3.8/dist-packages (0.3)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.17.1->Boruta) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.17.1->Boruta) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install Boruta\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from boruta import BorutaPy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import concatenate\n",
        "from keras import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Bidirectional\n",
        "from keras import layers\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import load_model\n",
        "from keras.layers import Input\n",
        "from sklearn.decomposition import PCA "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "lDilv4v2lz-w"
      },
      "outputs": [],
      "source": [
        "def lstm_data_transform(x_data, y_data, num_steps):\n",
        "    \"\"\" Changes data to the format for LSTM training \n",
        "for sliding window approach \"\"\"\n",
        "    # Prepare the list for the transformed data\n",
        "    X, y = list(), list()\n",
        "    # Loop of the entire data set\n",
        "    for i in range(x_data.shape[0]):\n",
        "        # compute a new (sliding window) index\n",
        "        end_ix = i + num_steps\n",
        "        # if index is larger than the size of the dataset, we stop\n",
        "        if end_ix >= x_data.shape[0]:\n",
        "            break\n",
        "        # Get a sequence of data for x\n",
        "        seq_X = x_data[i:end_ix]\n",
        "        # Get only the last element of the sequency for y\n",
        "        seq_y = y_data[end_ix]\n",
        "        # Append the list with sequencies\n",
        "        X.append(seq_X)\n",
        "        y.append(seq_y)\n",
        "    # Make final arrays\n",
        "    x_array = np.array(X)\n",
        "    y_array = np.array(y)\n",
        "    return x_array, y_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "iQt_oZP7QczL"
      },
      "outputs": [],
      "source": [
        "df=pd.read_excel(\"/content/pv_04.xlsx\")\n",
        "weather_input1=df.drop('power_normed',axis=1)\n",
        "weather_input=weather_input1.drop('time_idx',axis=1)\n",
        "solpow=df['power_normed']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoPnMw4oQQlc",
        "outputId": "81412a6a-c528-4920-d1d0-a78e1bea0948"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: \t1 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t2 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t3 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t4 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t5 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t6 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t7 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t8 / 100\n",
            "Confirmed: \t9\n",
            "Tentative: \t14\n",
            "Rejected: \t26\n",
            "Iteration: \t9 / 100\n",
            "Confirmed: \t9\n",
            "Tentative: \t14\n",
            "Rejected: \t26\n",
            "Iteration: \t10 / 100\n",
            "Confirmed: \t9\n",
            "Tentative: \t14\n",
            "Rejected: \t26\n",
            "Iteration: \t11 / 100\n",
            "Confirmed: \t9\n",
            "Tentative: \t14\n",
            "Rejected: \t26\n",
            "Iteration: \t12 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t8\n",
            "Rejected: \t29\n",
            "Iteration: \t13 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t8\n",
            "Rejected: \t29\n",
            "Iteration: \t14 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t8\n",
            "Rejected: \t29\n",
            "Iteration: \t15 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t8\n",
            "Rejected: \t29\n",
            "Iteration: \t16 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t7\n",
            "Rejected: \t29\n",
            "Iteration: \t17 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t7\n",
            "Rejected: \t29\n",
            "Iteration: \t18 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t7\n",
            "Rejected: \t29\n",
            "Iteration: \t19 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t7\n",
            "Rejected: \t29\n",
            "Iteration: \t20 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t7\n",
            "Rejected: \t29\n",
            "Iteration: \t21 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t7\n",
            "Rejected: \t29\n",
            "Iteration: \t22 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t23 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t24 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t25 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t26 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t27 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t28 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t29 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t30 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t31 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t32 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t33 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t34 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t35 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t36 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t37 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t38 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t39 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t40 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t41 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t42 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t43 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t44 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t45 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t46 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t47 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t48 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t49 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t50 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t51 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t52 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t53 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t54 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t55 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t56 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t57 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t58 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t59 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t60 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t61 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t62 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t63 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t64 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t65 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t66 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t67 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t68 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t69 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t70 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t71 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t72 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t73 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t74 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t75 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t76 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t77 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t78 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t79 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t80 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t81 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t82 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t83 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t84 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t85 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t86 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t87 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t88 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t89 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t90 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t91 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t92 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t93 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t94 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t95 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t96 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t97 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t98 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t99 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "\n",
            "\n",
            "BorutaPy finished running.\n",
            "\n",
            "Iteration: \t100 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t1\n",
            "Rejected: \t30\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BorutaPy(estimator=RandomForestRegressor(max_depth=7, n_estimators=88,\n",
              "                                         random_state=RandomState(MT19937) at 0x7F95C87EFD40),\n",
              "         n_estimators='auto',\n",
              "         random_state=RandomState(MT19937) at 0x7F95C87EFD40, verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "rfc = RandomForestRegressor(random_state=1, n_estimators=1000, max_depth=7)\n",
        "boruta_selector = BorutaPy(rfc, n_estimators='auto', verbose=2, random_state=1)\n",
        "boruta_selector.fit(np.array(weather_input), np.array(solpow)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "u2NoSDCGUFNU"
      },
      "outputs": [],
      "source": [
        "X_important_train = boruta_selector.transform(np.array(weather_input))\n",
        "num_steps = 3\n",
        "# training set\n",
        "(x_transformed_train,\n",
        " y_transformed_train) = lstm_data_transform(X_important_train,solpow , num_steps=num_steps)\n",
        "assert x_transformed_train.shape[0] == y_transformed_train.shape[0]\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_transformed_train,y_transformed_train,test_size=0.25, random_state=42,shuffle=False)\n",
        "#X_train_,X_val,y_train_,y_val=train_test_split(X_train,y_train,test_size=0.2, random_state=42,shuffle=False)\n",
        "inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdKjqiCK5m_T",
        "outputId": "d23be029-787b-480f-9f31-b80269b14df0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 3, 17) dtype=float32 (created by layer 'input_3')>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "inputs1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "V27z-GjNapD4"
      },
      "outputs": [],
      "source": [
        "from keras import optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "uxD0diT8a4c2"
      },
      "outputs": [],
      "source": [
        "opt=optimizers.Adam(learning_rate=0.003)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "YM0Epc0yvWnJ"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "\n",
        "class CustomAdam(optimizers.Adam):\n",
        "    def __init__(self, new_idea_param=0.1, *args, **kwargs):\n",
        "        self.new_idea_param = new_idea_param\n",
        "        super(CustomAdam, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [K.update_add(self.iterations, 1)]\n",
        "\n",
        "        lr = self.lr\n",
        "        if self.initial_decay > 0:\n",
        "            lr *= (1. / (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n",
        "\n",
        "        t = K.cast(self.iterations, K.floatx()) + 1\n",
        "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        new_idea_t = self.new_idea_param * (K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        self.weights = [self.iterations] + ms + vs\n",
        "\n",
        "        for p, g, m, v in zip(params, grads, ms, vs):\n",
        "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
        "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
        "            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon) - new_idea_t * g\n",
        "\n",
        "            self.updates.append(K.update(m, m_t))\n",
        "            self.updates.append(K.update(v, v_t))\n",
        "            self.updates.append(K.update(p, p_t))\n",
        "        return self.updates"
      ],
      "metadata": {
        "id": "g8F6yCGl21Sz"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "\n",
        "class GradientAdam(optimizers.Adam):\n",
        "    def __init__(self, gradient_param=0.1, *args, **kwargs):\n",
        "        self.gradient_param = gradient_param\n",
        "        super(GradientAdam, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [K.update_add(self.iterations, 1)]\n",
        "\n",
        "        lr = self.lr\n",
        "        if self.initial_decay > 0:\n",
        "            lr *= (1. / (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n",
        "\n",
        "        t = K.cast(self.iterations, K.floatx()) + 1\n",
        "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        gradient_t = self.gradient_param * grads\n",
        "\n",
        "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        self.weights = [self.iterations] + ms + vs\n",
        "\n",
        "        for p, g, m, v, g_t in zip(params, grads, ms, vs, gradient_t):\n",
        "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
        "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
        "            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon) + g_t\n",
        "\n",
        "            self.updates.append(K.update(m, m_t))\n",
        "            self.updates.append(K.update(v, v_t))\n",
        "            self.updates.append(K.update(p, p_t))\n",
        "        return self.updates\n"
      ],
      "metadata": {
        "id": "J_gyZaJU8f4W"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "t0f48T0zsiAs"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "class HalvAdam(Adam):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.prev_gradients = None\n",
        "\n",
        "    @tf.function\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [math_ops.cast(x, \"float32\") for x in grads]\n",
        "\n",
        "        if self.prev_gradients is not None:\n",
        "            for i in range(len(grads)):\n",
        "                if (grads[i] * self.prev_gradients[i] < 0):\n",
        "                    self.updates[i] = self.updates[i] / 2\n",
        "\n",
        "        self.prev_gradients = grads\n",
        "        return self.updates"
      ],
      "metadata": {
        "id": "MpStRslgCRBO"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "class AdaptiveAdam(Adam):\n",
        "    def __init__(self, *args, factor=0.5, patience=5, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.wait = 0\n",
        "        self.best_loss = float('inf')\n",
        "        self.best_weights = None\n",
        "\n",
        "    @tf.function\n",
        "    def get_updates(self, loss, params):\n",
        "        current_loss = loss()\n",
        "        if current_loss < self.best_loss:\n",
        "            self.best_loss = current_loss\n",
        "            self.best_weights = params\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.wait = 0\n",
        "                self.lr = self.lr * self.factor\n",
        "                params = self.best_weights\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [math_ops.cast(g, \"float32\") for g in grads]\n",
        "        return self.updates\n"
      ],
      "metadata": {
        "id": "PmHcGR7JJLo_"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "class MomentumAdam(Adam):\n",
        "    def __init__(self, *args, momentum=0.9, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.momentum = momentum\n",
        "        self.velocities = [tf.Variable(tf.zeros_like(p), trainable=False) for p in self.weights]\n",
        "\n",
        "    @tf.function\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = []\n",
        "        for p, g, v in zip(params, grads, self.velocities):\n",
        "            v_t = self.momentum * v - self.lr * g\n",
        "            p_t = p + v_t\n",
        "            self.updates.append(p_t)\n",
        "            self.updates.append(v_t)\n",
        "        return self.updates\n"
      ],
      "metadata": {
        "id": "Zqo9SvzjbTtq"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "cSM9vzEq3G3U"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "nq9ZwBIrI_qj"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "18n5dRvpuI5T"
      },
      "outputs": [],
      "source": [
        "def define_model():\n",
        "\n",
        "\n",
        "  fe2_0 = Bidirectional(LSTM(256, activation='LeakyReLU',return_sequences = True))(inputs1)\n",
        "  fe2_1 = Dropout(0.6)(fe2_0)\n",
        "  fe2_2 = Bidirectional(LSTM(64, activation='LeakyReLU',return_sequences = True))(fe2_1)\n",
        "  fe2_3= Dropout(0.5)(fe2_2)\n",
        "  fe2_4=Bidirectional(LSTM(4, activation='LeakyReLU'))(fe2_3)\n",
        "  out2_1=Dense(1, activation='relu')(fe2_4)\n",
        "\n",
        "  fe3_0 =Bidirectional(LSTM(128, activation='LeakyReLU',return_sequences = True))(inputs1)\n",
        "  fe3_1 = Dropout(0.6)(fe3_0)\n",
        "  fe3_2 = Bidirectional(LSTM(96, activation='LeakyReLU',return_sequences = True))(fe3_1)\n",
        "  fe3_3= Dropout(0.5)(fe3_2)\n",
        "  fe3_4=Bidirectional(LSTM(8, activation='LeakyReLU'))(fe3_3)#16\n",
        "  out3_1=Dense(1, activation='relu')(fe3_4)\n",
        " \n",
        " \n",
        "\n",
        "  output = layers.average([out2_1, out3_1])\n",
        "  #merged3 = concatenate([out2_1,out3_1], name='concat3')\n",
        "  #output = Dense(1, activation='relu')( merged3)\n",
        "  \n",
        "\n",
        "  model = Model(inputs=[inputs1], outputs=[output])\n",
        "  \n",
        " \n",
        "  return model\n",
        "mdl=define_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss=[]"
      ],
      "metadata": {
        "id": "P5UqekV1_q7F"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import clone_model"
      ],
      "metadata": {
        "id": "9zy5UX8p_zSl"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "dAICp2p5OCER"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "9iwWrmDs0z7O"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GlobalMinimaSearch(weights):\n",
        "  if len(loss)>9:\n",
        "   return\n",
        "  \n",
        "  initial_weights =weights\n",
        "  model=clone_model(mdl)\n",
        "  model.set_weights(weights)\n",
        "  model.compile(optimizer=HalvAdam(learning_rate=0.003), loss='mean_squared_error')\n",
        "  model.fit(X_train, y_train, epochs=120, batch_size=128)\n",
        "  y= model.predict(X_test)\n",
        "  loss.append(np.sqrt(mean_squared_error(y,y_test)))\n",
        "  best_weights= model.get_weights()\n",
        "  \n",
        "\n",
        "     \n",
        "\n",
        "  params_1 =[final_weight + (final_weight - initial_weight) for initial_weight, final_weight in zip(initial_weights, best_weights)]\n",
        "  #GlobalMinimaSearch(params_1)\n",
        "\n",
        "\n",
        "  params_2 =[final_weight - (final_weight - initial_weight) for initial_weight, final_weight in zip(initial_weights, best_weights)]\n",
        "  GlobalMinimaSearch(params_2)\n",
        "  \n",
        " "
      ],
      "metadata": {
        "id": "FxpviTJb_nUR"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GlobalMinimaSearch(mdl.get_weights())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuddmGCf_1dR",
        "outputId": "c319f1c8-2ecf-4f8a-da4e-ae079c06940b"
      },
      "execution_count": 101,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "36/36 [==============================] - 14s 87ms/step - loss: 0.0133\n",
            "Epoch 2/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0043\n",
            "Epoch 3/120\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.0040\n",
            "Epoch 4/120\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.0038\n",
            "Epoch 5/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0037\n",
            "Epoch 6/120\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.0038\n",
            "Epoch 7/120\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.0032\n",
            "Epoch 8/120\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.0030\n",
            "Epoch 9/120\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 0.0028\n",
            "Epoch 10/120\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.0029\n",
            "Epoch 11/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0030\n",
            "Epoch 12/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0027\n",
            "Epoch 13/120\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0027\n",
            "Epoch 14/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0026\n",
            "Epoch 15/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0027\n",
            "Epoch 16/120\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0027\n",
            "Epoch 17/120\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.0026\n",
            "Epoch 18/120\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.0026\n",
            "Epoch 19/120\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.0027\n",
            "Epoch 20/120\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0024\n",
            "Epoch 21/120\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.0025\n",
            "Epoch 22/120\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.0025\n",
            "Epoch 23/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0026\n",
            "Epoch 24/120\n",
            "36/36 [==============================] - 3s 94ms/step - loss: 0.0024\n",
            "Epoch 25/120\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.0024\n",
            "Epoch 26/120\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.0025\n",
            "Epoch 27/120\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0025\n",
            "Epoch 28/120\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.0023\n",
            "Epoch 29/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0024\n",
            "Epoch 30/120\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.0023\n",
            "Epoch 31/120\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 0.0023\n",
            "Epoch 32/120\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.0023\n",
            "Epoch 33/120\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.0024\n",
            "Epoch 34/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0023\n",
            "Epoch 35/120\n",
            "36/36 [==============================] - 4s 98ms/step - loss: 0.0023\n",
            "Epoch 36/120\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.0023\n",
            "Epoch 37/120\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.0022\n",
            "Epoch 38/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0024\n",
            "Epoch 39/120\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.0023\n",
            "Epoch 40/120\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.0022\n",
            "Epoch 41/120\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.0022\n",
            "Epoch 42/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0022\n",
            "Epoch 43/120\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.0023\n",
            "Epoch 44/120\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.0022\n",
            "Epoch 45/120\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.0022\n",
            "Epoch 46/120\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0021\n",
            "Epoch 47/120\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.0023\n",
            "Epoch 48/120\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.0023\n",
            "Epoch 49/120\n",
            "36/36 [==============================] - 3s 95ms/step - loss: 0.0021\n",
            "Epoch 50/120\n",
            "36/36 [==============================] - 3s 94ms/step - loss: 0.0020\n",
            "Epoch 51/120\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.0022\n",
            "Epoch 52/120\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.0021\n",
            "Epoch 53/120\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0022\n",
            "Epoch 54/120\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.0023\n",
            "Epoch 55/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0021\n",
            "Epoch 56/120\n",
            "36/36 [==============================] - 3s 95ms/step - loss: 0.0022\n",
            "Epoch 57/120\n",
            "36/36 [==============================] - 3s 94ms/step - loss: 0.0022\n",
            "Epoch 58/120\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.0021\n",
            "Epoch 59/120\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.0021\n",
            "Epoch 60/120\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0020\n",
            "Epoch 61/120\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.0020\n",
            "Epoch 62/120\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.0021\n",
            "Epoch 63/120\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.0021\n",
            "Epoch 64/120\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0020\n",
            "Epoch 65/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0020\n",
            "Epoch 66/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0020\n",
            "Epoch 67/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0021\n",
            "Epoch 68/120\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0021\n",
            "Epoch 69/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0020\n",
            "Epoch 70/120\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.0021\n",
            "Epoch 71/120\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0020\n",
            "Epoch 72/120\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.0021\n",
            "Epoch 73/120\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.0020\n",
            "Epoch 74/120\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.0019\n",
            "Epoch 75/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0019\n",
            "Epoch 76/120\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.0019\n",
            "Epoch 77/120\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.0020\n",
            "Epoch 78/120\n",
            "36/36 [==============================] - 3s 96ms/step - loss: 0.0019\n",
            "Epoch 79/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0019\n",
            "Epoch 80/120\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.0019\n",
            "Epoch 81/120\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.0020\n",
            "Epoch 82/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0019\n",
            "Epoch 83/120\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.0019\n",
            "Epoch 84/120\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.0019\n",
            "Epoch 85/120\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.0019\n",
            "Epoch 86/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0018\n",
            "Epoch 87/120\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.0018\n",
            "Epoch 88/120\n",
            "36/36 [==============================] - 3s 80ms/step - loss: 0.0018\n",
            "Epoch 89/120\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.0019\n",
            "Epoch 90/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0019\n",
            "Epoch 91/120\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.0018\n",
            "Epoch 92/120\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.0019\n",
            "Epoch 93/120\n",
            "36/36 [==============================] - 3s 96ms/step - loss: 0.0018\n",
            "Epoch 94/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0018\n",
            "Epoch 95/120\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.0019\n",
            "Epoch 96/120\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.0019\n",
            "Epoch 97/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0018\n",
            "Epoch 98/120\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.0019\n",
            "Epoch 99/120\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.0018\n",
            "Epoch 100/120\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.0019\n",
            "Epoch 101/120\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0018\n",
            "Epoch 102/120\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.0020\n",
            "Epoch 103/120\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.0019\n",
            "Epoch 104/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0018\n",
            "Epoch 105/120\n",
            "36/36 [==============================] - 3s 94ms/step - loss: 0.0018\n",
            "Epoch 106/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0018\n",
            "Epoch 107/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0018\n",
            "Epoch 108/120\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0017\n",
            "Epoch 109/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0017\n",
            "Epoch 110/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0018\n",
            "Epoch 111/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0017\n",
            "Epoch 112/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0018\n",
            "Epoch 113/120\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.0017\n",
            "Epoch 114/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0018\n",
            "Epoch 115/120\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 0.0017\n",
            "Epoch 116/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0018\n",
            "Epoch 117/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0018\n",
            "Epoch 118/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0017\n",
            "Epoch 119/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0017\n",
            "Epoch 120/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0017\n",
            "48/48 [==============================] - 2s 12ms/step\n",
            "Epoch 1/120\n",
            "36/36 [==============================] - 20s 101ms/step - loss: 0.0146\n",
            "Epoch 2/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0045\n",
            "Epoch 3/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0039\n",
            "Epoch 4/120\n",
            "36/36 [==============================] - 4s 116ms/step - loss: 0.0035\n",
            "Epoch 5/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0038\n",
            "Epoch 6/120\n",
            "36/36 [==============================] - 4s 124ms/step - loss: 0.0034\n",
            "Epoch 7/120\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0032\n",
            "Epoch 8/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0031\n",
            "Epoch 9/120\n",
            "36/36 [==============================] - 4s 123ms/step - loss: 0.0029\n",
            "Epoch 10/120\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0032\n",
            "Epoch 11/120\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0032\n",
            "Epoch 12/120\n",
            "36/36 [==============================] - 4s 124ms/step - loss: 0.0031\n",
            "Epoch 13/120\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0028\n",
            "Epoch 14/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0027\n",
            "Epoch 15/120\n",
            "36/36 [==============================] - 4s 123ms/step - loss: 0.0027\n",
            "Epoch 16/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0028\n",
            "Epoch 17/120\n",
            "36/36 [==============================] - 4s 108ms/step - loss: 0.0027\n",
            "Epoch 18/120\n",
            "36/36 [==============================] - 4s 117ms/step - loss: 0.0027\n",
            "Epoch 19/120\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0027\n",
            "Epoch 20/120\n",
            "36/36 [==============================] - 4s 108ms/step - loss: 0.0026\n",
            "Epoch 21/120\n",
            "36/36 [==============================] - 4s 114ms/step - loss: 0.0025\n",
            "Epoch 22/120\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 0.0026\n",
            "Epoch 23/120\n",
            "36/36 [==============================] - 4s 111ms/step - loss: 0.0024\n",
            "Epoch 24/120\n",
            "36/36 [==============================] - 4s 113ms/step - loss: 0.0025\n",
            "Epoch 25/120\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0025\n",
            "Epoch 26/120\n",
            "36/36 [==============================] - 4s 114ms/step - loss: 0.0026\n",
            "Epoch 27/120\n",
            "36/36 [==============================] - 4s 111ms/step - loss: 0.0023\n",
            "Epoch 28/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0024\n",
            "Epoch 29/120\n",
            "36/36 [==============================] - 4s 114ms/step - loss: 0.0023\n",
            "Epoch 30/120\n",
            "36/36 [==============================] - 4s 112ms/step - loss: 0.0024\n",
            "Epoch 31/120\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0023\n",
            "Epoch 32/120\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 0.0027\n",
            "Epoch 33/120\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0025\n",
            "Epoch 34/120\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 0.0024\n",
            "Epoch 35/120\n",
            "36/36 [==============================] - 5s 127ms/step - loss: 0.0024\n",
            "Epoch 36/120\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0024\n",
            "Epoch 37/120\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.0024\n",
            "Epoch 38/120\n",
            "36/36 [==============================] - 5s 127ms/step - loss: 0.0022\n",
            "Epoch 39/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0024\n",
            "Epoch 40/120\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0023\n",
            "Epoch 41/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0022\n",
            "Epoch 42/120\n",
            "36/36 [==============================] - 4s 108ms/step - loss: 0.0023\n",
            "Epoch 43/120\n",
            "36/36 [==============================] - 4s 108ms/step - loss: 0.0022\n",
            "Epoch 44/120\n",
            "36/36 [==============================] - 5s 127ms/step - loss: 0.0023\n",
            "Epoch 45/120\n",
            "36/36 [==============================] - 4s 108ms/step - loss: 0.0023\n",
            "Epoch 46/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0023\n",
            "Epoch 47/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0022\n",
            "Epoch 48/120\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.0022\n",
            "Epoch 49/120\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0022\n",
            "Epoch 50/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0022\n",
            "Epoch 51/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0022\n",
            "Epoch 52/120\n",
            "36/36 [==============================] - 4s 117ms/step - loss: 0.0023\n",
            "Epoch 53/120\n",
            "36/36 [==============================] - 4s 111ms/step - loss: 0.0021\n",
            "Epoch 54/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0021\n",
            "Epoch 55/120\n",
            "36/36 [==============================] - 5s 149ms/step - loss: 0.0021\n",
            "Epoch 56/120\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0021\n",
            "Epoch 57/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0022\n",
            "Epoch 58/120\n",
            "36/36 [==============================] - 5s 127ms/step - loss: 0.0021\n",
            "Epoch 59/120\n",
            "36/36 [==============================] - 4s 108ms/step - loss: 0.0021\n",
            "Epoch 60/120\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0021\n",
            "Epoch 61/120\n",
            "36/36 [==============================] - 5s 126ms/step - loss: 0.0020\n",
            "Epoch 62/120\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0021\n",
            "Epoch 63/120\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0021\n",
            "Epoch 64/120\n",
            "36/36 [==============================] - 4s 123ms/step - loss: 0.0021\n",
            "Epoch 65/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0021\n",
            "Epoch 66/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0020\n",
            "Epoch 67/120\n",
            "36/36 [==============================] - 5s 146ms/step - loss: 0.0020\n",
            "Epoch 68/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0021\n",
            "Epoch 69/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0020\n",
            "Epoch 70/120\n",
            "36/36 [==============================] - 4s 123ms/step - loss: 0.0021\n",
            "Epoch 71/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0022\n",
            "Epoch 72/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0021\n",
            "Epoch 73/120\n",
            "36/36 [==============================] - 4s 122ms/step - loss: 0.0021\n",
            "Epoch 74/120\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 0.0022\n",
            "Epoch 75/120\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0020\n",
            "Epoch 76/120\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 0.0020\n",
            "Epoch 77/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0021\n",
            "Epoch 78/120\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0020\n",
            "Epoch 79/120\n",
            "36/36 [==============================] - 4s 125ms/step - loss: 0.0021\n",
            "Epoch 80/120\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.0020\n",
            "Epoch 81/120\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0019\n",
            "Epoch 82/120\n",
            "36/36 [==============================] - 4s 122ms/step - loss: 0.0019\n",
            "Epoch 83/120\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 0.0019\n",
            "Epoch 84/120\n",
            "36/36 [==============================] - 4s 115ms/step - loss: 0.0019\n",
            "Epoch 85/120\n",
            "36/36 [==============================] - 4s 115ms/step - loss: 0.0021\n",
            "Epoch 86/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0019\n",
            "Epoch 87/120\n",
            "36/36 [==============================] - 4s 125ms/step - loss: 0.0019\n",
            "Epoch 88/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0020\n",
            "Epoch 89/120\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 0.0019\n",
            "Epoch 90/120\n",
            "36/36 [==============================] - 4s 123ms/step - loss: 0.0019\n",
            "Epoch 91/120\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.0018\n",
            "Epoch 92/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0020\n",
            "Epoch 93/120\n",
            "36/36 [==============================] - 4s 125ms/step - loss: 0.0020\n",
            "Epoch 94/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0020\n",
            "Epoch 95/120\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.0020\n",
            "Epoch 96/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0019\n",
            "Epoch 97/120\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0019\n",
            "Epoch 98/120\n",
            "36/36 [==============================] - 4s 108ms/step - loss: 0.0018\n",
            "Epoch 99/120\n",
            "36/36 [==============================] - 5s 127ms/step - loss: 0.0018\n",
            "Epoch 100/120\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.0018\n",
            "Epoch 101/120\n",
            "36/36 [==============================] - 4s 108ms/step - loss: 0.0019\n",
            "Epoch 102/120\n",
            "36/36 [==============================] - 5s 126ms/step - loss: 0.0019\n",
            "Epoch 103/120\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0019\n",
            "Epoch 104/120\n",
            "36/36 [==============================] - 4s 108ms/step - loss: 0.0019\n",
            "Epoch 105/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0017\n",
            "Epoch 106/120\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0018\n",
            "Epoch 107/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0018\n",
            "Epoch 108/120\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 0.0018\n",
            "Epoch 109/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0018\n",
            "Epoch 110/120\n",
            "36/36 [==============================] - 4s 122ms/step - loss: 0.0018\n",
            "Epoch 111/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0018\n",
            "Epoch 112/120\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.0018\n",
            "Epoch 113/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0018\n",
            "Epoch 114/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0019\n",
            "Epoch 115/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0018\n",
            "Epoch 116/120\n",
            "36/36 [==============================] - 4s 122ms/step - loss: 0.0017\n",
            "Epoch 117/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0017\n",
            "Epoch 118/120\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 0.0017\n",
            "Epoch 119/120\n",
            "36/36 [==============================] - 5s 138ms/step - loss: 0.0017\n",
            "Epoch 120/120\n",
            "36/36 [==============================] - 4s 111ms/step - loss: 0.0017\n",
            "48/48 [==============================] - 2s 16ms/step\n",
            "Epoch 1/120\n",
            "36/36 [==============================] - 16s 109ms/step - loss: 0.0144\n",
            "Epoch 2/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0044\n",
            "Epoch 3/120\n",
            "36/36 [==============================] - 3s 96ms/step - loss: 0.0038\n",
            "Epoch 4/120\n",
            "36/36 [==============================] - 3s 94ms/step - loss: 0.0037\n",
            "Epoch 5/120\n",
            "36/36 [==============================] - 4s 116ms/step - loss: 0.0037\n",
            "Epoch 6/120\n",
            "36/36 [==============================] - 3s 95ms/step - loss: 0.0036\n",
            "Epoch 7/120\n",
            "36/36 [==============================] - 3s 95ms/step - loss: 0.0031\n",
            "Epoch 8/120\n",
            "36/36 [==============================] - 5s 139ms/step - loss: 0.0030\n",
            "Epoch 9/120\n",
            "36/36 [==============================] - 3s 96ms/step - loss: 0.0030\n",
            "Epoch 10/120\n",
            "36/36 [==============================] - 3s 94ms/step - loss: 0.0029\n",
            "Epoch 11/120\n",
            "36/36 [==============================] - 4s 114ms/step - loss: 0.0029\n",
            "Epoch 12/120\n",
            "36/36 [==============================] - 3s 96ms/step - loss: 0.0029\n",
            "Epoch 13/120\n",
            "36/36 [==============================] - 4s 97ms/step - loss: 0.0027\n",
            "Epoch 14/120\n",
            "36/36 [==============================] - 4s 115ms/step - loss: 0.0027\n",
            "Epoch 15/120\n",
            "36/36 [==============================] - 3s 95ms/step - loss: 0.0027\n",
            "Epoch 16/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0027\n",
            "Epoch 17/120\n",
            "36/36 [==============================] - 4s 114ms/step - loss: 0.0027\n",
            "Epoch 18/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0026\n",
            "Epoch 19/120\n",
            "36/36 [==============================] - 3s 96ms/step - loss: 0.0025\n",
            "Epoch 20/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0025\n",
            "Epoch 21/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0025\n",
            "Epoch 22/120\n",
            "36/36 [==============================] - 4s 97ms/step - loss: 0.0024\n",
            "Epoch 23/120\n",
            "36/36 [==============================] - 3s 96ms/step - loss: 0.0024\n",
            "Epoch 24/120\n",
            "36/36 [==============================] - 4s 117ms/step - loss: 0.0024\n",
            "Epoch 25/120\n",
            "36/36 [==============================] - 4s 98ms/step - loss: 0.0024\n",
            "Epoch 26/120\n",
            "36/36 [==============================] - 4s 97ms/step - loss: 0.0024\n",
            "Epoch 27/120\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 0.0024\n",
            "Epoch 28/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0025\n",
            "Epoch 29/120\n",
            "36/36 [==============================] - 3s 96ms/step - loss: 0.0025\n",
            "Epoch 30/120\n",
            "36/36 [==============================] - 4s 118ms/step - loss: 0.0024\n",
            "Epoch 31/120\n",
            "36/36 [==============================] - 3s 97ms/step - loss: 0.0023\n",
            "Epoch 32/120\n",
            "36/36 [==============================] - 3s 97ms/step - loss: 0.0023\n",
            "Epoch 33/120\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 0.0024\n",
            "Epoch 34/120\n",
            "36/36 [==============================] - 4s 98ms/step - loss: 0.0026\n",
            "Epoch 35/120\n",
            "36/36 [==============================] - 4s 98ms/step - loss: 0.0025\n",
            "Epoch 36/120\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 0.0022\n",
            "Epoch 37/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0023\n",
            "Epoch 38/120\n",
            "36/36 [==============================] - 4s 97ms/step - loss: 0.0023\n",
            "Epoch 39/120\n",
            "36/36 [==============================] - 4s 114ms/step - loss: 0.0023\n",
            "Epoch 40/120\n",
            "36/36 [==============================] - 4s 98ms/step - loss: 0.0023\n",
            "Epoch 41/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0024\n",
            "Epoch 42/120\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.0023\n",
            "Epoch 43/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0022\n",
            "Epoch 44/120\n",
            "36/36 [==============================] - 3s 96ms/step - loss: 0.0023\n",
            "Epoch 45/120\n",
            "36/36 [==============================] - 4s 97ms/step - loss: 0.0021\n",
            "Epoch 46/120\n",
            "36/36 [==============================] - 4s 115ms/step - loss: 0.0023\n",
            "Epoch 47/120\n",
            "36/36 [==============================] - 3s 94ms/step - loss: 0.0022\n",
            "Epoch 48/120\n",
            "36/36 [==============================] - 3s 95ms/step - loss: 0.0021\n",
            "Epoch 49/120\n",
            "36/36 [==============================] - 4s 117ms/step - loss: 0.0021\n",
            "Epoch 50/120\n",
            "36/36 [==============================] - 3s 96ms/step - loss: 0.0023\n",
            "Epoch 51/120\n",
            "36/36 [==============================] - 3s 95ms/step - loss: 0.0021\n",
            "Epoch 52/120\n",
            "36/36 [==============================] - 4s 118ms/step - loss: 0.0021\n",
            "Epoch 53/120\n",
            "36/36 [==============================] - 3s 97ms/step - loss: 0.0023\n",
            "Epoch 54/120\n",
            "36/36 [==============================] - 3s 96ms/step - loss: 0.0022\n",
            "Epoch 55/120\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 0.0021\n",
            "Epoch 56/120\n",
            "36/36 [==============================] - 3s 97ms/step - loss: 0.0021\n",
            "Epoch 57/120\n",
            "36/36 [==============================] - 3s 96ms/step - loss: 0.0022\n",
            "Epoch 58/120\n",
            "36/36 [==============================] - 4s 117ms/step - loss: 0.0021\n",
            "Epoch 59/120\n",
            "36/36 [==============================] - 4s 97ms/step - loss: 0.0020\n",
            "Epoch 60/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0020\n",
            "Epoch 61/120\n",
            "36/36 [==============================] - 4s 116ms/step - loss: 0.0022\n",
            "Epoch 62/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0021\n",
            "Epoch 63/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0020\n",
            "Epoch 64/120\n",
            "36/36 [==============================] - 4s 111ms/step - loss: 0.0021\n",
            "Epoch 65/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0021\n",
            "Epoch 66/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0022\n",
            "Epoch 67/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0019\n",
            "Epoch 68/120\n",
            "36/36 [==============================] - 4s 122ms/step - loss: 0.0020\n",
            "Epoch 69/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0020\n",
            "Epoch 70/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0020\n",
            "Epoch 71/120\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 0.0019\n",
            "Epoch 72/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0021\n",
            "Epoch 73/120\n",
            "36/36 [==============================] - 4s 98ms/step - loss: 0.0020\n",
            "Epoch 74/120\n",
            "36/36 [==============================] - 4s 124ms/step - loss: 0.0019\n",
            "Epoch 75/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0020\n",
            "Epoch 76/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0021\n",
            "Epoch 77/120\n",
            "36/36 [==============================] - 5s 143ms/step - loss: 0.0020\n",
            "Epoch 78/120\n",
            "36/36 [==============================] - 3s 96ms/step - loss: 0.0019\n",
            "Epoch 79/120\n",
            "36/36 [==============================] - 3s 95ms/step - loss: 0.0022\n",
            "Epoch 80/120\n",
            "36/36 [==============================] - 4s 115ms/step - loss: 0.0020\n",
            "Epoch 81/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0020\n",
            "Epoch 82/120\n",
            "36/36 [==============================] - 3s 97ms/step - loss: 0.0020\n",
            "Epoch 83/120\n",
            "36/36 [==============================] - 4s 113ms/step - loss: 0.0022\n",
            "Epoch 84/120\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 0.0020\n",
            "Epoch 85/120\n",
            "36/36 [==============================] - 4s 97ms/step - loss: 0.0020\n",
            "Epoch 86/120\n",
            "36/36 [==============================] - 4s 98ms/step - loss: 0.0019\n",
            "Epoch 87/120\n",
            "36/36 [==============================] - 4s 117ms/step - loss: 0.0019\n",
            "Epoch 88/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0019\n",
            "Epoch 89/120\n",
            "36/36 [==============================] - 3s 95ms/step - loss: 0.0019\n",
            "Epoch 90/120\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 0.0019\n",
            "Epoch 91/120\n",
            "36/36 [==============================] - 4s 98ms/step - loss: 0.0018\n",
            "Epoch 92/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0019\n",
            "Epoch 93/120\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 0.0019\n",
            "Epoch 94/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0019\n",
            "Epoch 95/120\n",
            "36/36 [==============================] - 4s 98ms/step - loss: 0.0018\n",
            "Epoch 96/120\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 0.0019\n",
            "Epoch 97/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0018\n",
            "Epoch 98/120\n",
            "36/36 [==============================] - 3s 97ms/step - loss: 0.0019\n",
            "Epoch 99/120\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 0.0019\n",
            "Epoch 100/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0019\n",
            "Epoch 101/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0018\n",
            "Epoch 102/120\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 0.0018\n",
            "Epoch 103/120\n",
            "36/36 [==============================] - 4s 98ms/step - loss: 0.0019\n",
            "Epoch 104/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0018\n",
            "Epoch 105/120\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 0.0019\n",
            "Epoch 106/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0019\n",
            "Epoch 107/120\n",
            "36/36 [==============================] - 4s 98ms/step - loss: 0.0018\n",
            "Epoch 108/120\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 0.0018\n",
            "Epoch 109/120\n",
            "36/36 [==============================] - 3s 97ms/step - loss: 0.0019\n",
            "Epoch 110/120\n",
            "36/36 [==============================] - 3s 95ms/step - loss: 0.0020\n",
            "Epoch 111/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0017\n",
            "Epoch 112/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0018\n",
            "Epoch 113/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0018\n",
            "Epoch 114/120\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.0017\n",
            "Epoch 115/120\n",
            "36/36 [==============================] - 4s 113ms/step - loss: 0.0017\n",
            "Epoch 116/120\n",
            "36/36 [==============================] - 4s 98ms/step - loss: 0.0019\n",
            "Epoch 117/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0017\n",
            "Epoch 118/120\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 0.0017\n",
            "Epoch 119/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0019\n",
            "Epoch 120/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0018\n",
            "48/48 [==============================] - 2s 14ms/step\n",
            "Epoch 1/120\n",
            "36/36 [==============================] - 14s 95ms/step - loss: 0.0142\n",
            "Epoch 2/120\n",
            "36/36 [==============================] - 4s 113ms/step - loss: 0.0048\n",
            "Epoch 3/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0041\n",
            "Epoch 4/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0039\n",
            "Epoch 5/120\n",
            "36/36 [==============================] - 4s 111ms/step - loss: 0.0033\n",
            "Epoch 6/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0035\n",
            "Epoch 7/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0032\n",
            "Epoch 8/120\n",
            "36/36 [==============================] - 3s 94ms/step - loss: 0.0029\n",
            "Epoch 9/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0031\n",
            "Epoch 10/120\n",
            "36/36 [==============================] - 4s 114ms/step - loss: 0.0029\n",
            "Epoch 11/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0031\n",
            "Epoch 12/120\n",
            "36/36 [==============================] - 4s 115ms/step - loss: 0.0029\n",
            "Epoch 13/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0029\n",
            "Epoch 14/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0027\n",
            "Epoch 15/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0026\n",
            "Epoch 16/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0026\n",
            "Epoch 17/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0026\n",
            "Epoch 18/120\n",
            "36/36 [==============================] - 3s 95ms/step - loss: 0.0026\n",
            "Epoch 19/120\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 0.0026\n",
            "Epoch 20/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0025\n",
            "Epoch 21/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0026\n",
            "Epoch 22/120\n",
            "36/36 [==============================] - 4s 114ms/step - loss: 0.0025\n",
            "Epoch 23/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0024\n",
            "Epoch 24/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0024\n",
            "Epoch 25/120\n",
            "36/36 [==============================] - 4s 113ms/step - loss: 0.0025\n",
            "Epoch 26/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0024\n",
            "Epoch 27/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0024\n",
            "Epoch 28/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0025\n",
            "Epoch 29/120\n",
            "36/36 [==============================] - 4s 114ms/step - loss: 0.0023\n",
            "Epoch 30/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0023\n",
            "Epoch 31/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0025\n",
            "Epoch 32/120\n",
            "36/36 [==============================] - 4s 112ms/step - loss: 0.0024\n",
            "Epoch 33/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0023\n",
            "Epoch 34/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0023\n",
            "Epoch 35/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0023\n",
            "Epoch 36/120\n",
            "36/36 [==============================] - 4s 98ms/step - loss: 0.0023\n",
            "Epoch 37/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0025\n",
            "Epoch 38/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0024\n",
            "Epoch 39/120\n",
            "36/36 [==============================] - 4s 112ms/step - loss: 0.0023\n",
            "Epoch 40/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0023\n",
            "Epoch 41/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0022\n",
            "Epoch 42/120\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.0022\n",
            "Epoch 43/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0021\n",
            "Epoch 44/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0022\n",
            "Epoch 45/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0025\n",
            "Epoch 46/120\n",
            "36/36 [==============================] - 4s 111ms/step - loss: 0.0022\n",
            "Epoch 47/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0022\n",
            "Epoch 48/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 49/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0021\n",
            "Epoch 50/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0021\n",
            "Epoch 51/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0022\n",
            "Epoch 52/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0021\n",
            "Epoch 53/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0021\n",
            "Epoch 54/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0022\n",
            "Epoch 55/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0020\n",
            "Epoch 56/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0026\n",
            "Epoch 57/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0022\n",
            "Epoch 58/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0020\n",
            "Epoch 59/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0021\n",
            "Epoch 60/120\n",
            "36/36 [==============================] - 4s 111ms/step - loss: 0.0021\n",
            "Epoch 61/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0021\n",
            "Epoch 62/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0020\n",
            "Epoch 63/120\n",
            "36/36 [==============================] - 4s 113ms/step - loss: 0.0021\n",
            "Epoch 64/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0021\n",
            "Epoch 65/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0022\n",
            "Epoch 66/120\n",
            "36/36 [==============================] - 4s 98ms/step - loss: 0.0020\n",
            "Epoch 67/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0020\n",
            "Epoch 68/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0021\n",
            "Epoch 69/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0020\n",
            "Epoch 70/120\n",
            "36/36 [==============================] - 4s 113ms/step - loss: 0.0020\n",
            "Epoch 71/120\n",
            "36/36 [==============================] - 4s 113ms/step - loss: 0.0020\n",
            "Epoch 72/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0020\n",
            "Epoch 73/120\n",
            "36/36 [==============================] - 4s 112ms/step - loss: 0.0021\n",
            "Epoch 74/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0021\n",
            "Epoch 75/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0019\n",
            "Epoch 76/120\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0020\n",
            "Epoch 77/120\n",
            "36/36 [==============================] - 4s 96ms/step - loss: 0.0019\n",
            "Epoch 78/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0020\n",
            "Epoch 79/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0020\n",
            "Epoch 80/120\n",
            "36/36 [==============================] - 4s 112ms/step - loss: 0.0020\n",
            "Epoch 81/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0019\n",
            "Epoch 82/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0019\n",
            "Epoch 83/120\n",
            "36/36 [==============================] - 4s 112ms/step - loss: 0.0020\n",
            "Epoch 84/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0020\n",
            "Epoch 85/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0019\n",
            "Epoch 86/120\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0019\n",
            "Epoch 87/120\n",
            "36/36 [==============================] - 4s 96ms/step - loss: 0.0019\n",
            "Epoch 88/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0019\n",
            "Epoch 89/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0019\n",
            "Epoch 90/120\n",
            "36/36 [==============================] - 4s 112ms/step - loss: 0.0020\n",
            "Epoch 91/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0019\n",
            "Epoch 92/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0018\n",
            "Epoch 93/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0024\n",
            "Epoch 94/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0023\n",
            "Epoch 95/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0022\n",
            "Epoch 96/120\n",
            "36/36 [==============================] - 3s 95ms/step - loss: 0.0020\n",
            "Epoch 97/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0019\n",
            "Epoch 98/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0019\n",
            "Epoch 99/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0021\n",
            "Epoch 100/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0019\n",
            "Epoch 101/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0020\n",
            "Epoch 102/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0019\n",
            "Epoch 103/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0019\n",
            "Epoch 104/120\n",
            "36/36 [==============================] - 3s 96ms/step - loss: 0.0019\n",
            "Epoch 105/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0019\n",
            "Epoch 106/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0018\n",
            "Epoch 107/120\n",
            "36/36 [==============================] - 4s 114ms/step - loss: 0.0018\n",
            "Epoch 108/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0019\n",
            "Epoch 109/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0019\n",
            "Epoch 110/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0018\n",
            "Epoch 111/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0018\n",
            "Epoch 112/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0019\n",
            "Epoch 113/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0019\n",
            "Epoch 114/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0018\n",
            "Epoch 115/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0018\n",
            "Epoch 116/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0019\n",
            "Epoch 117/120\n",
            "36/36 [==============================] - 4s 114ms/step - loss: 0.0019\n",
            "Epoch 118/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0018\n",
            "Epoch 119/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0017\n",
            "Epoch 120/120\n",
            "36/36 [==============================] - 4s 108ms/step - loss: 0.0017\n",
            "48/48 [==============================] - 2s 14ms/step\n",
            "Epoch 1/120\n",
            "36/36 [==============================] - 15s 89ms/step - loss: 0.0140\n",
            "Epoch 2/120\n",
            "36/36 [==============================] - 3s 96ms/step - loss: 0.0048\n",
            "Epoch 3/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0037\n",
            "Epoch 4/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0036\n",
            "Epoch 5/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0036\n",
            "Epoch 6/120\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0035\n",
            "Epoch 7/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0030\n",
            "Epoch 8/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0030\n",
            "Epoch 9/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0031\n",
            "Epoch 10/120\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.0029\n",
            "Epoch 11/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0031\n",
            "Epoch 12/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0028\n",
            "Epoch 13/120\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0030\n",
            "Epoch 14/120\n",
            "36/36 [==============================] - 4s 108ms/step - loss: 0.0028\n",
            "Epoch 15/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0026\n",
            "Epoch 16/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0027\n",
            "Epoch 17/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0026\n",
            "Epoch 18/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0027\n",
            "Epoch 19/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0025\n",
            "Epoch 20/120\n",
            "36/36 [==============================] - 4s 108ms/step - loss: 0.0027\n",
            "Epoch 21/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0027\n",
            "Epoch 22/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0024\n",
            "Epoch 23/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0026\n",
            "Epoch 24/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0027\n",
            "Epoch 25/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0024\n",
            "Epoch 26/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0023\n",
            "Epoch 27/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0025\n",
            "Epoch 28/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0025\n",
            "Epoch 29/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0028\n",
            "Epoch 30/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0025\n",
            "Epoch 31/120\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 0.0026\n",
            "Epoch 32/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0023\n",
            "Epoch 33/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0025\n",
            "Epoch 34/120\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.0023\n",
            "Epoch 35/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0023\n",
            "Epoch 36/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0023\n",
            "Epoch 37/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0024\n",
            "Epoch 38/120\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0023\n",
            "Epoch 39/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0024\n",
            "Epoch 40/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0023\n",
            "Epoch 41/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0023\n",
            "Epoch 42/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0024\n",
            "Epoch 43/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0023\n",
            "Epoch 44/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0023\n",
            "Epoch 45/120\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0022\n",
            "Epoch 46/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0021\n",
            "Epoch 47/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 48/120\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 0.0022\n",
            "Epoch 49/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0023\n",
            "Epoch 50/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0024\n",
            "Epoch 51/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0021\n",
            "Epoch 52/120\n",
            "36/36 [==============================] - 4s 108ms/step - loss: 0.0022\n",
            "Epoch 53/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0021\n",
            "Epoch 54/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0021\n",
            "Epoch 55/120\n",
            "36/36 [==============================] - 3s 97ms/step - loss: 0.0021\n",
            "Epoch 56/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0021\n",
            "Epoch 57/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 58/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0022\n",
            "Epoch 59/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0021\n",
            "Epoch 60/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0021\n",
            "Epoch 61/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0021\n",
            "Epoch 62/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0023\n",
            "Epoch 63/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0020\n",
            "Epoch 64/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0021\n",
            "Epoch 65/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0021\n",
            "Epoch 66/120\n",
            "36/36 [==============================] - 4s 108ms/step - loss: 0.0021\n",
            "Epoch 67/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0020\n",
            "Epoch 68/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0020\n",
            "Epoch 69/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0020\n",
            "Epoch 70/120\n",
            "36/36 [==============================] - 4s 97ms/step - loss: 0.0021\n",
            "Epoch 71/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0020\n",
            "Epoch 72/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 73/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0021\n",
            "Epoch 74/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0020\n",
            "Epoch 75/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0020\n",
            "Epoch 76/120\n",
            "36/36 [==============================] - 3s 95ms/step - loss: 0.0019\n",
            "Epoch 77/120\n",
            "36/36 [==============================] - 4s 97ms/step - loss: 0.0019\n",
            "Epoch 78/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0019\n",
            "Epoch 79/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0020\n",
            "Epoch 80/120\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.0019\n",
            "Epoch 81/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0020\n",
            "Epoch 82/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0020\n",
            "Epoch 83/120\n",
            "36/36 [==============================] - 4s 98ms/step - loss: 0.0019\n",
            "Epoch 84/120\n",
            "36/36 [==============================] - 3s 95ms/step - loss: 0.0020\n",
            "Epoch 85/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0020\n",
            "Epoch 86/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0020\n",
            "Epoch 87/120\n",
            "36/36 [==============================] - 4s 108ms/step - loss: 0.0019\n",
            "Epoch 88/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 89/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0019\n",
            "Epoch 90/120\n",
            "36/36 [==============================] - 3s 94ms/step - loss: 0.0020\n",
            "Epoch 91/120\n",
            "36/36 [==============================] - 5s 125ms/step - loss: 0.0019\n",
            "Epoch 92/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0020\n",
            "Epoch 93/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0019\n",
            "Epoch 94/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0019\n",
            "Epoch 95/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0019\n",
            "Epoch 96/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0020\n",
            "Epoch 97/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0020\n",
            "Epoch 98/120\n",
            "36/36 [==============================] - 3s 94ms/step - loss: 0.0019\n",
            "Epoch 99/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0019\n",
            "Epoch 100/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0019\n",
            "Epoch 101/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0019\n",
            "Epoch 102/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0019\n",
            "Epoch 103/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0019\n",
            "Epoch 104/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0019\n",
            "Epoch 105/120\n",
            "36/36 [==============================] - 4s 97ms/step - loss: 0.0018\n",
            "Epoch 106/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0018\n",
            "Epoch 107/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0017\n",
            "Epoch 108/120\n",
            "36/36 [==============================] - 4s 108ms/step - loss: 0.0018\n",
            "Epoch 109/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0017\n",
            "Epoch 110/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0018\n",
            "Epoch 111/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0017\n",
            "Epoch 112/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0018\n",
            "Epoch 113/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0018\n",
            "Epoch 114/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0018\n",
            "Epoch 115/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0018\n",
            "Epoch 116/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0018\n",
            "Epoch 117/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0017\n",
            "Epoch 118/120\n",
            "36/36 [==============================] - 4s 108ms/step - loss: 0.0018\n",
            "Epoch 119/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0017\n",
            "Epoch 120/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0018\n",
            "48/48 [==============================] - 2s 14ms/step\n",
            "Epoch 1/120\n",
            "36/36 [==============================] - 15s 108ms/step - loss: 0.0127\n",
            "Epoch 2/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0052\n",
            "Epoch 3/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0039\n",
            "Epoch 4/120\n",
            "36/36 [==============================] - 3s 94ms/step - loss: 0.0041\n",
            "Epoch 5/120\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 0.0039\n",
            "Epoch 6/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0034\n",
            "Epoch 7/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0033\n",
            "Epoch 8/120\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0031\n",
            "Epoch 9/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0030\n",
            "Epoch 10/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0030\n",
            "Epoch 11/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0029\n",
            "Epoch 12/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0030\n",
            "Epoch 13/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0030\n",
            "Epoch 14/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0028\n",
            "Epoch 15/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0027\n",
            "Epoch 16/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0027\n",
            "Epoch 17/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0028\n",
            "Epoch 18/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0026\n",
            "Epoch 19/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0026\n",
            "Epoch 20/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0026\n",
            "Epoch 21/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0026\n",
            "Epoch 22/120\n",
            "36/36 [==============================] - 4s 108ms/step - loss: 0.0024\n",
            "Epoch 23/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0024\n",
            "Epoch 24/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0027\n",
            "Epoch 25/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0027\n",
            "Epoch 26/120\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.0025\n",
            "Epoch 27/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0025\n",
            "Epoch 28/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0025\n",
            "Epoch 29/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0025\n",
            "Epoch 30/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0026\n",
            "Epoch 31/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0025\n",
            "Epoch 32/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0024\n",
            "Epoch 33/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0025\n",
            "Epoch 34/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0023\n",
            "Epoch 35/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0023\n",
            "Epoch 36/120\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 0.0022\n",
            "Epoch 37/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0023\n",
            "Epoch 38/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0024\n",
            "Epoch 39/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0024\n",
            "Epoch 40/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0023\n",
            "Epoch 41/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0022\n",
            "Epoch 42/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 43/120\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 0.0022\n",
            "Epoch 44/120\n",
            "36/36 [==============================] - 4s 97ms/step - loss: 0.0022\n",
            "Epoch 45/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0022\n",
            "Epoch 46/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 47/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0023\n",
            "Epoch 48/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0021\n",
            "Epoch 49/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0021\n",
            "Epoch 50/120\n",
            "36/36 [==============================] - 3s 95ms/step - loss: 0.0022\n",
            "Epoch 51/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0022\n",
            "Epoch 52/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0023\n",
            "Epoch 53/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0022\n",
            "Epoch 54/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0023\n",
            "Epoch 55/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0021\n",
            "Epoch 56/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0021\n",
            "Epoch 57/120\n",
            "36/36 [==============================] - 3s 95ms/step - loss: 0.0022\n",
            "Epoch 58/120\n",
            "36/36 [==============================] - 4s 122ms/step - loss: 0.0022\n",
            "Epoch 59/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0021\n",
            "Epoch 60/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0022\n",
            "Epoch 61/120\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0021\n",
            "Epoch 62/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0022\n",
            "Epoch 63/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0021\n",
            "Epoch 64/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0021\n",
            "Epoch 65/120\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 0.0022\n",
            "Epoch 66/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 67/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0020\n",
            "Epoch 68/120\n",
            "36/36 [==============================] - 4s 108ms/step - loss: 0.0021\n",
            "Epoch 69/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0020\n",
            "Epoch 70/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0020\n",
            "Epoch 71/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0022\n",
            "Epoch 72/120\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.0020\n",
            "Epoch 73/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0019\n",
            "Epoch 74/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0021\n",
            "Epoch 75/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0021\n",
            "Epoch 76/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0022\n",
            "Epoch 77/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0020\n",
            "Epoch 78/120\n",
            "36/36 [==============================] - 3s 95ms/step - loss: 0.0020\n",
            "Epoch 79/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0022\n",
            "Epoch 80/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0020\n",
            "Epoch 81/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0022\n",
            "Epoch 82/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0021\n",
            "Epoch 83/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0021\n",
            "Epoch 84/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0020\n",
            "Epoch 85/120\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 0.0020\n",
            "Epoch 86/120\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 0.0019\n",
            "Epoch 87/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0020\n",
            "Epoch 88/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0020\n",
            "Epoch 89/120\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0020\n",
            "Epoch 90/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0021\n",
            "Epoch 91/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0020\n",
            "Epoch 92/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0021\n",
            "Epoch 93/120\n",
            "36/36 [==============================] - 4s 108ms/step - loss: 0.0019\n",
            "Epoch 94/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0019\n",
            "Epoch 95/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0019\n",
            "Epoch 96/120\n",
            "36/36 [==============================] - 4s 111ms/step - loss: 0.0022\n",
            "Epoch 97/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0020\n",
            "Epoch 98/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0019\n",
            "Epoch 99/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0020\n",
            "Epoch 100/120\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.0018\n",
            "Epoch 101/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0019\n",
            "Epoch 102/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0020\n",
            "Epoch 103/120\n",
            "36/36 [==============================] - 4s 112ms/step - loss: 0.0020\n",
            "Epoch 104/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0019\n",
            "Epoch 105/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0018\n",
            "Epoch 106/120\n",
            "36/36 [==============================] - 4s 98ms/step - loss: 0.0019\n",
            "Epoch 107/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0029\n",
            "Epoch 108/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0025\n",
            "Epoch 109/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0020\n",
            "Epoch 110/120\n",
            "36/36 [==============================] - 4s 111ms/step - loss: 0.0019\n",
            "Epoch 111/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0019\n",
            "Epoch 112/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0019\n",
            "Epoch 113/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0022\n",
            "Epoch 114/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0020\n",
            "Epoch 115/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0018\n",
            "Epoch 116/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0019\n",
            "Epoch 117/120\n",
            "36/36 [==============================] - 4s 112ms/step - loss: 0.0018\n",
            "Epoch 118/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0018\n",
            "Epoch 119/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0019\n",
            "Epoch 120/120\n",
            "36/36 [==============================] - 4s 112ms/step - loss: 0.0018\n",
            "48/48 [==============================] - 2s 14ms/step\n",
            "Epoch 1/120\n",
            "36/36 [==============================] - 16s 89ms/step - loss: 0.0121\n",
            "Epoch 2/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0045\n",
            "Epoch 3/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0037\n",
            "Epoch 4/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0034\n",
            "Epoch 5/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0035\n",
            "Epoch 6/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0035\n",
            "Epoch 7/120\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 0.0034\n",
            "Epoch 8/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0032\n",
            "Epoch 9/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0030\n",
            "Epoch 10/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0028\n",
            "Epoch 11/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0027\n",
            "Epoch 12/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0029\n",
            "Epoch 13/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0027\n",
            "Epoch 14/120\n",
            "36/36 [==============================] - 3s 95ms/step - loss: 0.0029\n",
            "Epoch 15/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0028\n",
            "Epoch 16/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0028\n",
            "Epoch 17/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0026\n",
            "Epoch 18/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0026\n",
            "Epoch 19/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0024\n",
            "Epoch 20/120\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.0025\n",
            "Epoch 21/120\n",
            "36/36 [==============================] - 3s 94ms/step - loss: 0.0025\n",
            "Epoch 22/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0024\n",
            "Epoch 23/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0024\n",
            "Epoch 24/120\n",
            "36/36 [==============================] - 4s 112ms/step - loss: 0.0025\n",
            "Epoch 25/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0024\n",
            "Epoch 26/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0024\n",
            "Epoch 27/120\n",
            "36/36 [==============================] - 4s 108ms/step - loss: 0.0024\n",
            "Epoch 28/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0023\n",
            "Epoch 29/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0024\n",
            "Epoch 30/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0024\n",
            "Epoch 31/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0023\n",
            "Epoch 32/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0024\n",
            "Epoch 33/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0023\n",
            "Epoch 34/120\n",
            "36/36 [==============================] - 4s 111ms/step - loss: 0.0023\n",
            "Epoch 35/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0025\n",
            "Epoch 36/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0023\n",
            "Epoch 37/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0023\n",
            "Epoch 38/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0023\n",
            "Epoch 39/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0023\n",
            "Epoch 40/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0023\n",
            "Epoch 41/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0021\n",
            "Epoch 42/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 43/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0024\n",
            "Epoch 44/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0021\n",
            "Epoch 45/120\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.0022\n",
            "Epoch 46/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0022\n",
            "Epoch 47/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 48/120\n",
            "36/36 [==============================] - 4s 108ms/step - loss: 0.0021\n",
            "Epoch 49/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0023\n",
            "Epoch 50/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 51/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0021\n",
            "Epoch 52/120\n",
            "36/36 [==============================] - 4s 108ms/step - loss: 0.0021\n",
            "Epoch 53/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0021\n",
            "Epoch 54/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 55/120\n",
            "36/36 [==============================] - 4s 108ms/step - loss: 0.0020\n",
            "Epoch 56/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0023\n",
            "Epoch 57/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0020\n",
            "Epoch 58/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0022\n",
            "Epoch 59/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0021\n",
            "Epoch 60/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0021\n",
            "Epoch 61/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0024\n",
            "Epoch 62/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0022\n",
            "Epoch 63/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0021\n",
            "Epoch 64/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0022\n",
            "Epoch 65/120\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 0.0021\n",
            "Epoch 66/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0021\n",
            "Epoch 67/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0021\n",
            "Epoch 68/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0020\n",
            "Epoch 69/120\n",
            "36/36 [==============================] - 4s 113ms/step - loss: 0.0021\n",
            "Epoch 70/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0021\n",
            "Epoch 71/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0021\n",
            "Epoch 72/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0021\n",
            "Epoch 73/120\n",
            "36/36 [==============================] - 4s 97ms/step - loss: 0.0019\n",
            "Epoch 74/120\n",
            "36/36 [==============================] - 3s 97ms/step - loss: 0.0020\n",
            "Epoch 75/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0020\n",
            "Epoch 76/120\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.0021\n",
            "Epoch 77/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0021\n",
            "Epoch 78/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0019\n",
            "Epoch 79/120\n",
            "36/36 [==============================] - 4s 111ms/step - loss: 0.0019\n",
            "Epoch 80/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0020\n",
            "Epoch 81/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0020\n",
            "Epoch 82/120\n",
            "36/36 [==============================] - 3s 96ms/step - loss: 0.0019\n",
            "Epoch 83/120\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0019\n",
            "Epoch 84/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0020\n",
            "Epoch 85/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0019\n",
            "Epoch 86/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0019\n",
            "Epoch 87/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0020\n",
            "Epoch 88/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0019\n",
            "Epoch 89/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0020\n",
            "Epoch 90/120\n",
            "36/36 [==============================] - 3s 94ms/step - loss: 0.0020\n",
            "Epoch 91/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0019\n",
            "Epoch 92/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0019\n",
            "Epoch 93/120\n",
            "36/36 [==============================] - 4s 111ms/step - loss: 0.0019\n",
            "Epoch 94/120\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 0.0019\n",
            "Epoch 95/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0019\n",
            "Epoch 96/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0018\n",
            "Epoch 97/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0020\n",
            "Epoch 98/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0019\n",
            "Epoch 99/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0022\n",
            "Epoch 100/120\n",
            "36/36 [==============================] - 4s 113ms/step - loss: 0.0018\n",
            "Epoch 101/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0019\n",
            "Epoch 102/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0018\n",
            "Epoch 103/120\n",
            "36/36 [==============================] - 4s 111ms/step - loss: 0.0018\n",
            "Epoch 104/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0019\n",
            "Epoch 105/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0018\n",
            "Epoch 106/120\n",
            "36/36 [==============================] - 4s 98ms/step - loss: 0.0019\n",
            "Epoch 107/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0018\n",
            "Epoch 108/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0018\n",
            "Epoch 109/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0018\n",
            "Epoch 110/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0019\n",
            "Epoch 111/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0018\n",
            "Epoch 112/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0017\n",
            "Epoch 113/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0018\n",
            "Epoch 114/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0018\n",
            "Epoch 115/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0018\n",
            "Epoch 116/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0017\n",
            "Epoch 117/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0018\n",
            "Epoch 118/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0017\n",
            "Epoch 119/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0017\n",
            "Epoch 120/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0019\n",
            "48/48 [==============================] - 2s 15ms/step\n",
            "Epoch 1/120\n",
            "36/36 [==============================] - 14s 91ms/step - loss: 0.0143\n",
            "Epoch 2/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0046\n",
            "Epoch 3/120\n",
            "36/36 [==============================] - 4s 112ms/step - loss: 0.0039\n",
            "Epoch 4/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0034\n",
            "Epoch 5/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0033\n",
            "Epoch 6/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0035\n",
            "Epoch 7/120\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 0.0035\n",
            "Epoch 8/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0029\n",
            "Epoch 9/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0032\n",
            "Epoch 10/120\n",
            "36/36 [==============================] - 4s 111ms/step - loss: 0.0029\n",
            "Epoch 11/120\n",
            "36/36 [==============================] - 3s 97ms/step - loss: 0.0029\n",
            "Epoch 12/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0028\n",
            "Epoch 13/120\n",
            "36/36 [==============================] - 4s 111ms/step - loss: 0.0028\n",
            "Epoch 14/120\n",
            "36/36 [==============================] - 4s 112ms/step - loss: 0.0027\n",
            "Epoch 15/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0027\n",
            "Epoch 16/120\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.0029\n",
            "Epoch 17/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0028\n",
            "Epoch 18/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0025\n",
            "Epoch 19/120\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 0.0026\n",
            "Epoch 20/120\n",
            "36/36 [==============================] - 4s 111ms/step - loss: 0.0026\n",
            "Epoch 21/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0024\n",
            "Epoch 22/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0024\n",
            "Epoch 23/120\n",
            "36/36 [==============================] - 4s 113ms/step - loss: 0.0025\n",
            "Epoch 24/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0024\n",
            "Epoch 25/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0026\n",
            "Epoch 26/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0025\n",
            "Epoch 27/120\n",
            "36/36 [==============================] - 4s 97ms/step - loss: 0.0025\n",
            "Epoch 28/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0025\n",
            "Epoch 29/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0024\n",
            "Epoch 30/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0023\n",
            "Epoch 31/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0023\n",
            "Epoch 32/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0024\n",
            "Epoch 33/120\n",
            "36/36 [==============================] - 4s 111ms/step - loss: 0.0023\n",
            "Epoch 34/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0023\n",
            "Epoch 35/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0023\n",
            "Epoch 36/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0023\n",
            "Epoch 37/120\n",
            "36/36 [==============================] - 4s 111ms/step - loss: 0.0022\n",
            "Epoch 38/120\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 0.0024\n",
            "Epoch 39/120\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 0.0022\n",
            "Epoch 40/120\n",
            "36/36 [==============================] - 4s 113ms/step - loss: 0.0022\n",
            "Epoch 41/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0022\n",
            "Epoch 42/120\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 0.0022\n",
            "Epoch 43/120\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.0023\n",
            "Epoch 44/120\n",
            "36/36 [==============================] - 4s 96ms/step - loss: 0.0025\n",
            "Epoch 45/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0021\n",
            "Epoch 46/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0022\n",
            "Epoch 47/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0022\n",
            "Epoch 48/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0022\n",
            "Epoch 49/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0022\n",
            "Epoch 50/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0022\n",
            "Epoch 51/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0021\n",
            "Epoch 52/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0021\n",
            "Epoch 53/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0022\n",
            "Epoch 54/120\n",
            "36/36 [==============================] - 4s 111ms/step - loss: 0.0022\n",
            "Epoch 55/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0022\n",
            "Epoch 56/120\n",
            "36/36 [==============================] - 3s 94ms/step - loss: 0.0020\n",
            "Epoch 57/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0022\n",
            "Epoch 58/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0020\n",
            "Epoch 59/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0021\n",
            "Epoch 60/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0020\n",
            "Epoch 61/120\n",
            "36/36 [==============================] - 4s 112ms/step - loss: 0.0021\n",
            "Epoch 62/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0021\n",
            "Epoch 63/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0020\n",
            "Epoch 64/120\n",
            "36/36 [==============================] - 4s 111ms/step - loss: 0.0020\n",
            "Epoch 65/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0020\n",
            "Epoch 66/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0020\n",
            "Epoch 67/120\n",
            "36/36 [==============================] - 3s 97ms/step - loss: 0.0020\n",
            "Epoch 68/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0021\n",
            "Epoch 69/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0020\n",
            "Epoch 70/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0019\n",
            "Epoch 71/120\n",
            "36/36 [==============================] - 4s 111ms/step - loss: 0.0021\n",
            "Epoch 72/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0019\n",
            "Epoch 73/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0020\n",
            "Epoch 74/120\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0020\n",
            "Epoch 75/120\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 0.0020\n",
            "Epoch 76/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0020\n",
            "Epoch 77/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0020\n",
            "Epoch 78/120\n",
            "36/36 [==============================] - 4s 111ms/step - loss: 0.0019\n",
            "Epoch 79/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0020\n",
            "Epoch 80/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0021\n",
            "Epoch 81/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0020\n",
            "Epoch 82/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0020\n",
            "Epoch 83/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0019\n",
            "Epoch 84/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0021\n",
            "Epoch 85/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0019\n",
            "Epoch 86/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0019\n",
            "Epoch 87/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0019\n",
            "Epoch 88/120\n",
            "36/36 [==============================] - 4s 124ms/step - loss: 0.0021\n",
            "Epoch 89/120\n",
            "36/36 [==============================] - 4s 96ms/step - loss: 0.0019\n",
            "Epoch 90/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0019\n",
            "Epoch 91/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0020\n",
            "Epoch 92/120\n",
            "36/36 [==============================] - 3s 94ms/step - loss: 0.0019\n",
            "Epoch 93/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0018\n",
            "Epoch 94/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0018\n",
            "Epoch 95/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0019\n",
            "Epoch 96/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0019\n",
            "Epoch 97/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0019\n",
            "Epoch 98/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0019\n",
            "Epoch 99/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0018\n",
            "Epoch 100/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0018\n",
            "Epoch 101/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0018\n",
            "Epoch 102/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0018\n",
            "Epoch 103/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0020\n",
            "Epoch 104/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0018\n",
            "Epoch 105/120\n",
            "36/36 [==============================] - 4s 111ms/step - loss: 0.0018\n",
            "Epoch 106/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0018\n",
            "Epoch 107/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0018\n",
            "Epoch 108/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0019\n",
            "Epoch 109/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0019\n",
            "Epoch 110/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0017\n",
            "Epoch 111/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0018\n",
            "Epoch 112/120\n",
            "36/36 [==============================] - 4s 114ms/step - loss: 0.0017\n",
            "Epoch 113/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0018\n",
            "Epoch 114/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0018\n",
            "Epoch 115/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0019\n",
            "Epoch 116/120\n",
            "36/36 [==============================] - 4s 96ms/step - loss: 0.0019\n",
            "Epoch 117/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0017\n",
            "Epoch 118/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0017\n",
            "Epoch 119/120\n",
            "36/36 [==============================] - 4s 112ms/step - loss: 0.0018\n",
            "Epoch 120/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0018\n",
            "48/48 [==============================] - 2s 14ms/step\n",
            "Epoch 1/120\n",
            "36/36 [==============================] - 15s 97ms/step - loss: 0.0119\n",
            "Epoch 2/120\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 0.0042\n",
            "Epoch 3/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0037\n",
            "Epoch 4/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0037\n",
            "Epoch 5/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0034\n",
            "Epoch 6/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0036\n",
            "Epoch 7/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0031\n",
            "Epoch 8/120\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0030\n",
            "Epoch 9/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0031\n",
            "Epoch 10/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0028\n",
            "Epoch 11/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0030\n",
            "Epoch 12/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0030\n",
            "Epoch 13/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0030\n",
            "Epoch 14/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0026\n",
            "Epoch 15/120\n",
            "36/36 [==============================] - 4s 112ms/step - loss: 0.0026\n",
            "Epoch 16/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0027\n",
            "Epoch 17/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0025\n",
            "Epoch 18/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0025\n",
            "Epoch 19/120\n",
            "36/36 [==============================] - 4s 112ms/step - loss: 0.0026\n",
            "Epoch 20/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0025\n",
            "Epoch 21/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0026\n",
            "Epoch 22/120\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0024\n",
            "Epoch 23/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0024\n",
            "Epoch 24/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0024\n",
            "Epoch 25/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0025\n",
            "Epoch 26/120\n",
            "36/36 [==============================] - 3s 95ms/step - loss: 0.0027\n",
            "Epoch 27/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0027\n",
            "Epoch 28/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0023\n",
            "Epoch 29/120\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0024\n",
            "Epoch 30/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0024\n",
            "Epoch 31/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0024\n",
            "Epoch 32/120\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 0.0024\n",
            "Epoch 33/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0022\n",
            "Epoch 34/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0023\n",
            "Epoch 35/120\n",
            "36/36 [==============================] - 3s 95ms/step - loss: 0.0023\n",
            "Epoch 36/120\n",
            "36/36 [==============================] - 4s 98ms/step - loss: 0.0023\n",
            "Epoch 37/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0022\n",
            "Epoch 38/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 39/120\n",
            "36/36 [==============================] - 4s 117ms/step - loss: 0.0022\n",
            "Epoch 40/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0022\n",
            "Epoch 41/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 42/120\n",
            "36/36 [==============================] - 3s 95ms/step - loss: 0.0023\n",
            "Epoch 43/120\n",
            "36/36 [==============================] - 3s 95ms/step - loss: 0.0024\n",
            "Epoch 44/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0022\n",
            "Epoch 45/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0023\n",
            "Epoch 46/120\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0022\n",
            "Epoch 47/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0021\n",
            "Epoch 48/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0023\n",
            "Epoch 49/120\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0022\n",
            "Epoch 50/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 51/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0022\n",
            "Epoch 52/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0022\n",
            "Epoch 53/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0020\n",
            "Epoch 54/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0020\n",
            "Epoch 55/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0022\n",
            "Epoch 56/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0022\n",
            "Epoch 57/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0021\n",
            "Epoch 58/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0021\n",
            "Epoch 59/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0021\n",
            "Epoch 60/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0021\n",
            "Epoch 61/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0020\n",
            "Epoch 62/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0020\n",
            "Epoch 63/120\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 0.0021\n",
            "Epoch 64/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0022\n",
            "Epoch 65/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 66/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0020\n",
            "Epoch 67/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0023\n",
            "Epoch 68/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0020\n",
            "Epoch 69/120\n",
            "36/36 [==============================] - 3s 97ms/step - loss: 0.0020\n",
            "Epoch 70/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0022\n",
            "Epoch 71/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0021\n",
            "Epoch 72/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0020\n",
            "Epoch 73/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0020\n",
            "Epoch 74/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0020\n",
            "Epoch 75/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0020\n",
            "Epoch 76/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0021\n",
            "Epoch 77/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0021\n",
            "Epoch 78/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0019\n",
            "Epoch 79/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0020\n",
            "Epoch 80/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0019\n",
            "Epoch 81/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0019\n",
            "Epoch 82/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0019\n",
            "Epoch 83/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0019\n",
            "Epoch 84/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0020\n",
            "Epoch 85/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0021\n",
            "Epoch 86/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0019\n",
            "Epoch 87/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0019\n",
            "Epoch 88/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0020\n",
            "Epoch 89/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0020\n",
            "Epoch 90/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0019\n",
            "Epoch 91/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0019\n",
            "Epoch 92/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0019\n",
            "Epoch 93/120\n",
            "36/36 [==============================] - 3s 92ms/step - loss: 0.0019\n",
            "Epoch 94/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0018\n",
            "Epoch 95/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0027\n",
            "Epoch 96/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0178\n",
            "Epoch 97/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0030\n",
            "Epoch 98/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0028\n",
            "Epoch 99/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0028\n",
            "Epoch 100/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0028\n",
            "Epoch 101/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0024\n",
            "Epoch 102/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0120\n",
            "Epoch 103/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0026\n",
            "Epoch 104/120\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 0.0025\n",
            "Epoch 105/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0024\n",
            "Epoch 106/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0024\n",
            "Epoch 107/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0023\n",
            "Epoch 108/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 109/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0024\n",
            "Epoch 110/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0024\n",
            "Epoch 111/120\n",
            "36/36 [==============================] - 4s 96ms/step - loss: 0.0024\n",
            "Epoch 112/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0022\n",
            "Epoch 113/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0022\n",
            "Epoch 114/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0022\n",
            "Epoch 115/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0023\n",
            "Epoch 116/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 117/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0022\n",
            "Epoch 118/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0021\n",
            "Epoch 119/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0021\n",
            "Epoch 120/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0021\n",
            "48/48 [==============================] - 2s 18ms/step\n",
            "Epoch 1/120\n",
            "36/36 [==============================] - 17s 105ms/step - loss: 0.0136\n",
            "Epoch 2/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0046\n",
            "Epoch 3/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0039\n",
            "Epoch 4/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0038\n",
            "Epoch 5/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0036\n",
            "Epoch 6/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0032\n",
            "Epoch 7/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0033\n",
            "Epoch 8/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0032\n",
            "Epoch 9/120\n",
            "36/36 [==============================] - 3s 96ms/step - loss: 0.0031\n",
            "Epoch 10/120\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 0.0030\n",
            "Epoch 11/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0033\n",
            "Epoch 12/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0028\n",
            "Epoch 13/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0028\n",
            "Epoch 14/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0027\n",
            "Epoch 15/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0028\n",
            "Epoch 16/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0027\n",
            "Epoch 17/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0028\n",
            "Epoch 18/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0028\n",
            "Epoch 19/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0028\n",
            "Epoch 20/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0027\n",
            "Epoch 21/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0026\n",
            "Epoch 22/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0024\n",
            "Epoch 23/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0024\n",
            "Epoch 24/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0024\n",
            "Epoch 25/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0024\n",
            "Epoch 26/120\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 0.0025\n",
            "Epoch 27/120\n",
            "36/36 [==============================] - 3s 96ms/step - loss: 0.0025\n",
            "Epoch 28/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0023\n",
            "Epoch 29/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0025\n",
            "Epoch 30/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0024\n",
            "Epoch 31/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0023\n",
            "Epoch 32/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0023\n",
            "Epoch 33/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0024\n",
            "Epoch 34/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0023\n",
            "Epoch 35/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0022\n",
            "Epoch 36/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0023\n",
            "Epoch 37/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0023\n",
            "Epoch 38/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0023\n",
            "Epoch 39/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0023\n",
            "Epoch 40/120\n",
            "36/36 [==============================] - 4s 98ms/step - loss: 0.0022\n",
            "Epoch 41/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0023\n",
            "Epoch 42/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0023\n",
            "Epoch 43/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0022\n",
            "Epoch 44/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0022\n",
            "Epoch 45/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0022\n",
            "Epoch 46/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0022\n",
            "Epoch 47/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0023\n",
            "Epoch 48/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0022\n",
            "Epoch 49/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0021\n",
            "Epoch 50/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0022\n",
            "Epoch 51/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0022\n",
            "Epoch 52/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0021\n",
            "Epoch 53/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0021\n",
            "Epoch 54/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0022\n",
            "Epoch 55/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0022\n",
            "Epoch 56/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0022\n",
            "Epoch 57/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0021\n",
            "Epoch 58/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0023\n",
            "Epoch 59/120\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.0021\n",
            "Epoch 60/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0021\n",
            "Epoch 61/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0021\n",
            "Epoch 62/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0021\n",
            "Epoch 63/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0022\n",
            "Epoch 64/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0021\n",
            "Epoch 65/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0020\n",
            "Epoch 66/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0021\n",
            "Epoch 67/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0021\n",
            "Epoch 68/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0020\n",
            "Epoch 69/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0020\n",
            "Epoch 70/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0020\n",
            "Epoch 71/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0021\n",
            "Epoch 72/120\n",
            "36/36 [==============================] - 4s 98ms/step - loss: 0.0020\n",
            "Epoch 73/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0020\n",
            "Epoch 74/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0020\n",
            "Epoch 75/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0020\n",
            "Epoch 76/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0020\n",
            "Epoch 77/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0020\n",
            "Epoch 78/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0020\n",
            "Epoch 79/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0019\n",
            "Epoch 80/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0020\n",
            "Epoch 81/120\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0021\n",
            "Epoch 82/120\n",
            "36/36 [==============================] - 3s 95ms/step - loss: 0.0019\n",
            "Epoch 83/120\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0021\n",
            "Epoch 84/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0020\n",
            "Epoch 85/120\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.0019\n",
            "Epoch 86/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0019\n",
            "Epoch 87/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0019\n",
            "Epoch 88/120\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 0.0018\n",
            "Epoch 89/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0019\n",
            "Epoch 90/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0020\n",
            "Epoch 91/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0020\n",
            "Epoch 92/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0019\n",
            "Epoch 93/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0019\n",
            "Epoch 94/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0019\n",
            "Epoch 95/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0020\n",
            "Epoch 96/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0019\n",
            "Epoch 97/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0019\n",
            "Epoch 98/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0018\n",
            "Epoch 99/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0019\n",
            "Epoch 100/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0019\n",
            "Epoch 101/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0018\n",
            "Epoch 102/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0019\n",
            "Epoch 103/120\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.0018\n",
            "Epoch 104/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0018\n",
            "Epoch 105/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0019\n",
            "Epoch 106/120\n",
            "36/36 [==============================] - 4s 101ms/step - loss: 0.0019\n",
            "Epoch 107/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0019\n",
            "Epoch 108/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0018\n",
            "Epoch 109/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0018\n",
            "Epoch 110/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0017\n",
            "Epoch 111/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0017\n",
            "Epoch 112/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0018\n",
            "Epoch 113/120\n",
            "36/36 [==============================] - 3s 95ms/step - loss: 0.0020\n",
            "Epoch 114/120\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 0.0018\n",
            "Epoch 115/120\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.0017\n",
            "Epoch 116/120\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0019\n",
            "Epoch 117/120\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0018\n",
            "Epoch 118/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0018\n",
            "Epoch 119/120\n",
            "36/36 [==============================] - 4s 99ms/step - loss: 0.0017\n",
            "Epoch 120/120\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0017\n",
            "48/48 [==============================] - 2s 14ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss)"
      ],
      "metadata": {
        "id": "MnuUdKWaqgaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3025eae4-380a-47ed-d72b-eadaec38bd90"
      },
      "execution_count": 102,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.047202543693130816, 0.04615521497462063, 0.04497380087546252, 0.04655888603282882, 0.04642479040136336, 0.04525885491622969, 0.04815659098767052, 0.0469130309017858, 0.04750334753653032, 0.04558266881772735]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(min(loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56ykd7kawkvX",
        "outputId": "32a15e0a-4993-4e4d-94f5-214ee237aec9"
      },
      "execution_count": 103,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.04497380087546252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "5KwbVjdXKn01"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss)"
      ],
      "metadata": {
        "id": "O622nEj3Krt7",
        "outputId": "cd2bdec9-91a9-41e3-89be-adf5002cefa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 105,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f95c0565700>]"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD4CAYAAADo30HgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3xU9bno/8+TO7lCksk95AaJggJq5A7BolZrFfvbarWt9dYNtdu2tvXsenrO6bE9r9Nf6261e596tLZirfXWjbUFi/cLCGok3Em4hRAgzJCEBDIJIffv+WMmNAmBTEhm1lye9+vli5m11qx5JiZ5sr7f73oeMcaglFJK9QuzOgCllFL+RRODUkqpQTQxKKWUGkQTg1JKqUE0MSillBokwuoAxkNqaqrJz8+3OgyllAoomzdvPm6MsQ3dHhSJIT8/n4qKCqvDUEqpgCIih4bbrkNJSimlBtHEoJRSahBNDEoppQbRxKCUUmoQTQxKKaUG0cSglFJqEE0MSimlBtHEoJQaUaW9hY3Vx60OQ/mIJgal1Ih+tnY3//zHClpOd1sdivIBTQxKqfMyxlBpd9Le1ct/VhyxOhzlA5oYlFLn5Wjp4GR7N+FhwrMba+np7bM6JOVlmhiUUudVZXcCcN/CAo6ePM27u+stjkh5myYGpdR5VTmciMADn5tCzqQJrNxQa3VIyss0MSilzqvK7iQ/JY7EmEjunp/PZ7XN7KxrsTos5UWaGJRS51XlcDItMxGAL1+ZS3x0BCs3HrQ4KuVNHiUGEblORPaKSLWIPDzM/mgRecW9v1xE8ofsnywibSLy0IBt3xORShHZJSIviUiMe3uB+xzV7nNGje0jKqUulLOjm8PN7UzLciWGhJhIbi3N4fUdduqdHRZHp7xlxMQgIuHAE8D1wDTgDhGZNuSw+4ATxpgpwOPAL4bsfwx4Y8A5s4HvAKXGmEuAcOB29+5fAI+7z3XCfW6llAX2OFoBzlwxANw9P5+ePsOfPh22x4sKAp5cMcwGqo0xNcaYLuBlYNmQY5YBz7kfrwKWiogAiMjNwEGgcshrIoAJIhIBxAJ292s+5z4H7nPePLqPpJQaL1V211xC/xUDQF5KHFdfnM4L5Yfp6O61KjTlRZ4khmxg4F0tde5twx5jjOkBWoAUEYkHfgj8ZODBxpijwC+Bw4ADaDHGvA2kACfd5zjXewEgIstFpEJEKhobGz34GEqp0aq0O0mJiyItIXrQ9nsXFNB8qou/bTtqUWTKm7w9+fwIrmGhtoEbRWQSrquMAiALiBORr43mxMaYp40xpcaYUpvtrF7WSqlxUOVwMi0rEfcAwBlzC5O5ODORlRtqMcZYFJ3yFk8Sw1Egd8DzHPe2YY9xDw0lAU3AHOBREakFHgR+JCIPAFcDB40xjcaYbuAvwHz3aya6z3Gu91JK+UBXTx/769sGDSP1ExHuXZDP3vpWPj7QZEF0yps8SQybgKnu1UJRuCaJVw85ZjVwl/vxLcD7xmWRMSbfGJMP/Br4mTHmN7iGkOaKSKx7XmEpsNu4/vT4wH0O3Of82xg+n1LqAh1obKOrt2/QxPNAN87MIjU+ipUbdOlqsBkxMbjH+x8A3gJ2A382xlSKyE9F5Cb3Yc/gmlOoBr4PnLWkdcg5y3FNMG8BdrrjeNq9+4fA993nSnGfWynlY/2lMKYPc8UAEBMZzlfn5PHengYOHj/ly9CUl0kwjA+WlpaaiooKq8NQKqj8r9ereKH8EJU/uY7wMBn2mIbWDhb+/APumJ3LT5Zd4uMI1ViJyGZjTOnQ7Xrns1JqWFV2JyUZiedMCgBpCTHcODOL/9xcp70agogmBqXUWYwxg0phnM+9C/Np7+rllU2HfRCZ8gVNDEqps9hbOmg53T3siqShpmclMbcwmec+PqS9GoKEJgal1Fn6J549uWIA1w1vR0+e5u0q7dUQDDQxKKXOUmlvQQQuykjw6PilF6czOTlWl64GCU0MSqmzVNmdFKTGERcdMfLBQHiYcPf8fCoOnWD7kZNejk55myYGpdRZPJ14HujW0hzioyN4Vns1BDxNDEqpQVpOd1N34rRHE88DJcREcltpLq/vcGivhgCniUEpNchux+gmnge6e34+vcbw/CfaqyGQaWJQSg1yZkXSKK8YACanxHLNxem8UH5IezUEME0MSqlBqhxOUuOjSUuIuaDX37uwgBPt3fx1qxZGDlSaGJRSg1TZnRd0tdBvTkEy0zITWbnxoPZqCFCaGJRSZ3T19LG/ofWC5hf6iQj3LixgX30bG6qPj2N0ylc0MSilztjf0Ep3rxnTFQPAjTMzSY2P1hveApQmBqXUGaMthXEu0RHh3Dk3jw/2NnKgsW3kFyi/oolBKXVGlcPJhMhwClLjxnyur86dTFR4GH/YWDv2wJRPaWJQSp1RZXdyUWbCeXsweCo1Pppls7JYtbmOlnbt1RBINDEopYDR9WDw1D0LCjjd3cvL2qshoGhiUEoBUHfiNK0dPWOeeB5oWlYi8wpTeO7jWu3VEEA0MSilANf8Aox94nmoexcWYG/p4K1K7dUQKDQxKKUA1/xCmMBFGeObGD53URp5KbGs1KqrAUMTg1IKcF0xFKTGMSEqfFzP29+rYfOhE2zTXg0BwaPEICLXicheEakWkYeH2R8tIq+495eLSP6Q/ZNFpE1EHnI/LxGRbQP+c4rIg+59j4jI0QH7vjD2j6mUGomrFEaSV859a2kuCdqrIWCMmBhEJBx4ArgemAbcISLThhx2H3DCGDMFeBz4xZD9jwFv9D8xxuw1xswyxswCrgDagdcGHP94/35jzNrRfiil1OicbO/i6MnT4z6/0C8+OoLbrszl7zscHGvRXg3+zpMrhtlAtTGmxhjTBbwMLBtyzDLgOffjVcBSEREAEbkZOAhUnuP8S4EDxhgt4K6URfonnqeP44qkoe6en0+fMfzxk1qvvYcvHGlu5+YnNvLB3garQ/EaTxJDNnBkwPM697ZhjzHG9AAtQIqIxAM/BH5ynvPfDrw0ZNsDIrJDRFaKyKThXiQiy0WkQkQqGhsbPfgYSqlz6S+FcbGXrhgAcpNjuWZaOi9+dpjTXYHZq6GxtZM7nyln25GTvFQevPdmeHvy+RFcw0LDFksRkSjgJuA/B2x+EigCZgEO4FfDvdYY87QxptQYU2qz2cY1aKVCTZXDSVpCNLaEaK++z30LCznZ3s1rAdirwdnRzV0rP6Pe2cns/GQ2Vh+nqyc4783wJDEcBXIHPM9xbxv2GBGJAJKAJmAO8KiI1AIPAj8SkQcGvO56YIsx5swCZ2NMvTGm1xjTB/wO11CWUsqLxtqDwVNX5k/ikuzA69XQ0d3LN56rYH9DK0/deQXfWFTAqa5eKg41Wx2aV3iSGDYBU0WkwP0X/u3A6iHHrAbucj++BXjfuCwyxuQbY/KBXwM/M8b8ZsDr7mDIMJKIZA54+iVgl8efRik1ap09vVQ3tHlt4nkgEeHeBQVUN7Tx0f7A6NXQ09vHAy9uYVNtM7+6bRZlxTbmT0klMlxYty84h7FHTAzuOYMHgLeA3cCfjTGVIvJTEbnJfdgzuOYUqoHvA2ctaR1KROKAa4C/DNn1qIjsFJEdwFXA9zz+NEqpUdtf30ZP39h7MHjqhhmZ2BKiA+KGt74+ww9f3cm7uxv46bJLuGlmFuBaZVWal8y6vcGZGCI8Oci9ZHTtkG0/HvC4A7h1hHM8MuT5KSBlmOPu9CQmpdT48FYpjHPp79Xw2Dv7qG5oY0pavE/ed7SMMfzvtbt5dUsd37+mmDvn5g3aX1Zi4+dv7OFYSwcZSRfWH9tf6Z3PSoW4KruT2Khw8lLG3oPBU1+ZM5moiDD+8LH/XjX83w8P8MyGg9w9P59vf27KWfuXlLgWvazbF3zLVjUxKBXiqhxOLsoYnx4MnkqNj+bmWVm8uvkoJ9u7fPa+nnqh/BD/9tZevnRZNj/+4jTct2UNUpKeQEZiTFDOM2hiUCqE9fUZdtudTPdSKYzz+UevhiMjH+xDf9/h4L//dRefuyiNR2+ZQdg5EqaIUFZs46P9x4OupLgmBqVCWN2J07R2jm8PBk9dnJnI/CJXr4ZuP/nF+tH+Rh58ZSuleZN44iuXExl+/l+RS0pstHb0sOVwcBUH1MSgVAircrQAvpt4HureBQU4Wjp4q/KYJe8/0NbDJ1jx/GaKbPH8/q4rPaoyO39KKuFhEnTzDJoYlAph/T0YSjISLHn//l4Nz2ywdhJ6X30r9/xhE7aEaP5432ySJkR69LqkCZFcMXkSHwbZslVNDEqFsCqHkyJbPDGR49uDwVNhYcI98/PZevgkWw6fsCSGI83t3PlMOZHhYTx/7xzSEka39LSsxEal3UlDa/BUjdXEoFQI81UpjPO55Uyvhlqfv/fxtk6+vvIzTnf18vx9s5mcEjvqc5QVu5atrt8XGHdye0ITg1Ih6sSpLuwtHZbNL/SLj47g9tm5rN3pwNFy2mfv2+ouiudoOc2z91x5wS1Np2clYkuI5sMgKsOtiUGpELW7/45ni68YAL4+Lx9jDH/8xDdtWfqL4u091sqTX7uCK/KSL/hcIsLiqa5lq719gVMY8Hw0MSgVovpLYXizB4OncpNj+fz0DF4s936vhp7ePr790lY+q23mV7fN5KqStDGfc0mJjZbT3UHT0zqkE8PJ9i42VgfPuKBSo1Fpd5KeGE1qvHd7MHjq3oUFtJzu5i9b67z2HsYYHv7LTt6pqueRG6ezbNbQnmMXZtHUVMKEoLkLOqQTwyOrK1nx/GZOnPK/W/KV8rYqi+54PpfSvElcmp3Eyg0H6fPCkIwxhp+t3c2qzXU8ePVU7pqfP27nnhgbxazciawLknmGkE4M37pqCqe6enhq/QGrQ1HKpzq6e6lu9E0PBk+JCPcuzOdA4yk+8sKV/JPrDvC7jw5y17w8vrt06riff0lJGjuOttDU1jnu5/a1kE4MxekJLJuZxXMf19LgDJ41yEqNZH99G70+7MHgqRsuzXL1ahjnG95e+uwwj765l2WzsvifN04ftijeWJUV2zCGgGlAdD4hnRgAHry6mJ5ewxMfVFsdilI+Y3UpjHOJigjj63PzWLevkeqG1nE559qdDv7baztZUmLjl7fOPGdRvLG6NDuJ5LiooFi2GvKJIT81jltLc3nxs8McaW63OhylfKLK7iQuKpzJyaO/ocvb+ns1jMcNbxv2H+fBl7dx+eRJPPnVK0YsijcWYWHC4qmprN9/3CtzJL4U8okB4DtLpyAi/Md7+60ORSmfqHI4uTgz0Wt/PY9FSnw0X5qVzatb6sa0MGTbkZMsf76CQlscz3hYFG+slpSk0Xyqi51HW7z+Xt6kiQHITJrA1+bk8eqWOg40tlkdjlJe1ddn2O1o9bv5hYHuWZhPR3cfL206fEGvr25o5Z5nPyMlPoo/3jubpFjPiuKN1aKpqUgQLFvVxOD2rauKiIkM5/F39lkdilJedeREO22dPX43vzDQRRmJLJiSwh8/PjTqXg1HT57mzmc+IzwsjD/dN4e0RN/1Y06Jj2ZGdlLAzzNoYnBLjY/mngX5vL7DQZXdaXU4SnlN//e3P18xANy3sIBjzg7e2OV5r4amtk7u/H05bZ09PH/fbJ/2se5XVpLGtiMn/bJlqac0MQywfFERCTERPPbOXqtDUcprKu1OwsOE4nRrejB4aklxGgWpcR4vXW3t6ObuZzdhbznNyruvtKzUR1mxjb4AX7bqUWIQketEZK+IVIvIw8PsjxaRV9z7y0Ukf8j+ySLSJiIPuZ+XiMi2Af85ReRB975kEXlHRPa7/5009o/pmaTYSFYsLuTd3Q2W1YZXytuqHE6mWNiDwVNhYcI9C/LZdmTkXg0d3b0s/+NmdjucPPnVK7gy/8KL4o3VrNyJJE2IDOjmPSMmBhEJB54ArgemAXeIyLQhh90HnDDGTAEeB34xZP9jwBv9T4wxe40xs4wxs4ArgHbgNffuh4H3jDFTgffcz33mngUFpMRF8au39apBBSd/6MHgqX+6PIeEmIjzXjX09PbxnZe28klNE7+8dSZXXTT2onhjER4mLJqayrp9jQG7bNWTK4bZQLUxpsYY0wW8DCwbcswy4Dn341XAUnHfWigiNwMHgcpznH8pcMAY019vd+C5ngNu9uSDjJe46AjuX1LExuomPj4QuJeCSg2nqa2TY07rezB4Ki46gjtmT+aNXcewnzy7V4Mxhh+9tpO3q+r5nzdO4+bLxqco3lgtKUnjeFvnmQq2gcaTxJANHBnwvM69bdhjjDE9QAuQIiLxwA+Bn5zn/LcDLw14nm6McbgfHwPSh3uRiCwXkQoRqWhsHN9Ltq/NzSMjMYZfvrUXYwIz4ys1nN0O193EgXLFAPD1eXnn7NXw8zf28OeKOr6zdCr3LCiwILrhLS5OBQJ32aq3J58fAR43xgx7c4CIRAE3Af853H7j+q087G9mY8zTxphSY0ypzWYbp3BdYiLD+c7SqWw5fJIPAnzZmVID9ZfC8IceDJ7KmRTLdZdk8NJnh2nv6jmz/al1B/jt+hq+Pi+P7109/kXxxiItIYbpWYmsC9B5Bk8Sw1Egd8DzHPe2YY8RkQggCWgC5gCPikgt8CDwIxF5YMDrrge2GGPqB2yrF5FM97kyAUt+M99amkNeSiz/9ta+gB0nVGqoKruTzKQYkuOirA5lVO5d4O7VsMX1q+flzw7z8zf2cNPMLB7xUlG8sVpSYmPz4RO0nO62OpRR8yQxbAKmikiB+y/824HVQ45ZDdzlfnwL8L5xWWSMyTfG5AO/Bn5mjPnNgNfdweBhpKHnugv4m8efZhxFhofx4NVT2e1wsnaXY+QXKBUAqhzOgJlfGOiKvEnMyEni2Y0HeWOngx+9tpOyYu8WxRursuI0evsMHwdgM7ARE4N7zuAB4C1gN/BnY0yliPxURG5yH/YMrjmFauD7eLCSSETigGuAvwzZ9XPgGhHZD1ztfm6Jm2ZmMzUtnsfe2UfPKO++VMrfdHT3cqDxVEDNL/QTEe5dUMCBxlN868UtzMqdyJNfu5yoCP+9FevyyRNJiIkIyGWrEZ4cZIxZC6wdsu3HAx53ALeOcI5Hhjw/BaQMc1wTrpVKlgsPE35wbTHf/NMWXtt6lFtLc0d+kVJ+al99K719hukBmBgAvnBpJv/21l7ioyNYefeVxEZ59OvLMhHhYWeWrRpj/HK461z8N936ic9Pz+DS7CT+/b39dPXoVYMKXJX9pTAy/aed52hERYTx9+8sZPW3FzAxNjDmSMqKbRxzdrC3fnx6S/iKJoYRiLiuGupOnOaVC6z0qJQ/qLI7SYiOIGfSBKtDuWATY6OIjvDvO7YHKit23WwXaKuTNDF4oKzYxpX5k/g/71dzuqvX6nCUuiD+3IMhWGUkxXBRRkLAzTNoYvCAiPDQtSU0tHby/Ke1Voej1Ki5ejAETimMYFJWYqPiUDNtnT0jH+wnNDF4aE5hCoumpvLkhwdo7Qi8dckqtB1qbqe9qzcgl6oGurJiG929gbVsVRPDKPyXz5dwor2blRtqrQ5FqVEJlB4Mwag0L5m4qHA+DKDyGJoYRmFGzkQ+Pz2d331UM6ZetEr5WpWjhYgwYUpavNWhhJyoiDAWTEll3d7GgKm9polhlH5wbQmnunp4av0Bq0NRymNVdidT0vy/B0OwKiuxcfTk6YDpKa+JYZSK0xNYNjOL5z6upcHZYXU4SnkkUEthBIuyYlehz0BZnaSJ4QI8eHUx3b2GJz6otjoUpUZ0vK2Temenzi9YKGdSLFPS4gOmDLcmhguQnxrHbaU5vPjZYepOtFsdjlLnpRPP/mFJsY3ymuZBpcP9lSaGC/Ttz01FEP7jvf1Wh6LUefV3EdOhJGstKUmjq7ePT2uarA5lRJoYLlDWxAl8de5kXt1ylJoAmVBSoanK7iR74oSAqS8UrK4smMSEyPCAmGfQxDAG31oyhajwMB5/V68alP/qL4WhrBUdEc78opSAmGfQxDAGtoRo7lmQz5rtdnYHaNNvFdxOd/VS09im8wt+oqzExqGmdg4eP2V1KOeliWGMViwuIiEmgl+9vc/qUJQ6y976VvqMzi/4iyXuaqsf+nkveU0MY5QUG8mKxYW8u7ueLYdPWB2OUoP0r0gK1OY8wWZySiwFqXF+P5ykiWEc3LOggJS4KH719l6rQ1FqkCpHCwkxgd2DIdiUFdv45EATHd3+W8JfE8M4iIuO4P4lRWysbuLjA4FTQVEFvyq7647nQGorGeyWlNjo7Omj/GCz1aGckyaGcfK1uXlkJMbwy7f2BkyhLBXcevsMux2tOvHsZ+YWphAdEebX8wyaGMZJTGQ43146hS2HT/KBH/8PDwRVdieNrZ1WhxHwaptOcbpbezD4m5jIcOYW+vey1QirAwgmt5Xm8tt1NfzyrX0sKU7TFooXYM8xJ1/4j48AKLTFMacghbmFycwpSCEjKcbi6AKLlsLwX2XFNn76ehVHmtvJTY61OpyzeHTFICLXicheEakWkYeH2R8tIq+495eLSP6Q/ZNFpE1EHhqwbaKIrBKRPSKyW0Tmubc/IiJHRWSb+78vjO0j+k5keBgPXj2VKoeTN3YdszqcgPS3bXbCw4SHri0mLzmW17fb+e7L25j7/79H2b99wL+u2s6rm+u0RpUHqhxOIsOFqWkJVoeihlhS0l9t1T9HF0a8YhCRcOAJ4BqgDtgkIquNMVUDDrsPOGGMmSIitwO/AL48YP9jwBtDTv3vwJvGmFtEJAoYmDYfN8b8cvQfx3rLZmXz5IcHeOydvVx3SQbhetXgMWMMr++ws2BKKg98birgGievsjspP9jEpzXNvFVZz58r6gDImTSBOQUpzClMZm5BCrnJE3SSdQBXD4YEoiJ0xNjfFKTGMTk5lnX7GrlzXr7V4ZzFk6Gk2UC1MaYGQEReBpYBAxPDMuAR9+NVwG9ERIwxRkRuBg4CZ271E5EkYDFwN4AxpgsIipZo4WHC968p5v4XtvDa1qPcckWO1SEFjO11LRxpPs133EkBXF/PS3OSuDQniW8sKqSvz7DnWCvlB5sor2nmg70NvLrFlSgyk2KYU5DMnMIU5hQkU5AaF9KJosrhZPFUm9VhqGGICGXFNl7dUkdnTy/REf7VQMmTxJANHBnwvA6Yc65jjDE9ItICpIhIB/BDXFcbDw04vgBoBJ4VkZnAZuC7xpj+5PGAiHwdqAB+YIw5684xEVkOLAeYPHmyBx/Dd667JINLs5P49bv7uGlmlv7F5qE12+1EhYdx7fSMcx4TFiZMy0pkWlYi9ywooK/PUN3YRnlNE58ebGZDdRN/3WYHXCVL+hPF3IJkpqTFh0yiaGjtoLFVezD4syUlNp7/9BAVtSdYMCXV6nAG8fbk8yO4hoXahvxARgCXA982xpSLyL8DDwP/A3gS+F+Acf/7K+DeoSc2xjwNPA1QWlrqV+tDRYQfXFvM3c9u4pWKI9w5N8/qkPxeX59rGKmsxEbShEiPXxcWJhSnJ1CcnsCd8/IxxlBz/BTlNc1nripe3+EAICUuitkFyWeSRUl6QtAuENjtaAW0FIY/m1eUQlS4a9lqICaGo0DugOc57m3DHVMnIhFAEtCE68riFhF5FJgI9LmvIlYBdcaYcvfrV+FKDBhj6vtPKiK/A14f7YfyB2XFNq7Mn8T/eW8/t1yew4Qo/7pU9Debapupd3Zy48ysMZ1HRCiyxVNki+crcyZjjOFwczuf1jS5k0XzmYUBE2MjuTLflSjmFqZwcWZi0MwJ6Yok/xcbFcHsgmTW7Wvkv91gdTSDeZIYNgFTRaQAVwK4HfjKkGNWA3cBnwC3AO8b111ei/oPEJFHgDZjzG/cz4+ISIkxZi+wFPechYhkGmMc7pd9Cdh1gZ/NUiLCQ9eW8OWnP+X5T2tZvrjI6pD82poddiZEhnP1xWnjel4RIS8ljryUOL58pWvI8UhzO+UHmymvaaL8YDPvVLn+FkmIiRiUKKZnJRIRHpjDgFUOJzmTJozq6kv5Xlmxjf+9djf2k6fJmug/ZUtGTAzuOYMHgLeAcGClMaZSRH4KVBhjVgPPAM+LSDXQjCt5jOTbwAvuFUk1wD3u7Y+KyCxcQ0m1wIpRfia/MacwhUVTU3nywwPcMXsyCTH6Qzqcnt4+1u48xtKL04iN8v6tNbnJseQmx55ZGOBoOT1o6On9Pa4lhKnx0fzl/vlMTvG/deYjqbS36DBSAFhS4koMH+5t5Ctz/Geu1KOfQmPMWmDtkG0/HvC4A7h1hHM8MuT5NqB0mOPu9CSmQPHQtSUse2IjKzfU8t2rp478ghD08YEmmk91jXkY6UJlJk3g5suyufmybAAanB18UtPEf1m1g6fWH+BnX7rUkrguVHtXDwePn+Imi76eynNT0uLJnjiBdfsa/CoxBOZ1cgCZmTuRa6el8/uPajjZHhQrcsfdmu12EqIjKCv2j6WVaYkxLJuVzS1X5LBqcx0NrR1WhzQqe461YrQHQ0AQERYX29hY3URXT5/V4ZyhicEHfnBtCW1dPTy1rsbqUPxOZ08vb1Ye49rpGcRE+tcE/fJFhfT09vHsxlqrQxkVnXgOLEtKbLR19vhVPxdNDD5QkpHATTOz+MPHBwPur09vW7/vOK0dPdw4M9PqUM6SnxrH9Zdm8qdPDuHs6LY6HI9VOZwkxkSQ7UeTmerc5helEBEmfLjXf4rqaWLwke9dXUx3r+H/fnDA6lD8yprtdibFRvrdOu5+95cV0drZw4vlh60OxWNVdifTsrQHQ6BIiImkNH+SX9VN0sTgI/mpcdxWmsOL5Yc5evK01eH4hfauHt6pquf6SzOJ9NNloZdkJ7FoairPbDjo1x23+vX2GfYcczItM8nqUNQoLClJY8+xVuqd/jGi4J8/jUHq2+4aQP/x7n6LI/EP7+9p4HR3LzfO8O/VM/eXFdHY2slrW4fe1+l/Dh4/RUd3n/Z4DjD9Cy/W+clwkiYGH8qaOIGvzp3Mqi111DS2WR2O5dZst5OWEM3sgmSrQzmveUUpzMhJ4rfrDtDb51fVV85S5dCJ50B0UUYC6YnRftO8RxODj31ryRSiwsN4PMSvGpwd3XywtxCMnqEAABoaSURBVJEvXJrp92UoRIT7y4qobWrnTT/vs1FpbyEqPIwiW7zVoahR6K+2+tH+Rnp6rV+2qonBx2wJ0dyzIJ812+3sdv91F4reqaynq6fPspvaRuva6RkUpMbx1LoDft3Tu8ruZGp6vFb0DUBLStJwdvSw7chJq0PRxGCFFYuLSIiJ4Fdv77M6FMus2WEne+IELp880epQPBIeJqxYXMjOoy1srG6yOpxhGeNqaqQ3tgWmBVNSCfeTZauaGCyQFBvJ8kWFvLu7nq1+dFOLr5w41cWG/cf54szMgFpS+aXLs0lLiOapdf655LixtZOmU106vxCgkiZEcvnkiXy4z/plq5oYLHLPwgKS46JC8qrhzcpj9PQZv1+NNFR0RDj3LSxgQ/Vxdta1WB3OWSr7J571iiFgLSlJY9dRJ42tnZbGoYnBIvHREXxrSREbqo/zyQH/HJrwljXb7RSmxgXkksqvzJlMQkyEX1419JfCuDgAv67KpX/Z6nqLVydpYrDQ1+bmkZ4YzS/f3uvXE5rjqb9y6RdnZgXUMFK/hJhI7pybx9pdDg4ePzXyC3yoyuEkN3kCiVrePWBNy0wkNd76ZauaGCwUExnOd5ZOZfOhE34x4eQLa3c6MAZunOF/tZE8dc+CAiLDw3h6vX9dNezWieeAFxYmLC5OZf3+RkvvmdHEYLHbSnOZnBzL4+/uC4mrhjU7HFyUkcDU9ASrQ7lgtoRobr0ih1c3H6XBT0oYnOrs4WDTKaZnaSmMQLekJI2T7d3sqLNu2aomBotFhofxzbIidtS18ElNcM811J1oZ/OhEwFz78L5LF9cSE9fH89sPGh1KID2YAgmi6akEiZYOoqgicEP/H+XZ5MaH8Vvg7xfw993uFp5B9pqpOHkpcTxhUszefHTw35RkrvK7lolpUtVA9+kuChm5k7kQwvnGTQx+IGYyHDuWVDAun2NQX039JoddmbmTgzIHsrD+aa7JPefPj1kdShUOZxMjI0kMynG6lDUOFhSnMaOupM0n7Km66MmBj/xtTl5xEaF8/T64LxqqGlsY9dRZ0BPOg/VX5J75YZay0ty99/xHIgrvdTZykpsGAMf7bfmqkETg59Iio3kjtmTWb3dTt2JdqvDGXev73AgAl8MgmGkge5fUsTxtk5e3VJnWQw9vX3sOdaq8wtBZEZ2EslxUZaV4dbE4EfuXViAACs31FodyrgyxrB6u50r85PJCLKhjnmFKczMSeLp9TWWLS88ePwUnT19Or8QRMLChEVTU1m3r5E+C76vPEoMInKdiOwVkWoReXiY/dEi8op7f7mI5A/ZP1lE2kTkoQHbJorIKhHZIyK7RWSee3uyiLwjIvvd/04a20cMHNkTJ3DTzCxe3nSYk+3WjC16w976Vqob2oJiNdJQIsL9S4o41NTOG7sclsSgPRiC05ISG02nuthl9335lRETg4iEA08A1wPTgDtEZNqQw+4DThhjpgCPA78Ysv8x4I0h2/4deNMYcxEwE9jt3v4w8J4xZirwnvt5yFheVkh7V69fTGiOlzXb7YQJXH9JhtWheMU10zIoTI3jyQ+tKcldZXcSFaE9GILN4qk2RKzp6ubJFcNsoNoYU2OM6QJeBpYNOWYZ8Jz78SpgqbhnwUTkZuAgUNl/sIgkAYuBZwCMMV3GmJPDnOs54ObRfqhAdlFGIktKbPzhY+snNMeDMYY12x0smJJKany01eF4RXiYsKKskEq7kw3Vx33+/lUOJyXpCX7bN1tdmJT4aC7NTrJk2aon30nZwJEBz+vc24Y9xhjTA7QAKSISD/wQ+MmQ4wuARuBZEdkqIr8XkTj3vnRjTP81+TEgfbigRGS5iFSISEVjY3CVk1ixuIjjbV2WTmiOlx11LRxubg+KexfO5+bLsklPjObJD31bJkN7MAS3JcU2th4+QUu7b++V8fafGI8AjxtjhjY4jgAuB540xlwGnGKYISPjui4f9trcGPO0MabUGFNqs9nGN2qLzS1MZmZOEr+zcEJzvKzZbicyXPj89OAcRurXX5L74wNNbPdhB64G7cEQ1MpKbPQZ+Kjat3/8epIYjgK5A57nuLcNe4yIRABJQBMwB3hURGqBB4EficgDuK466owx5e7Xr8KVKADqRSTTfa5MwPquFT4mIqxw9xh+u9K/ewyfT1+f4e87HZQV20iKDf6Kn3fMnkyij0tyV+odz0FtVu4kkiZE+nyewZPEsAmYKiIFIhIF3A6sHnLMauAu9+NbgPeNyyJjTL4xJh/4NfAzY8xvjDHHgCMiUuJ+zVKgaphz3QX87UI+WKD7/PQM8lJieWp9TcAW19t8+ASOlo6gXI00nISYSO6cl8eblceoaRx6kewd/T0YLsoI3KKE6tzCByxb9eXvgRETg3vO4AHgLVwrh/5sjKkUkZ+KyE3uw57BNadQDXwfz1YSfRt4QUR2ALOAn7m3/xy4RkT2A1e7n4ec8DDhnxcVsv3IST472Gx1OBdkzXY7MZFhXH3xsNNEQenu+QVEhYf57A72KoeTvJRYErQHQ9AqK7bR0Np5ZlmyL0R4cpAxZi2wdsi2Hw943AHcOsI5HhnyfBtQOsxxTbiuIELeLVfk8Pg7+/jt+hrmFKZYHc6o9PT2sXang6UXpRMX7dG3WVCwJURza2kOf95Ux/euKSY90bs39OnEc/Dr7+q2bl+jz8qq6/o2PxYTGc7d8/N5f08De4+1Wh3OqHxa08zxti5unBk8tZE8tXxRET19fazc4N2S3G2dPdQ2tWtiCHJpiTFMy0z0aRluTQx+7s55eUyIDLziemu224mPjmBJSZrVofjc5JRYbpiRxQvlh2k57b1lhnv0jueQsaTExpZDJ3xW4l0Tg5+bGBvF7bNz+du2ozhaTlsdjke6evp4Y5eDa6elExMZbnU4lvhmWSFtXi7J3T/mrF3bgl9ZsY2ePsPHPrqBUhNDALhvYQEGvD40MV4+2t+Is6MnZFYjDWd6VhKLi208u/Gg1+5gr7I7SY6LIj0xOO8oV/9wed4kEqIjWOeju6A1MQSAnEmx3Dgjkxe9PDQxXtZstzMxNpIFU1KtDsVS95e57mBftdk7d7BXObQHQ6iIDA9j4dRUPtzrm2WrmhgCxPLFRZzq6uWFcv8urne6q5d3quq5/pIMoiJC+9trbmEyM3Mn8vT6Gnp6+8b13N39PRh0fiFklBXbcLR0sK/e+/fIhPZPbgCZlpXoHprw7+J6H+xt4FRXb9DXRvKEiHB/WRGHm9t5Y9f43sFe03iKrp4+XZEUQspK+peter8YhCaGAPLNxYU0tnby161DK5L4jzXb7aTGRwfcfRfecu20dApt41+Su8qhpTBCTWbSBErSE3yybFUTQwCZV5TCpdmubmFWdHUaSWtHN+/vaeCGSzMID9Nxb3B14vrm4iKqHE4+2j9+K0r6ezAUpsaNfLAKGktKbGyqbeZUZ49X30cTQwBxFdcrpOb4Kd7ZXW91OGd5d3c9nT19Ib0aaTjLLssiIzFmXEtyVzmcXJSRQIT2YAgpZSU2unsNHx9o8ur76HdVgLluegaTk2N5ap013cLOZ812B1lJMVw+OWS6sXqkvyT3JzVNbBuHktzagyF0leYlExcV7vV5Bk0MASYiPIx/XlTA1sMnqTh0wupwzjjZ3sX6fY18cWYWYTqMdJY75rhLco/DVcMxZwcn2rt1fiEERUWEMX+K95etamIIQLdckUtyXBS/9WHd/5G8uesYPX1GVyOdQ3x0BF+fl89bVcc4MMaS3P2ltqdrYghJZcU26k6c5kDjKa+9hyaGADQhKpy75uXz7u4G9tf7R3G9NTvs5KfEckm2/rI6l7sX5LtKcq8bW92rKrsTESjJ0K91KBpYbdVbNDEEqK/7UXG9xtZOPjnQxI0zs/Qu3PNIjY/mttJc/rK1jmMtHRd8niqHk/yUOOJDqJy5+ofc5FiKbHF8uNd78wyaGALUpLgovnxlLn/ddnRMv2TGwxu7HPQZdDWSB5YvLqTPwMqNF173qlInnkPekpI0yg82c7rLOze7amIIYPctLKDPwLNj+CUzHtZst1OSnkBxuraXHEluciw3XJrJC58eoqV99HWvnB3dHG5u14nnELekxEZXTx+f1nhn2aomhgB25pdM+WGf1Wkfyn7yNJtqT4RkQ54L9c0yV92rP11A3as9Dteckl4xhLYr85OZEBnuteEkTQwBbvliV93/F8sPW/L+f9/hAOCLuhrJY9OyEllSYmPlhtGX5K6yaykM5eruOK8oxWsT0JoYAtwl2UksmprKyg0H6ezxfXG9NTvszMhJIl9LM4zKN8uKaDrVxX9WHBnV66ocTlLiokhL0B4Moa6s2EZtUzu1x8d/2aomhiCwYnERDa2d/G2r3afvW3v8FDvqWvTehQswpyCZyyZP5OmPRleSu8rhZFqW9mBQrnmGjMQY7CfHv7OjJoYgsGBKCtOzEvnt+gM+La73+g5XIrphhs4vjJaI8M2yIo40n+bvOx0evaa7t499x9p0GEkBkJcSxyf/9XPM90JDLI8Sg4hcJyJ7RaRaRB4eZn+0iLzi3l8uIvlD9k8WkTYReWjAtloR2Ski20SkYsD2R0TkqHv7NhH5woV/vNAgIixfXMiBxlO8t8f7tdr7rdnu4Mr8SWRNnOCz9wwm11ycTpEtjqfW1XhU3uBAYxtdvdqDQf2Dt64cR0wMIhIOPAFcD0wD7hCRaUMOuw84YYyZAjwO/GLI/seAN4Y5/VXGmFnGmNIh2x93b59ljFnryQcJdTdcmkn2xAk+K5Ox91gre+tb9d6FMQgLE1aUFbHb4fRoElFLYShf8eSKYTZQbYypMcZ0AS8Dy4Ycswx4zv14FbBU3KlMRG4GDgKV4xOyGk5/cb2KQyeoqG32+vu9vsNOmMD1l+gw0ljcPCubjMQYnvIgoVfZncREhlGQGu+DyFQo8yQxZAMDl07UubcNe4wxpgdoAVJEJB74IfCTYc5rgLdFZLOILB+y7wER2SEiK0Vk2BrOIrJcRCpEpKKx0fsdjQLBbVfmMjE2kt96uUyGMYY12+3MK0rBpqtjxiQqIoxvLCrg05pmth4+f7XcSruTkoxEbYKkvM7bk8+P4BoWGq6c5EJjzOW4hqj+RUQWu7c/CRQBswAH8KvhTmyMedoYU2qMKbXZbOMfeQCKjXJV8Hynqp7qBu81DN911EltU7uuRhont8+eTNKEyPNeNRhjXCuSdH5B+YAnieEokDvgeY5727DHiEgEkAQ0AXOAR0WkFngQ+JGIPABgjDnq/rcBeA3XkBXGmHpjTK8xpg/4Xf925Zm75uURHRHG77x41bBmh52IMOG6SzK89h6hxFWSO4+3Kuupbhi+Wq69pYOW09qDQfmGJ4lhEzBVRApEJAq4HVg95JjVwF3ux7cA7xuXRcaYfGNMPvBr4GfGmN+ISJyIJACISBxwLbDL/XzgoPWX+rcrz6S4K3i+tvUo9c7xL67X12d4fbudxcU2JsZGjfv5Q9Xd8/OJiQzjt+coyd0/8axXDMoXRkwM7jmDB4C3gN3An40xlSLyUxG5yX3YM7jmFKqB7wNnLWkdIh3YICLbgc+Avxtj3nTve9S9jHUHcBXwvVF/qhD3jUUF9PT18ezG2nE/95bDJ7C3dGhtpHGWEh/Nl0td1XIdLWffsNTfg+GiDC1UqLzPo4Lu7iWja4ds+/GAxx3ArSOc45EBj2uAmec47k5PYlLnlpcSx/XuCp7/clURCTGR43buNdvtREeEcfXF6eN2TuXyjUWF/Kn8MM98dJD//sXBK8KrHC0UpMYRpz0YlA/onc9BasXiQlo7e3jps/ErrtfbZ/j7zmN87qK0cU02yiU3OZYbZ2Ty0meHOdneNWifTjwrX9LEEKRm5ExkflEKz2w4SFeP57V4zqe8ponjbZ16U5sXrXCX5H7+k3+U5G453c2R5tM68ax8RhNDEFtRVkS9s5O/bRu6iOzCrNlhJy4qnKtK0sblfOpsF2cmclWJjT98XHumO9ceh048K9/SxBDEFk9N5aKMBJ5eXzPm4npdPX28sesY10xLZ0JU+DhFqIZzpiT3Ztd9pZX9K5L0ikH5iCaGINZfwXN/QxsfjLHT08bq45xs79ZhJB+YXZDM5ZMn8vR6V0nuKoeT1Pho0hJirA5NhQhNDEHuhhn9xfXGdsPbmu12EmMiWDRV7zL3tv6EXnfCVZK7yu7UqwXlU5oYglxkeBj3LSzgs9pmNh86fy2ec+no7uXtqnquvySTqAj9lvGFqy9OZ0paPE98UM3+hladX1A+pT/lIeDLV+aSNCGSp9dfWEnuD/c20NbZo8NIPhQWJqxYXMi++ja6e41eMSif0sQQAuLctXjerqrnQOPoi+ut2e4gNT6KuYXJXohOncuyWdlkJrnmFfSKQfmSJoYQcdf8fCLDw/j9R6Oba2jr7OG9Pa5hpIhw/XbxpaiIMB66toQZOUkUpMZZHY4KIfqTHiJS46O59YocXt18lIZWz4vrvbe7no7uPh1Gssg/XZHD6gcWag8G5VOaGELIPy8qpLuvjz+Morjemu12MhJjKM0btl+SUioIaWIIIfmpcVx/SQbPf3qIts6eEY9vae9m3b5GvjgjkzD9i1WpkKGJIcSsWFxEa0cPL3tQXO+tymN09xodRlIqxGhiCDEzcycytzDZo+J6a3bYmZwcy4ycJB9Fp5TyB5oYQtCKsiIcLR2s2W4/5zHH2zrZWH2cG2dmIqLDSEqFEk0MIWhJsY2S9AR+u/4AxgxfXO+NnQ76DDqMpFQI0sQQgkSEFWWuu2o/3Ns47DFrtjuYmhZPSbq2klQq1GhiCFE3zswiKymGp9adXSbD0XKaTYeauXFmlg4jKRWCNDGEqMjwMO5dWED5wWa2Hh5cXO/vOxwYA1+ckWlRdEopK2liCGG3z55MYkwET68fXCZjzQ4Hl2QnUmiLtygypZSVNDGEsPjoCO6cl8eblcc4ePwUAIeb2tl+5CQ3ztBJZ6VClUeJQUSuE5G9IlItIg8Psz9aRF5x7y8Xkfwh+yeLSJuIPDRgW62I7BSRbSJSMWB7soi8IyL73f9qLQYv6i+u9zt3cb01O1xLWG/QYSSlQtaIiUFEwoEngOuBacAdIjJtyGH3ASeMMVOAx4FfDNn/GPDGMKe/yhgzyxhTOmDbw8B7xpipwHvu58pL0hJi+KfLc1i1uY7G1k7WbLdzRd4kcibFWh2aUsoinlwxzAaqjTE1xpgu4GVg2ZBjlgHPuR+vApaKezmLiNwMHAQqPYxp4LmeA2728HXqAv3zogK6e/v4H3/dxZ5jrdyoVwtKhTRPEkM2cGTA8zr3tmGPMcb0AC1AiojEAz8EfjLMeQ3wtohsFpHlA7anG2Mc7sfHgPThghKR5SJSISIVjY3Dr8VXnim0xfP5aRm8WXkMEfjCpZoYlApl3p58fgR43BgzXNuwhcaYy3ENUf2LiCweeoBx3ZY77K25xpinjTGlxphSm00b1I/VirJCAOYWpJCWGGNxNEopK0V4cMxRIHfA8xz3tuGOqRORCCAJaALmALeIyKPARKBPRDqMMb8xxhwFMMY0iMhruIas1gP1IpJpjHGISCbQMIbPpzx02eRJ/Ot1JczO1/adSoU6T64YNgFTRaRARKKA24HVQ45ZDdzlfnwL8L5xWWSMyTfG5AO/Bn5mjPmNiMSJSAKAiMQB1wK7hjnXXcDfLvCzqVH61pIplGpiUCrkjXjFYIzpEZEHgLeAcGClMaZSRH4KVBhjVgPPAM+LSDXQjCt5nE868Jp7fjoCeNEY86Z738+BP4vIfcAh4LYL+FxKKaUukJyrumYgKS0tNRUVFSMfqJRS6gwR2TzkdgFA73xWSik1hCYGpZRSg2hiUEopNYgmBqWUUoNoYlBKKTWIJgallFKDBMVyVRFpxHXPw4VIBY6PYziBTr8e/6Bfi8H06zFYMHw98owxZ9UUCorEMBYiUjHcOt5QpV+Pf9CvxWD69RgsmL8eOpSklFJqEE0MSimlBtHEAE9bHYCf0a/HP+jXYjD9egwWtF+PkJ9jUEopNZheMSillBpEE4NSSqlBQjoxiMh1IrJXRKpF5GGr47GKiOSKyAciUiUilSLyXatj8gciEi4iW0XkdatjsZqITBSRVSKyR0R2i8g8q2Oyioh8z/1zsktEXhKRoOuFG7KJQUTCgSdw9ZyeBtwhItOsjcoyPcAPjDHTgLm4enCH6tdioO8Cu60Owk/8O/CmMeYiYCYh+nURkWzgO0CpMeYSXM3LRmpMFnBCNjHg6jFdbYypMcZ0AS8DyyyOyRLGGIcxZov7cSuuH/psa6OylojkADcAv7c6FquJSBKwGFenRowxXcaYk9ZGZakIYIK7v30sYLc4nnEXyokhGzgy4HkdIf7LEEBE8oHLgHJrI7Hcr4F/BfqsDsQPFACNwLPuobXfu3u1hxxjzFHgl8BhwAG0GGPetjaq8RfKiUENISLxwKvAg8YYp9XxWEVEvgg0GGM2Wx2Ln4gALgeeNMZcBpwCQnJOTkQm4RpZKACygDgR+Zq1UY2/UE4MR4HcAc9z3NtCkohE4koKLxhj/mJ1PBZbANwkIrW4hhg/JyJ/sjYkS9UBdcaY/qvIVbgSRSi6GjhojGk0xnQDfwHmWxzTuAvlxLAJmCoiBSIShWsCabXFMVlCRATX+PFuY8xjVsdjNWPMfzXG5Bhj8nF9X7xvjAm6vwo9ZYw5BhwRkRL3pqVAlYUhWekwMFdEYt0/N0sJwon4CKsDsIoxpkdEHgDewrWyYKUxptLisKyyALgT2Cki29zbfmSMWWthTMq/fBt4wf1HVA1wj8XxWMIYUy4iq4AtuFbzbSUIS2NoSQyllFKDhPJQklJKqWFoYlBKKTWIJgallFKDaGJQSik1iCYGpZRSg2hiUEopNYgmBqWUUoP8P8P+a0m40qoFAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}