{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DIPANJAN001/Forecasting-Solar-Energy/blob/master/final_gsm_bestresult.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzs_vH9vlX74",
        "outputId": "5d2e8c4f-aae8-42fe-fdf2-9a000a1b97be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Boruta in /usr/local/lib/python3.8/dist-packages (0.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.0.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.17.1->Boruta) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.17.1->Boruta) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install Boruta\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from boruta import BorutaPy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import concatenate\n",
        "from keras import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Bidirectional\n",
        "from keras import layers\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import load_model\n",
        "from keras.layers import Input\n",
        "from sklearn.decomposition import PCA "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lDilv4v2lz-w"
      },
      "outputs": [],
      "source": [
        "def lstm_data_transform(x_data, y_data, num_steps):\n",
        "    \"\"\" Changes data to the format for LSTM training \n",
        "for sliding window approach \"\"\"\n",
        "    # Prepare the list for the transformed data\n",
        "    X, y = list(), list()\n",
        "    # Loop of the entire data set\n",
        "    for i in range(x_data.shape[0]):\n",
        "        # compute a new (sliding window) index\n",
        "        end_ix = i + num_steps\n",
        "        # if index is larger than the size of the dataset, we stop\n",
        "        if end_ix >= x_data.shape[0]:\n",
        "            break\n",
        "        # Get a sequence of data for x\n",
        "        seq_X = x_data[i:end_ix]\n",
        "        # Get only the last element of the sequency for y\n",
        "        seq_y = y_data[end_ix]\n",
        "        # Append the list with sequencies\n",
        "        X.append(seq_X)\n",
        "        y.append(seq_y)\n",
        "    # Make final arrays\n",
        "    x_array = np.array(X)\n",
        "    y_array = np.array(y)\n",
        "    return x_array, y_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iQt_oZP7QczL"
      },
      "outputs": [],
      "source": [
        "df=pd.read_excel(\"/content/pv_04.xlsx\")\n",
        "weather_input1=df.drop('power_normed',axis=1)\n",
        "weather_input=weather_input1.drop('time_idx',axis=1)\n",
        "solpow=df['power_normed']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoPnMw4oQQlc",
        "outputId": "a21c7d43-320e-49b8-b74e-4b2b276b696c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: \t1 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t2 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t3 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t4 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t5 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t6 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t7 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t8 / 100\n",
            "Confirmed: \t9\n",
            "Tentative: \t14\n",
            "Rejected: \t26\n",
            "Iteration: \t9 / 100\n",
            "Confirmed: \t9\n",
            "Tentative: \t14\n",
            "Rejected: \t26\n",
            "Iteration: \t10 / 100\n",
            "Confirmed: \t9\n",
            "Tentative: \t14\n",
            "Rejected: \t26\n",
            "Iteration: \t11 / 100\n",
            "Confirmed: \t9\n",
            "Tentative: \t14\n",
            "Rejected: \t26\n",
            "Iteration: \t12 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t8\n",
            "Rejected: \t29\n",
            "Iteration: \t13 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t8\n",
            "Rejected: \t29\n",
            "Iteration: \t14 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t8\n",
            "Rejected: \t29\n",
            "Iteration: \t15 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t8\n",
            "Rejected: \t29\n",
            "Iteration: \t16 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t7\n",
            "Rejected: \t29\n",
            "Iteration: \t17 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t7\n",
            "Rejected: \t29\n",
            "Iteration: \t18 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t7\n",
            "Rejected: \t29\n",
            "Iteration: \t19 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t7\n",
            "Rejected: \t29\n",
            "Iteration: \t20 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t7\n",
            "Rejected: \t29\n",
            "Iteration: \t21 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t7\n",
            "Rejected: \t29\n",
            "Iteration: \t22 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t23 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t24 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t25 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t26 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t27 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t28 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t29 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t30 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t31 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t32 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t33 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t34 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t35 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t36 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t37 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t38 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t39 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t40 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t41 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t42 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t43 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t44 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t45 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t5\n",
            "Rejected: \t30\n",
            "Iteration: \t46 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t47 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t48 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t49 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t50 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t51 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t52 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t53 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t54 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t55 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t56 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t57 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t58 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t59 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t60 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t61 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t62 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t63 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t64 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t65 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t66 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t67 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t68 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t69 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t70 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t71 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t72 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t73 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t74 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t75 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t76 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t77 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t78 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t79 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t80 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t81 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t82 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t83 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t84 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t85 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t86 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t87 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t88 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t89 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t90 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t91 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t92 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t93 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t94 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t95 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t96 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t97 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t98 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "Iteration: \t99 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t30\n",
            "\n",
            "\n",
            "BorutaPy finished running.\n",
            "\n",
            "Iteration: \t100 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t1\n",
            "Rejected: \t30\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BorutaPy(estimator=RandomForestRegressor(max_depth=7, n_estimators=88,\n",
              "                                         random_state=RandomState(MT19937) at 0x7F75B4F65840),\n",
              "         n_estimators='auto',\n",
              "         random_state=RandomState(MT19937) at 0x7F75B4F65840, verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "rfc = RandomForestRegressor(random_state=1, n_estimators=1000, max_depth=7)\n",
        "boruta_selector = BorutaPy(rfc, n_estimators='auto', verbose=2, random_state=1)\n",
        "boruta_selector.fit(np.array(weather_input), np.array(solpow)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "u2NoSDCGUFNU"
      },
      "outputs": [],
      "source": [
        "X_important_train = boruta_selector.transform(np.array(weather_input))\n",
        "num_steps = 3\n",
        "# training set\n",
        "(x_transformed_train,\n",
        " y_transformed_train) = lstm_data_transform(X_important_train,solpow , num_steps=num_steps)\n",
        "assert x_transformed_train.shape[0] == y_transformed_train.shape[0]\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_transformed_train,y_transformed_train,test_size=0.33, random_state=42,shuffle=False)\n",
        "#X_train_,X_val,y_train_,y_val=train_test_split(X_train,y_train,test_size=0.2, random_state=42,shuffle=False)\n",
        "inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdKjqiCK5m_T",
        "outputId": "1fa4b413-9de5-4fb8-8a1d-bfb984e96ae1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 3, 17) dtype=float32 (created by layer 'input_2')>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "inputs1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "V27z-GjNapD4"
      },
      "outputs": [],
      "source": [
        "from keras import optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "uxD0diT8a4c2"
      },
      "outputs": [],
      "source": [
        "opt=optimizers.Adam(learning_rate=0.003)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "YM0Epc0yvWnJ"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "\n",
        "class CustomAdam(optimizers.Adam):\n",
        "    def __init__(self, new_idea_param=0.1, *args, **kwargs):\n",
        "        self.new_idea_param = new_idea_param\n",
        "        super(CustomAdam, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [K.update_add(self.iterations, 1)]\n",
        "\n",
        "        lr = self.lr\n",
        "        if self.initial_decay > 0:\n",
        "            lr *= (1. / (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n",
        "\n",
        "        t = K.cast(self.iterations, K.floatx()) + 1\n",
        "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        new_idea_t = self.new_idea_param * (K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        self.weights = [self.iterations] + ms + vs\n",
        "\n",
        "        for p, g, m, v in zip(params, grads, ms, vs):\n",
        "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
        "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
        "            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon) - new_idea_t * g\n",
        "\n",
        "            self.updates.append(K.update(m, m_t))\n",
        "            self.updates.append(K.update(v, v_t))\n",
        "            self.updates.append(K.update(p, p_t))\n",
        "        return self.updates"
      ],
      "metadata": {
        "id": "g8F6yCGl21Sz"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "\n",
        "class GradientAdam(optimizers.Adam):\n",
        "    def __init__(self, gradient_param=0.1, *args, **kwargs):\n",
        "        self.gradient_param = gradient_param\n",
        "        super(GradientAdam, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [K.update_add(self.iterations, 1)]\n",
        "\n",
        "        lr = self.lr\n",
        "        if self.initial_decay > 0:\n",
        "            lr *= (1. / (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n",
        "\n",
        "        t = K.cast(self.iterations, K.floatx()) + 1\n",
        "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        gradient_t = self.gradient_param * grads\n",
        "\n",
        "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        self.weights = [self.iterations] + ms + vs\n",
        "\n",
        "        for p, g, m, v, g_t in zip(params, grads, ms, vs, gradient_t):\n",
        "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
        "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
        "            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon) + g_t\n",
        "\n",
        "            self.updates.append(K.update(m, m_t))\n",
        "            self.updates.append(K.update(v, v_t))\n",
        "            self.updates.append(K.update(p, p_t))\n",
        "        return self.updates\n"
      ],
      "metadata": {
        "id": "J_gyZaJU8f4W"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "t0f48T0zsiAs"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "class HalvAdam(Adam):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.prev_gradients = None\n",
        "\n",
        "    @tf.function\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [math_ops.cast(x, \"float32\") for x in grads]\n",
        "\n",
        "        if self.prev_gradients is not None:\n",
        "            for i in range(len(grads)):\n",
        "                if (grads[i] * self.prev_gradients[i] < 0):\n",
        "                    self.updates[i] = self.updates[i] / 2\n",
        "\n",
        "        self.prev_gradients = grads\n",
        "        return self.updates"
      ],
      "metadata": {
        "id": "MpStRslgCRBO"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "class AdaptiveAdam(Adam):\n",
        "    def __init__(self, *args, factor=0.5, patience=5, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.wait = 0\n",
        "        self.best_loss = float('inf')\n",
        "        self.best_weights = None\n",
        "\n",
        "    @tf.function\n",
        "    def get_updates(self, loss, params):\n",
        "        current_loss = loss()\n",
        "        if current_loss < self.best_loss:\n",
        "            self.best_loss = current_loss\n",
        "            self.best_weights = params\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.wait = 0\n",
        "                self.lr = self.lr * self.factor\n",
        "                params = self.best_weights\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [math_ops.cast(g, \"float32\") for g in grads]\n",
        "        return self.updates\n"
      ],
      "metadata": {
        "id": "PmHcGR7JJLo_"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "class MomentumAdam(Adam):\n",
        "    def __init__(self, *args, momentum=0.9, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.momentum = momentum\n",
        "        self.velocities = [tf.Variable(tf.zeros_like(p), trainable=False) for p in self.weights]\n",
        "\n",
        "    @tf.function\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = []\n",
        "        for p, g, v in zip(params, grads, self.velocities):\n",
        "            v_t = self.momentum * v - self.lr * g\n",
        "            p_t = p + v_t\n",
        "            self.updates.append(p_t)\n",
        "            self.updates.append(v_t)\n",
        "        return self.updates\n"
      ],
      "metadata": {
        "id": "Zqo9SvzjbTtq"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "cSM9vzEq3G3U"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "nq9ZwBIrI_qj"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "18n5dRvpuI5T"
      },
      "outputs": [],
      "source": [
        "def define_model():\n",
        "\n",
        "\n",
        "  fe2_0 = Bidirectional(LSTM(256, activation='relu',return_sequences = True))(inputs1)\n",
        "  fe2_1 = Dropout(0.6)(fe2_0)\n",
        "  fe2_2 = Bidirectional(LSTM(64, activation='relu',return_sequences = True))(fe2_1)\n",
        "  fe2_3= Dropout(0.5)(fe2_2)\n",
        "  fe2_4=Bidirectional(LSTM(4, activation='relu'))(fe2_3)\n",
        "  out2_1=Dense(1, activation='relu')(fe2_4)\n",
        "\n",
        "  fe3_0 =Bidirectional(LSTM(128, activation='relu',return_sequences = True))(inputs1)\n",
        "  fe3_1 = Dropout(0.6)(fe3_0)\n",
        "  fe3_2 = Bidirectional(LSTM(96, activation='relu',return_sequences = True))(fe3_1)\n",
        "  fe3_3= Dropout(0.5)(fe3_2)\n",
        "  fe3_4=Bidirectional(LSTM(8, activation='relu'))(fe3_3)#16\n",
        "  out3_1=Dense(1, activation='relu')(fe3_4)\n",
        " \n",
        " \n",
        "\n",
        "  output = layers.average([out2_1, out3_1])\n",
        "  #merged3 = concatenate([out2_1,out3_1], name='concat3')\n",
        "  #output = Dense(1, activation='relu')( merged3)\n",
        "  \n",
        "\n",
        "  model = Model(inputs=[inputs1], outputs=[output])\n",
        "  \n",
        " \n",
        "  return model\n",
        "mdl=define_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss=[]"
      ],
      "metadata": {
        "id": "P5UqekV1_q7F"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import clone_model"
      ],
      "metadata": {
        "id": "9zy5UX8p_zSl"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "dAICp2p5OCER"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "9iwWrmDs0z7O"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GlobalMinimaSearch(weights):\n",
        "  if len(loss)>9:\n",
        "   return\n",
        "  \n",
        "  initial_weights =weights\n",
        "  model=clone_model(mdl)\n",
        "  model.set_weights(weights)\n",
        "  model.compile(optimizer=HalvAdam(learning_rate=0.002), loss='mean_squared_error')\n",
        "  model.fit(X_train, y_train, epochs=75, batch_size=64)\n",
        "  y= model.predict(X_test)\n",
        "  loss.append(np.sqrt(mean_squared_error(y,y_test)))\n",
        "  best_weights= model.get_weights()\n",
        "  \n",
        "\n",
        "     \n",
        "\n",
        "  params_1 =[final_weight + (final_weight - initial_weight) for initial_weight, final_weight in zip(initial_weights, best_weights)]\n",
        "  #GlobalMinimaSearch(params_1)\n",
        "\n",
        "\n",
        "  params_2 =[final_weight - (final_weight - initial_weight) for initial_weight, final_weight in zip(initial_weights, best_weights)]\n",
        "  GlobalMinimaSearch(params_2)\n",
        "  \n",
        " "
      ],
      "metadata": {
        "id": "FxpviTJb_nUR"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GlobalMinimaSearch(mdl.get_weights())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuddmGCf_1dR",
        "outputId": "2e58715f-a7a7-4246-a87a-73d835d2978d"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "64/64 [==============================] - 23s 78ms/step - loss: 0.0104\n",
            "Epoch 2/75\n",
            "64/64 [==============================] - 5s 84ms/step - loss: 0.0039\n",
            "Epoch 3/75\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0035\n",
            "Epoch 4/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0033\n",
            "Epoch 5/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0031\n",
            "Epoch 6/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0029\n",
            "Epoch 7/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0032\n",
            "Epoch 8/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0027\n",
            "Epoch 9/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0029\n",
            "Epoch 10/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0027\n",
            "Epoch 11/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0026\n",
            "Epoch 12/75\n",
            "64/64 [==============================] - 6s 91ms/step - loss: 0.0025\n",
            "Epoch 13/75\n",
            "64/64 [==============================] - 5s 82ms/step - loss: 0.0023\n",
            "Epoch 14/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0023\n",
            "Epoch 15/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0028\n",
            "Epoch 16/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0023\n",
            "Epoch 17/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0025\n",
            "Epoch 18/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0023\n",
            "Epoch 19/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0023\n",
            "Epoch 20/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0024\n",
            "Epoch 21/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0021\n",
            "Epoch 22/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0021\n",
            "Epoch 23/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0022\n",
            "Epoch 24/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0021\n",
            "Epoch 25/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0022\n",
            "Epoch 26/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0021\n",
            "Epoch 27/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0022\n",
            "Epoch 28/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0022\n",
            "Epoch 29/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0022\n",
            "Epoch 30/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0021\n",
            "Epoch 31/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0020\n",
            "Epoch 32/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0020\n",
            "Epoch 33/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0019\n",
            "Epoch 34/75\n",
            "64/64 [==============================] - 5s 73ms/step - loss: 0.0019\n",
            "Epoch 35/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0021\n",
            "Epoch 36/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0021\n",
            "Epoch 37/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0019\n",
            "Epoch 38/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0020\n",
            "Epoch 39/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0019\n",
            "Epoch 40/75\n",
            "64/64 [==============================] - 5s 73ms/step - loss: 0.0019\n",
            "Epoch 41/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0019\n",
            "Epoch 42/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0020\n",
            "Epoch 43/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0020\n",
            "Epoch 44/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0019\n",
            "Epoch 45/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0019\n",
            "Epoch 46/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0020\n",
            "Epoch 47/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0019\n",
            "Epoch 48/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0019\n",
            "Epoch 49/75\n",
            "64/64 [==============================] - 5s 73ms/step - loss: 0.0019\n",
            "Epoch 50/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0019\n",
            "Epoch 51/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0018\n",
            "Epoch 52/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0018\n",
            "Epoch 53/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0019\n",
            "Epoch 54/75\n",
            "64/64 [==============================] - 7s 114ms/step - loss: 0.0018\n",
            "Epoch 55/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0019\n",
            "Epoch 56/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0018\n",
            "Epoch 57/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0017\n",
            "Epoch 58/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0017\n",
            "Epoch 59/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0019\n",
            "Epoch 60/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0018\n",
            "Epoch 61/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0018\n",
            "Epoch 62/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0017\n",
            "Epoch 63/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0017\n",
            "Epoch 64/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0016\n",
            "Epoch 65/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0017\n",
            "Epoch 66/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0018\n",
            "Epoch 67/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0016\n",
            "Epoch 68/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0018\n",
            "Epoch 69/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0017\n",
            "Epoch 70/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0018\n",
            "Epoch 71/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0017\n",
            "Epoch 72/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0016\n",
            "Epoch 73/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0017\n",
            "Epoch 74/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0017\n",
            "Epoch 75/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0017\n",
            "63/63 [==============================] - 2s 14ms/step\n",
            "Epoch 1/75\n",
            "64/64 [==============================] - 18s 74ms/step - loss: 0.0109\n",
            "Epoch 2/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0039\n",
            "Epoch 3/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0037\n",
            "Epoch 4/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0034\n",
            "Epoch 5/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0030\n",
            "Epoch 6/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0031\n",
            "Epoch 7/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0028\n",
            "Epoch 8/75\n",
            "64/64 [==============================] - 5s 84ms/step - loss: 0.0028\n",
            "Epoch 9/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0025\n",
            "Epoch 10/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0027\n",
            "Epoch 11/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0025\n",
            "Epoch 12/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0024\n",
            "Epoch 13/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0027\n",
            "Epoch 14/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0025\n",
            "Epoch 15/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0024\n",
            "Epoch 16/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0023\n",
            "Epoch 17/75\n",
            "64/64 [==============================] - 5s 73ms/step - loss: 0.0023\n",
            "Epoch 18/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0024\n",
            "Epoch 19/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0022\n",
            "Epoch 20/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0022\n",
            "Epoch 21/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0024\n",
            "Epoch 22/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0023\n",
            "Epoch 23/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0021\n",
            "Epoch 24/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0022\n",
            "Epoch 25/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0022\n",
            "Epoch 26/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0023\n",
            "Epoch 27/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0022\n",
            "Epoch 28/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0020\n",
            "Epoch 29/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0020\n",
            "Epoch 30/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0019\n",
            "Epoch 31/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0019\n",
            "Epoch 32/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0021\n",
            "Epoch 33/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0020\n",
            "Epoch 34/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0021\n",
            "Epoch 35/75\n",
            "64/64 [==============================] - 6s 87ms/step - loss: 0.0020\n",
            "Epoch 36/75\n",
            "64/64 [==============================] - 7s 102ms/step - loss: 0.0019\n",
            "Epoch 37/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0020\n",
            "Epoch 38/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0019\n",
            "Epoch 39/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0019\n",
            "Epoch 40/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0019\n",
            "Epoch 41/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0019\n",
            "Epoch 42/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0019\n",
            "Epoch 43/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0020\n",
            "Epoch 44/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0018\n",
            "Epoch 45/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0019\n",
            "Epoch 46/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0020\n",
            "Epoch 47/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0019\n",
            "Epoch 48/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0020\n",
            "Epoch 49/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0018\n",
            "Epoch 50/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0018\n",
            "Epoch 51/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0018\n",
            "Epoch 52/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0019\n",
            "Epoch 53/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0018\n",
            "Epoch 54/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0019\n",
            "Epoch 55/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0018\n",
            "Epoch 56/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0017\n",
            "Epoch 57/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0018\n",
            "Epoch 58/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0020\n",
            "Epoch 59/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0017\n",
            "Epoch 60/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0019\n",
            "Epoch 61/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0017\n",
            "Epoch 62/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0017\n",
            "Epoch 63/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0017\n",
            "Epoch 64/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0017\n",
            "Epoch 65/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0017\n",
            "Epoch 66/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0017\n",
            "Epoch 67/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0018\n",
            "Epoch 68/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0018\n",
            "Epoch 69/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0017\n",
            "Epoch 70/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0017\n",
            "Epoch 71/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0017\n",
            "Epoch 72/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0017\n",
            "Epoch 73/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0016\n",
            "Epoch 74/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0017\n",
            "Epoch 75/75\n",
            "64/64 [==============================] - 5s 73ms/step - loss: 0.0016\n",
            "63/63 [==============================] - 3s 16ms/step\n",
            "Epoch 1/75\n",
            "64/64 [==============================] - 18s 75ms/step - loss: 0.0094\n",
            "Epoch 2/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0042\n",
            "Epoch 3/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0037\n",
            "Epoch 4/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0034\n",
            "Epoch 5/75\n",
            "64/64 [==============================] - 5s 73ms/step - loss: 0.0029\n",
            "Epoch 6/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0029\n",
            "Epoch 7/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0029\n",
            "Epoch 8/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0027\n",
            "Epoch 9/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0028\n",
            "Epoch 10/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0028\n",
            "Epoch 11/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0025\n",
            "Epoch 12/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0024\n",
            "Epoch 13/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0024\n",
            "Epoch 14/75\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0025\n",
            "Epoch 15/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0026\n",
            "Epoch 16/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0023\n",
            "Epoch 17/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0023\n",
            "Epoch 18/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0023\n",
            "Epoch 19/75\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.0022\n",
            "Epoch 20/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0022\n",
            "Epoch 21/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0022\n",
            "Epoch 22/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0022\n",
            "Epoch 23/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0022\n",
            "Epoch 24/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0022\n",
            "Epoch 25/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0021\n",
            "Epoch 26/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0022\n",
            "Epoch 27/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0022\n",
            "Epoch 28/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0022\n",
            "Epoch 29/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0020\n",
            "Epoch 30/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0020\n",
            "Epoch 31/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0021\n",
            "Epoch 32/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0021\n",
            "Epoch 33/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0021\n",
            "Epoch 34/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0020\n",
            "Epoch 35/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0020\n",
            "Epoch 36/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0019\n",
            "Epoch 37/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0020\n",
            "Epoch 38/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0021\n",
            "Epoch 39/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0019\n",
            "Epoch 40/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0020\n",
            "Epoch 41/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0019\n",
            "Epoch 42/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0019\n",
            "Epoch 43/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0021\n",
            "Epoch 44/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0019\n",
            "Epoch 45/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0019\n",
            "Epoch 46/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0020\n",
            "Epoch 47/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0019\n",
            "Epoch 48/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0018\n",
            "Epoch 49/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0019\n",
            "Epoch 50/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0020\n",
            "Epoch 51/75\n",
            "64/64 [==============================] - 10s 155ms/step - loss: 0.0018\n",
            "Epoch 52/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0020\n",
            "Epoch 53/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0018\n",
            "Epoch 54/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0019\n",
            "Epoch 55/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0018\n",
            "Epoch 56/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0018\n",
            "Epoch 57/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0018\n",
            "Epoch 58/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0020\n",
            "Epoch 59/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0019\n",
            "Epoch 60/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0018\n",
            "Epoch 61/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0017\n",
            "Epoch 62/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0017\n",
            "Epoch 63/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0018\n",
            "Epoch 64/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0018\n",
            "Epoch 65/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0018\n",
            "Epoch 66/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0018\n",
            "Epoch 67/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0019\n",
            "Epoch 68/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0018\n",
            "Epoch 69/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0017\n",
            "Epoch 70/75\n",
            "64/64 [==============================] - 7s 106ms/step - loss: 0.0017\n",
            "Epoch 71/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0017\n",
            "Epoch 72/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0017\n",
            "Epoch 73/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0016\n",
            "Epoch 74/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0016\n",
            "Epoch 75/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0016\n",
            "63/63 [==============================] - 2s 15ms/step\n",
            "Epoch 1/75\n",
            "64/64 [==============================] - 18s 77ms/step - loss: 0.0106\n",
            "Epoch 2/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0042\n",
            "Epoch 3/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0037\n",
            "Epoch 4/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0036\n",
            "Epoch 5/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0037\n",
            "Epoch 6/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0031\n",
            "Epoch 7/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0031\n",
            "Epoch 8/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0030\n",
            "Epoch 9/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0029\n",
            "Epoch 10/75\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 0.0027\n",
            "Epoch 11/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0028\n",
            "Epoch 12/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0029\n",
            "Epoch 13/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0027\n",
            "Epoch 14/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0025\n",
            "Epoch 15/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0026\n",
            "Epoch 16/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0026\n",
            "Epoch 17/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0024\n",
            "Epoch 18/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0025\n",
            "Epoch 19/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0024\n",
            "Epoch 20/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0024\n",
            "Epoch 21/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0023\n",
            "Epoch 22/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0023\n",
            "Epoch 23/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0022\n",
            "Epoch 24/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0023\n",
            "Epoch 25/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0024\n",
            "Epoch 26/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0021\n",
            "Epoch 27/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0023\n",
            "Epoch 28/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0022\n",
            "Epoch 29/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0021\n",
            "Epoch 30/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0022\n",
            "Epoch 31/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0021\n",
            "Epoch 32/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0023\n",
            "Epoch 33/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0020\n",
            "Epoch 34/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0020\n",
            "Epoch 35/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0020\n",
            "Epoch 36/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0022\n",
            "Epoch 37/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0020\n",
            "Epoch 38/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0020\n",
            "Epoch 39/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0021\n",
            "Epoch 40/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0021\n",
            "Epoch 41/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0020\n",
            "Epoch 42/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0020\n",
            "Epoch 43/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0020\n",
            "Epoch 44/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0020\n",
            "Epoch 45/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0020\n",
            "Epoch 46/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0021\n",
            "Epoch 47/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0020\n",
            "Epoch 48/75\n",
            "64/64 [==============================] - 7s 105ms/step - loss: 0.0019\n",
            "Epoch 49/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0019\n",
            "Epoch 50/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0019\n",
            "Epoch 51/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0022\n",
            "Epoch 52/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0019\n",
            "Epoch 53/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0019\n",
            "Epoch 54/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0018\n",
            "Epoch 55/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0020\n",
            "Epoch 56/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0019\n",
            "Epoch 57/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0019\n",
            "Epoch 58/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0018\n",
            "Epoch 59/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0019\n",
            "Epoch 60/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0018\n",
            "Epoch 61/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0018\n",
            "Epoch 62/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0018\n",
            "Epoch 63/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0019\n",
            "Epoch 64/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0018\n",
            "Epoch 65/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0018\n",
            "Epoch 66/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0018\n",
            "Epoch 67/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0017\n",
            "Epoch 68/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0019\n",
            "Epoch 69/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0017\n",
            "Epoch 70/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0019\n",
            "Epoch 71/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0018\n",
            "Epoch 72/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0017\n",
            "Epoch 73/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0018\n",
            "Epoch 74/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0018\n",
            "Epoch 75/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0017\n",
            "63/63 [==============================] - 2s 15ms/step\n",
            "Epoch 1/75\n",
            "64/64 [==============================] - 19s 80ms/step - loss: 0.0097\n",
            "Epoch 2/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0041\n",
            "Epoch 3/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0037\n",
            "Epoch 4/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0033\n",
            "Epoch 5/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0031\n",
            "Epoch 6/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0029\n",
            "Epoch 7/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0029\n",
            "Epoch 8/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0028\n",
            "Epoch 9/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0027\n",
            "Epoch 10/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0027\n",
            "Epoch 11/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0026\n",
            "Epoch 12/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0025\n",
            "Epoch 13/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0024\n",
            "Epoch 14/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0024\n",
            "Epoch 15/75\n",
            "64/64 [==============================] - 5s 84ms/step - loss: 0.0024\n",
            "Epoch 16/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0025\n",
            "Epoch 17/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0023\n",
            "Epoch 18/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0023\n",
            "Epoch 19/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0023\n",
            "Epoch 20/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0023\n",
            "Epoch 21/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0023\n",
            "Epoch 22/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0022\n",
            "Epoch 23/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0021\n",
            "Epoch 24/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0021\n",
            "Epoch 25/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0020\n",
            "Epoch 26/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0022\n",
            "Epoch 27/75\n",
            "64/64 [==============================] - 7s 106ms/step - loss: 0.0022\n",
            "Epoch 28/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0023\n",
            "Epoch 29/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0021\n",
            "Epoch 30/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0020\n",
            "Epoch 31/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0021\n",
            "Epoch 32/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0022\n",
            "Epoch 33/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0020\n",
            "Epoch 34/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0023\n",
            "Epoch 35/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0021\n",
            "Epoch 36/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0019\n",
            "Epoch 37/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0019\n",
            "Epoch 38/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0020\n",
            "Epoch 39/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0019\n",
            "Epoch 40/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0019\n",
            "Epoch 41/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0019\n",
            "Epoch 42/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0019\n",
            "Epoch 43/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0019\n",
            "Epoch 44/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0018\n",
            "Epoch 45/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0019\n",
            "Epoch 46/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0019\n",
            "Epoch 47/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0019\n",
            "Epoch 48/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0019\n",
            "Epoch 49/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0019\n",
            "Epoch 50/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0018\n",
            "Epoch 51/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0018\n",
            "Epoch 52/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0019\n",
            "Epoch 53/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0018\n",
            "Epoch 54/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0018\n",
            "Epoch 55/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0017\n",
            "Epoch 56/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0018\n",
            "Epoch 57/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0018\n",
            "Epoch 58/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0017\n",
            "Epoch 59/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0019\n",
            "Epoch 60/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0018\n",
            "Epoch 61/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0018\n",
            "Epoch 62/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0016\n",
            "Epoch 63/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0018\n",
            "Epoch 64/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0017\n",
            "Epoch 65/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0017\n",
            "Epoch 66/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0017\n",
            "Epoch 67/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0018\n",
            "Epoch 68/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0018\n",
            "Epoch 69/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0017\n",
            "Epoch 70/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0017\n",
            "Epoch 71/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0018\n",
            "Epoch 72/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0017\n",
            "Epoch 73/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0018\n",
            "Epoch 74/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0017\n",
            "Epoch 75/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0016\n",
            "63/63 [==============================] - 2s 15ms/step\n",
            "Epoch 1/75\n",
            "64/64 [==============================] - 18s 78ms/step - loss: 0.0101\n",
            "Epoch 2/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0038\n",
            "Epoch 3/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0036\n",
            "Epoch 4/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0032\n",
            "Epoch 5/75\n",
            "64/64 [==============================] - 6s 94ms/step - loss: 0.0032\n",
            "Epoch 6/75\n",
            "64/64 [==============================] - 6s 88ms/step - loss: 0.0030\n",
            "Epoch 7/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0027\n",
            "Epoch 8/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0028\n",
            "Epoch 9/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0027\n",
            "Epoch 10/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0026\n",
            "Epoch 11/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0027\n",
            "Epoch 12/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0025\n",
            "Epoch 13/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0026\n",
            "Epoch 14/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0024\n",
            "Epoch 15/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0024\n",
            "Epoch 16/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0023\n",
            "Epoch 17/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0025\n",
            "Epoch 18/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0023\n",
            "Epoch 19/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0025\n",
            "Epoch 20/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0025\n",
            "Epoch 21/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0021\n",
            "Epoch 22/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0021\n",
            "Epoch 23/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0020\n",
            "Epoch 24/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0021\n",
            "Epoch 25/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0022\n",
            "Epoch 26/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0022\n",
            "Epoch 27/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0020\n",
            "Epoch 28/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0020\n",
            "Epoch 29/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0021\n",
            "Epoch 30/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0020\n",
            "Epoch 31/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0021\n",
            "Epoch 32/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0021\n",
            "Epoch 33/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0022\n",
            "Epoch 34/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0019\n",
            "Epoch 35/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0019\n",
            "Epoch 36/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0019\n",
            "Epoch 37/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0019\n",
            "Epoch 38/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0020\n",
            "Epoch 39/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0020\n",
            "Epoch 40/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0019\n",
            "Epoch 41/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0019\n",
            "Epoch 42/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0018\n",
            "Epoch 43/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0019\n",
            "Epoch 44/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0021\n",
            "Epoch 45/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0019\n",
            "Epoch 46/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0019\n",
            "Epoch 47/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0019\n",
            "Epoch 48/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0018\n",
            "Epoch 49/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0021\n",
            "Epoch 50/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0019\n",
            "Epoch 51/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0018\n",
            "Epoch 52/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0018\n",
            "Epoch 53/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0018\n",
            "Epoch 54/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0019\n",
            "Epoch 55/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0020\n",
            "Epoch 56/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0019\n",
            "Epoch 57/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0017\n",
            "Epoch 58/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0018\n",
            "Epoch 59/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0017\n",
            "Epoch 60/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0016\n",
            "Epoch 61/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0017\n",
            "Epoch 62/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0018\n",
            "Epoch 63/75\n",
            "64/64 [==============================] - 5s 85ms/step - loss: 0.0018\n",
            "Epoch 64/75\n",
            "64/64 [==============================] - 6s 95ms/step - loss: 0.0018\n",
            "Epoch 65/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0018\n",
            "Epoch 66/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0019\n",
            "Epoch 67/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0020\n",
            "Epoch 68/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0017\n",
            "Epoch 69/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0017\n",
            "Epoch 70/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0018\n",
            "Epoch 71/75\n",
            "64/64 [==============================] - 5s 76ms/step - loss: 0.0017\n",
            "Epoch 72/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0016\n",
            "Epoch 73/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0018\n",
            "Epoch 74/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0016\n",
            "Epoch 75/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0017\n",
            "63/63 [==============================] - 2s 15ms/step\n",
            "Epoch 1/75\n",
            "64/64 [==============================] - 19s 78ms/step - loss: 0.0103\n",
            "Epoch 2/75\n",
            "64/64 [==============================] - 5s 84ms/step - loss: 0.0039\n",
            "Epoch 3/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0035\n",
            "Epoch 4/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0033\n",
            "Epoch 5/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0032\n",
            "Epoch 6/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0029\n",
            "Epoch 7/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0030\n",
            "Epoch 8/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0030\n",
            "Epoch 9/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0026\n",
            "Epoch 10/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0025\n",
            "Epoch 11/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0026\n",
            "Epoch 12/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0025\n",
            "Epoch 13/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0026\n",
            "Epoch 14/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0024\n",
            "Epoch 15/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0023\n",
            "Epoch 16/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0025\n",
            "Epoch 17/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0023\n",
            "Epoch 18/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0023\n",
            "Epoch 19/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0023\n",
            "Epoch 20/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0022\n",
            "Epoch 21/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0023\n",
            "Epoch 22/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0022\n",
            "Epoch 23/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0023\n",
            "Epoch 24/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0022\n",
            "Epoch 25/75\n",
            "64/64 [==============================] - 5s 82ms/step - loss: 0.0021\n",
            "Epoch 26/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0022\n",
            "Epoch 27/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0021\n",
            "Epoch 28/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0021\n",
            "Epoch 29/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0021\n",
            "Epoch 30/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0021\n",
            "Epoch 31/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0021\n",
            "Epoch 32/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0020\n",
            "Epoch 33/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0022\n",
            "Epoch 34/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0020\n",
            "Epoch 35/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0020\n",
            "Epoch 36/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0020\n",
            "Epoch 37/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0020\n",
            "Epoch 38/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0021\n",
            "Epoch 39/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0020\n",
            "Epoch 40/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0019\n",
            "Epoch 41/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0023\n",
            "Epoch 42/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0019\n",
            "Epoch 43/75\n",
            "64/64 [==============================] - 7s 105ms/step - loss: 0.0018\n",
            "Epoch 44/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0020\n",
            "Epoch 45/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0019\n",
            "Epoch 46/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0019\n",
            "Epoch 47/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0019\n",
            "Epoch 48/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0018\n",
            "Epoch 49/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0019\n",
            "Epoch 50/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0018\n",
            "Epoch 51/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0018\n",
            "Epoch 52/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0018\n",
            "Epoch 53/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0018\n",
            "Epoch 54/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0018\n",
            "Epoch 55/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0019\n",
            "Epoch 56/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0017\n",
            "Epoch 57/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0017\n",
            "Epoch 58/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0018\n",
            "Epoch 59/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0017\n",
            "Epoch 60/75\n",
            "64/64 [==============================] - 5s 82ms/step - loss: 0.0018\n",
            "Epoch 61/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0017\n",
            "Epoch 62/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0017\n",
            "Epoch 63/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0018\n",
            "Epoch 64/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0017\n",
            "Epoch 65/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0017\n",
            "Epoch 66/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0019\n",
            "Epoch 67/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0018\n",
            "Epoch 68/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0017\n",
            "Epoch 69/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0017\n",
            "Epoch 70/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0016\n",
            "Epoch 71/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0017\n",
            "Epoch 72/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0016\n",
            "Epoch 73/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0016\n",
            "Epoch 74/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0016\n",
            "Epoch 75/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0017\n",
            "63/63 [==============================] - 3s 16ms/step\n",
            "Epoch 1/75\n",
            "64/64 [==============================] - 18s 80ms/step - loss: 0.0099\n",
            "Epoch 2/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0042\n",
            "Epoch 3/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0037\n",
            "Epoch 4/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0033\n",
            "Epoch 5/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0031\n",
            "Epoch 6/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0030\n",
            "Epoch 7/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0031\n",
            "Epoch 8/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0027\n",
            "Epoch 9/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0028\n",
            "Epoch 10/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0026\n",
            "Epoch 11/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0025\n",
            "Epoch 12/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0025\n",
            "Epoch 13/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0025\n",
            "Epoch 14/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0025\n",
            "Epoch 15/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0025\n",
            "Epoch 16/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0023\n",
            "Epoch 17/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0024\n",
            "Epoch 18/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0024\n",
            "Epoch 19/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0022\n",
            "Epoch 20/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0024\n",
            "Epoch 21/75\n",
            "64/64 [==============================] - 7s 108ms/step - loss: 0.0022\n",
            "Epoch 22/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0023\n",
            "Epoch 23/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0022\n",
            "Epoch 24/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0022\n",
            "Epoch 25/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0024\n",
            "Epoch 26/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0021\n",
            "Epoch 27/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0022\n",
            "Epoch 28/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0021\n",
            "Epoch 29/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0021\n",
            "Epoch 30/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0020\n",
            "Epoch 31/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0020\n",
            "Epoch 32/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0020\n",
            "Epoch 33/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0019\n",
            "Epoch 34/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0020\n",
            "Epoch 35/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0021\n",
            "Epoch 36/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0020\n",
            "Epoch 37/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0020\n",
            "Epoch 38/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0020\n",
            "Epoch 39/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0019\n",
            "Epoch 40/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0019\n",
            "Epoch 41/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0019\n",
            "Epoch 42/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0019\n",
            "Epoch 43/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0019\n",
            "Epoch 44/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0019\n",
            "Epoch 45/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0019\n",
            "Epoch 46/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0019\n",
            "Epoch 47/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0019\n",
            "Epoch 48/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0018\n",
            "Epoch 49/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0019\n",
            "Epoch 50/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0019\n",
            "Epoch 51/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0018\n",
            "Epoch 52/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0018\n",
            "Epoch 53/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0018\n",
            "Epoch 54/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0020\n",
            "Epoch 55/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0019\n",
            "Epoch 56/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0019\n",
            "Epoch 57/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0018\n",
            "Epoch 58/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0018\n",
            "Epoch 59/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0017\n",
            "Epoch 60/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0019\n",
            "Epoch 61/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0018\n",
            "Epoch 62/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0017\n",
            "Epoch 63/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0018\n",
            "Epoch 64/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0018\n",
            "Epoch 65/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0017\n",
            "Epoch 66/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0018\n",
            "Epoch 67/75\n",
            "64/64 [==============================] - 5s 82ms/step - loss: 0.0018\n",
            "Epoch 68/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0017\n",
            "Epoch 69/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0017\n",
            "Epoch 70/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0017\n",
            "Epoch 71/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0018\n",
            "Epoch 72/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0017\n",
            "Epoch 73/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0019\n",
            "Epoch 74/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0017\n",
            "Epoch 75/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0017\n",
            "63/63 [==============================] - 3s 18ms/step\n",
            "Epoch 1/75\n",
            "64/64 [==============================] - 19s 78ms/step - loss: 0.0101\n",
            "Epoch 2/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0039\n",
            "Epoch 3/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0036\n",
            "Epoch 4/75\n",
            "64/64 [==============================] - 5s 77ms/step - loss: 0.0033\n",
            "Epoch 5/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0033\n",
            "Epoch 6/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0032\n",
            "Epoch 7/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0029\n",
            "Epoch 8/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0028\n",
            "Epoch 9/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0028\n",
            "Epoch 10/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0029\n",
            "Epoch 11/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0026\n",
            "Epoch 12/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0026\n",
            "Epoch 13/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0025\n",
            "Epoch 14/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0025\n",
            "Epoch 15/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0024\n",
            "Epoch 16/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0024\n",
            "Epoch 17/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0024\n",
            "Epoch 18/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0025\n",
            "Epoch 19/75\n",
            "64/64 [==============================] - 5s 82ms/step - loss: 0.0024\n",
            "Epoch 20/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0024\n",
            "Epoch 21/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0023\n",
            "Epoch 22/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0021\n",
            "Epoch 23/75\n",
            "64/64 [==============================] - 5s 82ms/step - loss: 0.0023\n",
            "Epoch 24/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0021\n",
            "Epoch 25/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0021\n",
            "Epoch 26/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0021\n",
            "Epoch 27/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0021\n",
            "Epoch 28/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0022\n",
            "Epoch 29/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0022\n",
            "Epoch 30/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0023\n",
            "Epoch 31/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0021\n",
            "Epoch 32/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0021\n",
            "Epoch 33/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0022\n",
            "Epoch 34/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0020\n",
            "Epoch 35/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0020\n",
            "Epoch 36/75\n",
            "64/64 [==============================] - 5s 82ms/step - loss: 0.0020\n",
            "Epoch 37/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0020\n",
            "Epoch 38/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0021\n",
            "Epoch 39/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0020\n",
            "Epoch 40/75\n",
            "64/64 [==============================] - 5s 82ms/step - loss: 0.0020\n",
            "Epoch 41/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0021\n",
            "Epoch 42/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0020\n",
            "Epoch 43/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0019\n",
            "Epoch 44/75\n",
            "64/64 [==============================] - 5s 82ms/step - loss: 0.0018\n",
            "Epoch 45/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0019\n",
            "Epoch 46/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0018\n",
            "Epoch 47/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0019\n",
            "Epoch 48/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0020\n",
            "Epoch 49/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0019\n",
            "Epoch 50/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0019\n",
            "Epoch 51/75\n",
            "64/64 [==============================] - 5s 85ms/step - loss: 0.0020\n",
            "Epoch 52/75\n",
            "64/64 [==============================] - 5s 82ms/step - loss: 0.0018\n",
            "Epoch 53/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0018\n",
            "Epoch 54/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0019\n",
            "Epoch 55/75\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0019\n",
            "Epoch 56/75\n",
            "64/64 [==============================] - 5s 83ms/step - loss: 0.0018\n",
            "Epoch 57/75\n",
            "64/64 [==============================] - 5s 82ms/step - loss: 0.0017\n",
            "Epoch 58/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0018\n",
            "Epoch 59/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0018\n",
            "Epoch 60/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0018\n",
            "Epoch 61/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0018\n",
            "Epoch 62/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0018\n",
            "Epoch 63/75\n",
            "64/64 [==============================] - 5s 82ms/step - loss: 0.0017\n",
            "Epoch 64/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0018\n",
            "Epoch 65/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0017\n",
            "Epoch 66/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0018\n",
            "Epoch 67/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0017\n",
            "Epoch 68/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0017\n",
            "Epoch 69/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0018\n",
            "Epoch 70/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0017\n",
            "Epoch 71/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0017\n",
            "Epoch 72/75\n",
            "64/64 [==============================] - 5s 82ms/step - loss: 0.0018\n",
            "Epoch 73/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0018\n",
            "Epoch 74/75\n",
            "64/64 [==============================] - 5s 85ms/step - loss: 0.0017\n",
            "Epoch 75/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0017\n",
            "63/63 [==============================] - 3s 18ms/step\n",
            "Epoch 1/75\n",
            "64/64 [==============================] - 18s 79ms/step - loss: 0.0094\n",
            "Epoch 2/75\n",
            "64/64 [==============================] - 5s 82ms/step - loss: 0.0046\n",
            "Epoch 3/75\n",
            "64/64 [==============================] - 5s 83ms/step - loss: 0.0038\n",
            "Epoch 4/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0035\n",
            "Epoch 5/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0032\n",
            "Epoch 6/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0032\n",
            "Epoch 7/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0029\n",
            "Epoch 8/75\n",
            "64/64 [==============================] - 5s 82ms/step - loss: 0.0026\n",
            "Epoch 9/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0027\n",
            "Epoch 10/75\n",
            "64/64 [==============================] - 5s 83ms/step - loss: 0.0027\n",
            "Epoch 11/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0027\n",
            "Epoch 12/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0025\n",
            "Epoch 13/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0024\n",
            "Epoch 14/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0025\n",
            "Epoch 15/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0025\n",
            "Epoch 16/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0025\n",
            "Epoch 17/75\n",
            "64/64 [==============================] - 5s 83ms/step - loss: 0.0023\n",
            "Epoch 18/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0022\n",
            "Epoch 19/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0022\n",
            "Epoch 20/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0023\n",
            "Epoch 21/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0024\n",
            "Epoch 22/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0024\n",
            "Epoch 23/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0022\n",
            "Epoch 24/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0022\n",
            "Epoch 25/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0021\n",
            "Epoch 26/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0021\n",
            "Epoch 27/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0020\n",
            "Epoch 28/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0022\n",
            "Epoch 29/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0021\n",
            "Epoch 30/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0020\n",
            "Epoch 31/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0021\n",
            "Epoch 32/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0020\n",
            "Epoch 33/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0020\n",
            "Epoch 34/75\n",
            "64/64 [==============================] - 7s 106ms/step - loss: 0.0019\n",
            "Epoch 35/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0019\n",
            "Epoch 36/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0019\n",
            "Epoch 37/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0020\n",
            "Epoch 38/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0020\n",
            "Epoch 39/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0020\n",
            "Epoch 40/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0019\n",
            "Epoch 41/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0021\n",
            "Epoch 42/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0019\n",
            "Epoch 43/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0020\n",
            "Epoch 44/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0019\n",
            "Epoch 45/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0019\n",
            "Epoch 46/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0020\n",
            "Epoch 47/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0019\n",
            "Epoch 48/75\n",
            "64/64 [==============================] - 5s 82ms/step - loss: 0.0019\n",
            "Epoch 49/75\n",
            "64/64 [==============================] - 5s 82ms/step - loss: 0.0018\n",
            "Epoch 50/75\n",
            "64/64 [==============================] - 5s 83ms/step - loss: 0.0017\n",
            "Epoch 51/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0018\n",
            "Epoch 52/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0022\n",
            "Epoch 53/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0020\n",
            "Epoch 54/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0019\n",
            "Epoch 55/75\n",
            "64/64 [==============================] - 5s 83ms/step - loss: 0.0018\n",
            "Epoch 56/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0018\n",
            "Epoch 57/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0018\n",
            "Epoch 58/75\n",
            "64/64 [==============================] - 5s 78ms/step - loss: 0.0019\n",
            "Epoch 59/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0019\n",
            "Epoch 60/75\n",
            "64/64 [==============================] - 5s 82ms/step - loss: 0.0018\n",
            "Epoch 61/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0018\n",
            "Epoch 62/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0017\n",
            "Epoch 63/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0018\n",
            "Epoch 64/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0017\n",
            "Epoch 65/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0017\n",
            "Epoch 66/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0018\n",
            "Epoch 67/75\n",
            "64/64 [==============================] - 5s 80ms/step - loss: 0.0017\n",
            "Epoch 68/75\n",
            "64/64 [==============================] - 5s 82ms/step - loss: 0.0018\n",
            "Epoch 69/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0017\n",
            "Epoch 70/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0018\n",
            "Epoch 71/75\n",
            "64/64 [==============================] - 5s 82ms/step - loss: 0.0017\n",
            "Epoch 72/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0017\n",
            "Epoch 73/75\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0017\n",
            "Epoch 74/75\n",
            "64/64 [==============================] - 5s 81ms/step - loss: 0.0016\n",
            "Epoch 75/75\n",
            "64/64 [==============================] - 5s 83ms/step - loss: 0.0017\n",
            "63/63 [==============================] - 3s 17ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss)"
      ],
      "metadata": {
        "id": "MnuUdKWaqgaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09903223-967a-40c9-c76d-8f9c876af18e"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.055112968144810454, 0.05452275122526007, 0.05311156467651334, 0.052870170453822814, 0.05474330241313237, 0.05183350757212422, 0.05442215562568959, 0.05269795003012481, 0.05268793895307243, 0.05411695365980893]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(min(loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56ykd7kawkvX",
        "outputId": "e180ff55-988c-425c-d655-a891ec1e5561"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05183350757212422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "5KwbVjdXKn01"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss)"
      ],
      "metadata": {
        "id": "O622nEj3Krt7",
        "outputId": "509655ee-8461-4579-8caa-21c3cb80ba42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f75a0f04b50>]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}