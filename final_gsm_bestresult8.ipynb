{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DIPANJAN001/Forecasting-Solar-Energy/blob/master/final_gsm_bestresult8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzs_vH9vlX74",
        "outputId": "6087f7c9-5384-4949-f9d3-dd63f8d6b745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Boruta in /usr/local/lib/python3.8/dist-packages (0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.0.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.17.1->Boruta) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.17.1->Boruta) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install Boruta\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from boruta import BorutaPy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import concatenate\n",
        "from keras import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Bidirectional\n",
        "from keras import layers\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import load_model\n",
        "from keras.layers import Input\n",
        "from sklearn.decomposition import PCA "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "lDilv4v2lz-w"
      },
      "outputs": [],
      "source": [
        "def lstm_data_transform(x_data, y_data, num_steps):\n",
        "    \"\"\" Changes data to the format for LSTM training \n",
        "for sliding window approach \"\"\"\n",
        "    # Prepare the list for the transformed data\n",
        "    X, y = list(), list()\n",
        "    # Loop of the entire data set\n",
        "    for i in range(x_data.shape[0]):\n",
        "        # compute a new (sliding window) index\n",
        "        end_ix = i + num_steps\n",
        "        # if index is larger than the size of the dataset, we stop\n",
        "        if end_ix >= x_data.shape[0]:\n",
        "            break\n",
        "        # Get a sequence of data for x\n",
        "        seq_X = x_data[i:end_ix]\n",
        "        # Get only the last element of the sequency for y\n",
        "        seq_y = y_data[end_ix]\n",
        "        # Append the list with sequencies\n",
        "        X.append(seq_X)\n",
        "        y.append(seq_y)\n",
        "    # Make final arrays\n",
        "    x_array = np.array(X)\n",
        "    y_array = np.array(y)\n",
        "    return x_array, y_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "iQt_oZP7QczL"
      },
      "outputs": [],
      "source": [
        "df=pd.read_excel(\"/content/pv_01.xlsx\")\n",
        "weather_input1=df.drop('power_normed',axis=1)\n",
        "weather_input=weather_input1.drop('time_idx',axis=1)\n",
        "solpow=df['power_normed']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoPnMw4oQQlc",
        "outputId": "3e0dc082-8b6b-4bd7-a996-4695a665da7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: \t1 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t2 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t3 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t4 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t5 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t6 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t7 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t8 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t11\n",
            "Rejected: \t27\n",
            "Iteration: \t9 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t11\n",
            "Rejected: \t27\n",
            "Iteration: \t10 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t11\n",
            "Rejected: \t27\n",
            "Iteration: \t11 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t11\n",
            "Rejected: \t27\n",
            "Iteration: \t12 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t9\n",
            "Rejected: \t27\n",
            "Iteration: \t13 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t8\n",
            "Rejected: \t28\n",
            "Iteration: \t14 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t8\n",
            "Rejected: \t28\n",
            "Iteration: \t15 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t8\n",
            "Rejected: \t28\n",
            "Iteration: \t16 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t8\n",
            "Rejected: \t28\n",
            "Iteration: \t17 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t8\n",
            "Rejected: \t28\n",
            "Iteration: \t18 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t8\n",
            "Rejected: \t28\n",
            "Iteration: \t19 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t8\n",
            "Rejected: \t28\n",
            "Iteration: \t20 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t8\n",
            "Rejected: \t28\n",
            "Iteration: \t21 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t8\n",
            "Rejected: \t28\n",
            "Iteration: \t22 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t7\n",
            "Rejected: \t29\n",
            "Iteration: \t23 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t7\n",
            "Rejected: \t29\n",
            "Iteration: \t24 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t7\n",
            "Rejected: \t29\n",
            "Iteration: \t25 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t7\n",
            "Rejected: \t29\n",
            "Iteration: \t26 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t27 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t28 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t29 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t30 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t31 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t32 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t33 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t34 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t35 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t36 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t37 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t38 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t39 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t40 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t41 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t42 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t43 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t44 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t45 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t46 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t47 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t48 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t49 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t50 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t51 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t52 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t53 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t54 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t55 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t56 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t57 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t58 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t59 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t60 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t61 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t62 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t63 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t64 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t65 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t66 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t67 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t68 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t69 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t70 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t71 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t72 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t73 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t74 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t75 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t76 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t77 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t78 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t79 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t80 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t81 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t82 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t83 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t84 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t85 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t86 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t87 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t88 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t89 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t90 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t91 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t92 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t93 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t94 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t95 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t96 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t97 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t98 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t99 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "\n",
            "\n",
            "BorutaPy finished running.\n",
            "\n",
            "Iteration: \t100 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BorutaPy(estimator=RandomForestRegressor(max_depth=7, n_estimators=88,\n",
              "                                         random_state=RandomState(MT19937) at 0x7F75655A7D40),\n",
              "         n_estimators='auto',\n",
              "         random_state=RandomState(MT19937) at 0x7F75655A7D40, verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "rfc = RandomForestRegressor(random_state=1, n_estimators=1000, max_depth=7)\n",
        "boruta_selector = BorutaPy(rfc, n_estimators='auto', verbose=2, random_state=1)\n",
        "boruta_selector.fit(np.array(weather_input), np.array(solpow)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "u2NoSDCGUFNU"
      },
      "outputs": [],
      "source": [
        "X_important_train = boruta_selector.transform(np.array(weather_input))\n",
        "num_steps = 3\n",
        "# training set\n",
        "(x_transformed_train,\n",
        " y_transformed_train) = lstm_data_transform(X_important_train,solpow , num_steps=num_steps)\n",
        "assert x_transformed_train.shape[0] == y_transformed_train.shape[0]\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_transformed_train,y_transformed_train,test_size=0.25, random_state=42,shuffle=False)\n",
        "#X_train_,X_val,y_train_,y_val=train_test_split(X_train,y_train,test_size=0.2, random_state=42,shuffle=False)\n",
        "inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdKjqiCK5m_T",
        "outputId": "f00b8954-44d9-452e-a971-f284b6ba87b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 3, 16) dtype=float32 (created by layer 'input_4')>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "inputs1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "V27z-GjNapD4"
      },
      "outputs": [],
      "source": [
        "from keras import optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "uxD0diT8a4c2"
      },
      "outputs": [],
      "source": [
        "opt=optimizers.Adam(learning_rate=0.003)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "YM0Epc0yvWnJ"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "t0f48T0zsiAs"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "class HalvAdam(Adam):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.prev_gradients = None\n",
        "\n",
        "    @tf.function\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [math_ops.cast(x, \"float32\") for x in grads]\n",
        "\n",
        "        if self.prev_gradients is not None:\n",
        "            for i in range(len(grads)):\n",
        "                if (grads[i] * self.prev_gradients[i] < 0):\n",
        "                    self.updates[i] = self.updates[i] / 2\n",
        "\n",
        "        self.prev_gradients = grads\n",
        "        return self.updates"
      ],
      "metadata": {
        "id": "MpStRslgCRBO"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "cSM9vzEq3G3U"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "nq9ZwBIrI_qj"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "18n5dRvpuI5T"
      },
      "outputs": [],
      "source": [
        "def define_model():\n",
        "\n",
        "\n",
        "  fe2_0 = Bidirectional(LSTM(256, activation='relu',return_sequences = True))(inputs1)\n",
        "  fe2_1 = Dropout(0.6)(fe2_0)\n",
        "  fe2_2 = Bidirectional(LSTM(64, activation='relu',return_sequences = True))(fe2_1)\n",
        "  fe2_3= Dropout(0.5)(fe2_2)\n",
        "  fe2_4=Bidirectional(LSTM(4, activation='relu'))(fe2_3)\n",
        "  out2_1=Dense(1, activation='relu')(fe2_4)\n",
        "\n",
        "  fe3_0 =Bidirectional(LSTM(128, activation='relu',return_sequences = True))(inputs1)\n",
        "  fe3_1 = Dropout(0.6)(fe3_0)\n",
        "  fe3_2 = Bidirectional(LSTM(96, activation='relu',return_sequences = True))(fe3_1)\n",
        "  fe3_3= Dropout(0.5)(fe3_2)\n",
        "  fe3_4=Bidirectional(LSTM(8, activation='relu'))(fe3_3)#16\n",
        "  out3_1=Dense(1, activation='relu')(fe3_4)\n",
        " \n",
        " \n",
        "\n",
        "  output = layers.average([out2_1, out3_1])\n",
        "  #merged3 = concatenate([out2_1,out3_1], name='concat3')\n",
        "  #output = Dense(1, activation='relu')( merged3)\n",
        "  \n",
        "\n",
        "  model = Model(inputs=[inputs1], outputs=[output])\n",
        "  \n",
        " \n",
        "  return model\n",
        "mdl=define_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss=[]"
      ],
      "metadata": {
        "id": "P5UqekV1_q7F"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import clone_model"
      ],
      "metadata": {
        "id": "9zy5UX8p_zSl"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "dAICp2p5OCER"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "9iwWrmDs0z7O"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GlobalMinimaSearch(weights):\n",
        "  if len(loss)>9:\n",
        "   return\n",
        "  \n",
        "  initial_weights =weights\n",
        "  model=clone_model(mdl)\n",
        "  model.set_weights(weights)\n",
        "  model.compile(optimizer=HalvAdam(learning_rate=0.002), loss='mean_squared_error')\n",
        "  model.fit(X_train, y_train, epochs=75, batch_size=64)\n",
        "  y= model.predict(X_test)\n",
        "  loss.append(np.sqrt(mean_squared_error(y,y_test)))\n",
        "  best_weights= model.get_weights()\n",
        "\n",
        "\n",
        "  params_2 =[final_weight - (final_weight - initial_weight) for initial_weight, final_weight in zip(initial_weights, best_weights)]\n",
        "  GlobalMinimaSearch(params_2)\n",
        "  \n",
        " "
      ],
      "metadata": {
        "id": "FxpviTJb_nUR"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GlobalMinimaSearch(mdl.get_weights())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuddmGCf_1dR",
        "outputId": "44150af4-d5e4-459c-988d-1b892258f731"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "73/73 [==============================] - 20s 80ms/step - loss: 0.0149\n",
            "Epoch 2/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0068\n",
            "Epoch 3/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0067\n",
            "Epoch 4/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0063\n",
            "Epoch 5/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0060\n",
            "Epoch 6/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0059\n",
            "Epoch 7/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0058\n",
            "Epoch 8/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0054\n",
            "Epoch 9/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0057\n",
            "Epoch 10/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0053\n",
            "Epoch 11/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0053\n",
            "Epoch 12/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0052\n",
            "Epoch 13/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0051\n",
            "Epoch 14/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0050\n",
            "Epoch 15/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0050\n",
            "Epoch 16/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0050\n",
            "Epoch 17/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0050\n",
            "Epoch 18/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0050\n",
            "Epoch 19/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0050\n",
            "Epoch 20/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0054\n",
            "Epoch 21/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0052\n",
            "Epoch 22/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0053\n",
            "Epoch 23/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0052\n",
            "Epoch 24/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0050\n",
            "Epoch 25/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0047\n",
            "Epoch 26/75\n",
            "73/73 [==============================] - 7s 96ms/step - loss: 0.0048\n",
            "Epoch 27/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0049\n",
            "Epoch 28/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0049\n",
            "Epoch 29/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0047\n",
            "Epoch 30/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0047\n",
            "Epoch 31/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0048\n",
            "Epoch 32/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0047\n",
            "Epoch 33/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0046\n",
            "Epoch 34/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0047\n",
            "Epoch 35/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0047\n",
            "Epoch 36/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0047\n",
            "Epoch 37/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0045\n",
            "Epoch 38/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0046\n",
            "Epoch 39/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0046\n",
            "Epoch 40/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0046\n",
            "Epoch 41/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0046\n",
            "Epoch 42/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0044\n",
            "Epoch 43/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0047\n",
            "Epoch 44/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0044\n",
            "Epoch 45/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0046\n",
            "Epoch 46/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0044\n",
            "Epoch 47/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0044\n",
            "Epoch 48/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0043\n",
            "Epoch 49/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0042\n",
            "Epoch 50/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0045\n",
            "Epoch 51/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0044\n",
            "Epoch 52/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0044\n",
            "Epoch 53/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0044\n",
            "Epoch 54/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0046\n",
            "Epoch 55/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0043\n",
            "Epoch 56/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0043\n",
            "Epoch 57/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0045\n",
            "Epoch 58/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0043\n",
            "Epoch 59/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0042\n",
            "Epoch 60/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0045\n",
            "Epoch 61/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0043\n",
            "Epoch 62/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0043\n",
            "Epoch 63/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0043\n",
            "Epoch 64/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0042\n",
            "Epoch 65/75\n",
            "73/73 [==============================] - 7s 91ms/step - loss: 0.0043\n",
            "Epoch 66/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0040\n",
            "Epoch 67/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0045\n",
            "Epoch 68/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0043\n",
            "Epoch 69/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0042\n",
            "Epoch 70/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0041\n",
            "Epoch 71/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0044\n",
            "Epoch 72/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0042\n",
            "Epoch 73/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0041\n",
            "Epoch 74/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0042\n",
            "Epoch 75/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0040\n",
            "49/49 [==============================] - 3s 17ms/step\n",
            "Epoch 1/75\n",
            "73/73 [==============================] - 20s 79ms/step - loss: 0.0149\n",
            "Epoch 2/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0071\n",
            "Epoch 3/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0066\n",
            "Epoch 4/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0063\n",
            "Epoch 5/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0059\n",
            "Epoch 6/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0056\n",
            "Epoch 7/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0058\n",
            "Epoch 8/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0058\n",
            "Epoch 9/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0053\n",
            "Epoch 10/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0056\n",
            "Epoch 11/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0051\n",
            "Epoch 12/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0054\n",
            "Epoch 13/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0050\n",
            "Epoch 14/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0055\n",
            "Epoch 15/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0053\n",
            "Epoch 16/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0051\n",
            "Epoch 17/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0051\n",
            "Epoch 18/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0048\n",
            "Epoch 19/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0050\n",
            "Epoch 20/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0048\n",
            "Epoch 21/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0048\n",
            "Epoch 22/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0050\n",
            "Epoch 23/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0050\n",
            "Epoch 24/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0047\n",
            "Epoch 25/75\n",
            "73/73 [==============================] - 7s 96ms/step - loss: 0.0046\n",
            "Epoch 26/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0047\n",
            "Epoch 27/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0048\n",
            "Epoch 28/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0047\n",
            "Epoch 29/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0049\n",
            "Epoch 30/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0048\n",
            "Epoch 31/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0048\n",
            "Epoch 32/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0047\n",
            "Epoch 33/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0047\n",
            "Epoch 34/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0048\n",
            "Epoch 35/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0046\n",
            "Epoch 36/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0048\n",
            "Epoch 37/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0045\n",
            "Epoch 38/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0046\n",
            "Epoch 39/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0047\n",
            "Epoch 40/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0047\n",
            "Epoch 41/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0044\n",
            "Epoch 42/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0045\n",
            "Epoch 43/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0045\n",
            "Epoch 44/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0044\n",
            "Epoch 45/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0048\n",
            "Epoch 46/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0045\n",
            "Epoch 47/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0044\n",
            "Epoch 48/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0044\n",
            "Epoch 49/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0045\n",
            "Epoch 50/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0043\n",
            "Epoch 51/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0044\n",
            "Epoch 52/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0044\n",
            "Epoch 53/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0043\n",
            "Epoch 54/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0044\n",
            "Epoch 55/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0042\n",
            "Epoch 56/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0046\n",
            "Epoch 57/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0041\n",
            "Epoch 58/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0044\n",
            "Epoch 59/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0042\n",
            "Epoch 60/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0042\n",
            "Epoch 61/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0042\n",
            "Epoch 62/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0041\n",
            "Epoch 63/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0042\n",
            "Epoch 64/75\n",
            "73/73 [==============================] - 7s 96ms/step - loss: 0.0042\n",
            "Epoch 65/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0041\n",
            "Epoch 66/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0043\n",
            "Epoch 67/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0044\n",
            "Epoch 68/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0041\n",
            "Epoch 69/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0041\n",
            "Epoch 70/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0042\n",
            "Epoch 71/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0041\n",
            "Epoch 72/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0042\n",
            "Epoch 73/75\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.0041\n",
            "Epoch 74/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0042\n",
            "Epoch 75/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0042\n",
            "49/49 [==============================] - 3s 17ms/step\n",
            "Epoch 1/75\n",
            "73/73 [==============================] - 20s 82ms/step - loss: 0.0154\n",
            "Epoch 2/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0075\n",
            "Epoch 3/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0065\n",
            "Epoch 4/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0068\n",
            "Epoch 5/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0061\n",
            "Epoch 6/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0057\n",
            "Epoch 7/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0056\n",
            "Epoch 8/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0055\n",
            "Epoch 9/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0055\n",
            "Epoch 10/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0055\n",
            "Epoch 11/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0054\n",
            "Epoch 12/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0052\n",
            "Epoch 13/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0052\n",
            "Epoch 14/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0051\n",
            "Epoch 15/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0050\n",
            "Epoch 16/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0051\n",
            "Epoch 17/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0051\n",
            "Epoch 18/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0054\n",
            "Epoch 19/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0049\n",
            "Epoch 20/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0049\n",
            "Epoch 21/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0048\n",
            "Epoch 22/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0048\n",
            "Epoch 23/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0049\n",
            "Epoch 24/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0048\n",
            "Epoch 25/75\n",
            "73/73 [==============================] - 7s 97ms/step - loss: 0.0049\n",
            "Epoch 26/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0051\n",
            "Epoch 27/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0047\n",
            "Epoch 28/75\n",
            "73/73 [==============================] - 8s 105ms/step - loss: 0.0046\n",
            "Epoch 29/75\n",
            "73/73 [==============================] - 7s 97ms/step - loss: 0.0047\n",
            "Epoch 30/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0046\n",
            "Epoch 31/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0047\n",
            "Epoch 32/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0046\n",
            "Epoch 33/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0047\n",
            "Epoch 34/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0046\n",
            "Epoch 35/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0047\n",
            "Epoch 36/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0045\n",
            "Epoch 37/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0045\n",
            "Epoch 38/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0045\n",
            "Epoch 39/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0047\n",
            "Epoch 40/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0046\n",
            "Epoch 41/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0045\n",
            "Epoch 42/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0049\n",
            "Epoch 43/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0048\n",
            "Epoch 44/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0047\n",
            "Epoch 45/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0045\n",
            "Epoch 46/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0046\n",
            "Epoch 47/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0048\n",
            "Epoch 48/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0045\n",
            "Epoch 49/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0044\n",
            "Epoch 50/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0044\n",
            "Epoch 51/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0044\n",
            "Epoch 52/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0044\n",
            "Epoch 53/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0044\n",
            "Epoch 54/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0043\n",
            "Epoch 55/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0046\n",
            "Epoch 56/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0043\n",
            "Epoch 57/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0043\n",
            "Epoch 58/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0045\n",
            "Epoch 59/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0043\n",
            "Epoch 60/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0043\n",
            "Epoch 61/75\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.0042\n",
            "Epoch 62/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0043\n",
            "Epoch 63/75\n",
            "73/73 [==============================] - 7s 93ms/step - loss: 0.0042\n",
            "Epoch 64/75\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.0042\n",
            "Epoch 65/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0045\n",
            "Epoch 66/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0041\n",
            "Epoch 67/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0043\n",
            "Epoch 68/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0044\n",
            "Epoch 69/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0042\n",
            "Epoch 70/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0042\n",
            "Epoch 71/75\n",
            "73/73 [==============================] - 12s 161ms/step - loss: 0.0042\n",
            "Epoch 72/75\n",
            "73/73 [==============================] - 15s 209ms/step - loss: 0.0042\n",
            "Epoch 73/75\n",
            "73/73 [==============================] - 15s 212ms/step - loss: 0.0042\n",
            "Epoch 74/75\n",
            "73/73 [==============================] - 14s 188ms/step - loss: 0.0043\n",
            "Epoch 75/75\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.0041\n",
            "49/49 [==============================] - 4s 41ms/step\n",
            "Epoch 1/75\n",
            "73/73 [==============================] - 30s 192ms/step - loss: 0.0152\n",
            "Epoch 2/75\n",
            "73/73 [==============================] - 16s 224ms/step - loss: 0.0070\n",
            "Epoch 3/75\n",
            "73/73 [==============================] - 16s 216ms/step - loss: 0.0067\n",
            "Epoch 4/75\n",
            "73/73 [==============================] - 14s 200ms/step - loss: 0.0066\n",
            "Epoch 5/75\n",
            "73/73 [==============================] - 16s 225ms/step - loss: 0.0061\n",
            "Epoch 6/75\n",
            "73/73 [==============================] - 17s 235ms/step - loss: 0.0058\n",
            "Epoch 7/75\n",
            "73/73 [==============================] - 14s 193ms/step - loss: 0.0062\n",
            "Epoch 8/75\n",
            "73/73 [==============================] - 14s 188ms/step - loss: 0.0059\n",
            "Epoch 9/75\n",
            "73/73 [==============================] - 14s 194ms/step - loss: 0.0056\n",
            "Epoch 10/75\n",
            "73/73 [==============================] - 16s 226ms/step - loss: 0.0057\n",
            "Epoch 11/75\n",
            "73/73 [==============================] - 14s 197ms/step - loss: 0.0055\n",
            "Epoch 12/75\n",
            "73/73 [==============================] - 14s 198ms/step - loss: 0.0051\n",
            "Epoch 13/75\n",
            "73/73 [==============================] - 15s 208ms/step - loss: 0.0050\n",
            "Epoch 14/75\n",
            "73/73 [==============================] - 14s 192ms/step - loss: 0.0056\n",
            "Epoch 15/75\n",
            "73/73 [==============================] - 17s 231ms/step - loss: 0.0052\n",
            "Epoch 16/75\n",
            "73/73 [==============================] - 15s 203ms/step - loss: 0.0051\n",
            "Epoch 17/75\n",
            "73/73 [==============================] - 16s 212ms/step - loss: 0.0050\n",
            "Epoch 18/75\n",
            "73/73 [==============================] - 10s 141ms/step - loss: 0.0049\n",
            "Epoch 19/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0049\n",
            "Epoch 20/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0049\n",
            "Epoch 21/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0051\n",
            "Epoch 22/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0050\n",
            "Epoch 23/75\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.0049\n",
            "Epoch 24/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0048\n",
            "Epoch 25/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0050\n",
            "Epoch 26/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0048\n",
            "Epoch 27/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0048\n",
            "Epoch 28/75\n",
            "73/73 [==============================] - 7s 97ms/step - loss: 0.0048\n",
            "Epoch 29/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0048\n",
            "Epoch 30/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0046\n",
            "Epoch 31/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0048\n",
            "Epoch 32/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0048\n",
            "Epoch 33/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0049\n",
            "Epoch 34/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0047\n",
            "Epoch 35/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0047\n",
            "Epoch 36/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0045\n",
            "Epoch 37/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0046\n",
            "Epoch 38/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0044\n",
            "Epoch 39/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0047\n",
            "Epoch 40/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0046\n",
            "Epoch 41/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0045\n",
            "Epoch 42/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0046\n",
            "Epoch 43/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0045\n",
            "Epoch 44/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0046\n",
            "Epoch 45/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0046\n",
            "Epoch 46/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0045\n",
            "Epoch 47/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0044\n",
            "Epoch 48/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0044\n",
            "Epoch 49/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0047\n",
            "Epoch 50/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0045\n",
            "Epoch 51/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0043\n",
            "Epoch 52/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0044\n",
            "Epoch 53/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0044\n",
            "Epoch 54/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0044\n",
            "Epoch 55/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0045\n",
            "Epoch 56/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0046\n",
            "Epoch 57/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0043\n",
            "Epoch 58/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0043\n",
            "Epoch 59/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0044\n",
            "Epoch 60/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0045\n",
            "Epoch 61/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0045\n",
            "Epoch 62/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0043\n",
            "Epoch 63/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0043\n",
            "Epoch 64/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0045\n",
            "Epoch 65/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0045\n",
            "Epoch 66/75\n",
            "73/73 [==============================] - 7s 95ms/step - loss: 0.0042\n",
            "Epoch 67/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0041\n",
            "Epoch 68/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0042\n",
            "Epoch 69/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0042\n",
            "Epoch 70/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0043\n",
            "Epoch 71/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0040\n",
            "Epoch 72/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0042\n",
            "Epoch 73/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0043\n",
            "Epoch 74/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0042\n",
            "Epoch 75/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0042\n",
            "49/49 [==============================] - 3s 17ms/step\n",
            "Epoch 1/75\n",
            "73/73 [==============================] - 21s 82ms/step - loss: 0.0155\n",
            "Epoch 2/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0073\n",
            "Epoch 3/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0064\n",
            "Epoch 4/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0067\n",
            "Epoch 5/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0065\n",
            "Epoch 6/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0061\n",
            "Epoch 7/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0054\n",
            "Epoch 8/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0057\n",
            "Epoch 9/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0053\n",
            "Epoch 10/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0055\n",
            "Epoch 11/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0053\n",
            "Epoch 12/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0053\n",
            "Epoch 13/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0055\n",
            "Epoch 14/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0051\n",
            "Epoch 15/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0049\n",
            "Epoch 16/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0049\n",
            "Epoch 17/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0050\n",
            "Epoch 18/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0052\n",
            "Epoch 19/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0051\n",
            "Epoch 20/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0052\n",
            "Epoch 21/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0049\n",
            "Epoch 22/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0049\n",
            "Epoch 23/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0048\n",
            "Epoch 24/75\n",
            "73/73 [==============================] - 7s 102ms/step - loss: 0.0049\n",
            "Epoch 25/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0050\n",
            "Epoch 26/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0047\n",
            "Epoch 27/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0047\n",
            "Epoch 28/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0047\n",
            "Epoch 29/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0047\n",
            "Epoch 30/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0050\n",
            "Epoch 31/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0045\n",
            "Epoch 32/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0046\n",
            "Epoch 33/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0046\n",
            "Epoch 34/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0046\n",
            "Epoch 35/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0048\n",
            "Epoch 36/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0047\n",
            "Epoch 37/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0046\n",
            "Epoch 38/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0045\n",
            "Epoch 39/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0047\n",
            "Epoch 40/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0047\n",
            "Epoch 41/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0047\n",
            "Epoch 42/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0046\n",
            "Epoch 43/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0046\n",
            "Epoch 44/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0044\n",
            "Epoch 45/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0043\n",
            "Epoch 46/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0044\n",
            "Epoch 47/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0059\n",
            "Epoch 48/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0048\n",
            "Epoch 49/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0046\n",
            "Epoch 50/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0046\n",
            "Epoch 51/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0046\n",
            "Epoch 52/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0047\n",
            "Epoch 53/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0045\n",
            "Epoch 54/75\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 0.0044\n",
            "Epoch 55/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0046\n",
            "Epoch 56/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0046\n",
            "Epoch 57/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0044\n",
            "Epoch 58/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0043\n",
            "Epoch 59/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0046\n",
            "Epoch 60/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0043\n",
            "Epoch 61/75\n",
            "73/73 [==============================] - 7s 98ms/step - loss: 0.0043\n",
            "Epoch 62/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0041\n",
            "Epoch 63/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0043\n",
            "Epoch 64/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0042\n",
            "Epoch 65/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0043\n",
            "Epoch 66/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0043\n",
            "Epoch 67/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0042\n",
            "Epoch 68/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0042\n",
            "Epoch 69/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0042\n",
            "Epoch 70/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0042\n",
            "Epoch 71/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0042\n",
            "Epoch 72/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0041\n",
            "Epoch 73/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0043\n",
            "Epoch 74/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0043\n",
            "Epoch 75/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0041\n",
            "49/49 [==============================] - 3s 17ms/step\n",
            "Epoch 1/75\n",
            "73/73 [==============================] - 21s 82ms/step - loss: 0.0162\n",
            "Epoch 2/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0074\n",
            "Epoch 3/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0065\n",
            "Epoch 4/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0066\n",
            "Epoch 5/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0059\n",
            "Epoch 6/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0059\n",
            "Epoch 7/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0058\n",
            "Epoch 8/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0056\n",
            "Epoch 9/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0056\n",
            "Epoch 10/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0059\n",
            "Epoch 11/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0052\n",
            "Epoch 12/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0050\n",
            "Epoch 13/75\n",
            "73/73 [==============================] - 7s 101ms/step - loss: 0.0052\n",
            "Epoch 14/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0050\n",
            "Epoch 15/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0051\n",
            "Epoch 16/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0051\n",
            "Epoch 17/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0048\n",
            "Epoch 18/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0052\n",
            "Epoch 19/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0050\n",
            "Epoch 20/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0049\n",
            "Epoch 21/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0051\n",
            "Epoch 22/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0049\n",
            "Epoch 23/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0047\n",
            "Epoch 24/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0050\n",
            "Epoch 25/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0049\n",
            "Epoch 26/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0047\n",
            "Epoch 27/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0047\n",
            "Epoch 28/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0046\n",
            "Epoch 29/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0047\n",
            "Epoch 30/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0045\n",
            "Epoch 31/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0048\n",
            "Epoch 32/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0047\n",
            "Epoch 33/75\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.0047\n",
            "Epoch 34/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0047\n",
            "Epoch 35/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0046\n",
            "Epoch 36/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0047\n",
            "Epoch 37/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0047\n",
            "Epoch 38/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0046\n",
            "Epoch 39/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0046\n",
            "Epoch 40/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0047\n",
            "Epoch 41/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0049\n",
            "Epoch 42/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0047\n",
            "Epoch 43/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0046\n",
            "Epoch 44/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0075\n",
            "Epoch 45/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0052\n",
            "Epoch 46/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0048\n",
            "Epoch 47/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0048\n",
            "Epoch 48/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0047\n",
            "Epoch 49/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0046\n",
            "Epoch 50/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0046\n",
            "Epoch 51/75\n",
            "73/73 [==============================] - 7s 101ms/step - loss: 0.0046\n",
            "Epoch 52/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0047\n",
            "Epoch 53/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0045\n",
            "Epoch 54/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0046\n",
            "Epoch 55/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0046\n",
            "Epoch 56/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0045\n",
            "Epoch 57/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0044\n",
            "Epoch 58/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0043\n",
            "Epoch 59/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0044\n",
            "Epoch 60/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0043\n",
            "Epoch 61/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0045\n",
            "Epoch 62/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0043\n",
            "Epoch 63/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0045\n",
            "Epoch 64/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0045\n",
            "Epoch 65/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0043\n",
            "Epoch 66/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0043\n",
            "Epoch 67/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0043\n",
            "Epoch 68/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0043\n",
            "Epoch 69/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0042\n",
            "Epoch 70/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0042\n",
            "Epoch 71/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0043\n",
            "Epoch 72/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0043\n",
            "Epoch 73/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0043\n",
            "Epoch 74/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0043\n",
            "Epoch 75/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0042\n",
            "49/49 [==============================] - 3s 18ms/step\n",
            "Epoch 1/75\n",
            "73/73 [==============================] - 21s 83ms/step - loss: 0.0139\n",
            "Epoch 2/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0072\n",
            "Epoch 3/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0068\n",
            "Epoch 4/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0061\n",
            "Epoch 5/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0062\n",
            "Epoch 6/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0055\n",
            "Epoch 7/75\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.0056\n",
            "Epoch 8/75\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.0057\n",
            "Epoch 9/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0053\n",
            "Epoch 10/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0052\n",
            "Epoch 11/75\n",
            "73/73 [==============================] - 7s 99ms/step - loss: 0.0052\n",
            "Epoch 12/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0052\n",
            "Epoch 13/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0050\n",
            "Epoch 14/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0056\n",
            "Epoch 15/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0051\n",
            "Epoch 16/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0053\n",
            "Epoch 17/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0048\n",
            "Epoch 18/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0052\n",
            "Epoch 19/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0049\n",
            "Epoch 20/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0050\n",
            "Epoch 21/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0049\n",
            "Epoch 22/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0049\n",
            "Epoch 23/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0049\n",
            "Epoch 24/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0049\n",
            "Epoch 25/75\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.0049\n",
            "Epoch 26/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0048\n",
            "Epoch 27/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0047\n",
            "Epoch 28/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0046\n",
            "Epoch 29/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0047\n",
            "Epoch 30/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0048\n",
            "Epoch 31/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0046\n",
            "Epoch 32/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0048\n",
            "Epoch 33/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0049\n",
            "Epoch 34/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0048\n",
            "Epoch 35/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0045\n",
            "Epoch 36/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0046\n",
            "Epoch 37/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0047\n",
            "Epoch 38/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0046\n",
            "Epoch 39/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0046\n",
            "Epoch 40/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0044\n",
            "Epoch 41/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0046\n",
            "Epoch 42/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0047\n",
            "Epoch 43/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0044\n",
            "Epoch 44/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0046\n",
            "Epoch 45/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0045\n",
            "Epoch 46/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0046\n",
            "Epoch 47/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0043\n",
            "Epoch 48/75\n",
            "73/73 [==============================] - 8s 105ms/step - loss: 0.0045\n",
            "Epoch 49/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0045\n",
            "Epoch 50/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0044\n",
            "Epoch 51/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0043\n",
            "Epoch 52/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0043\n",
            "Epoch 53/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0043\n",
            "Epoch 54/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0043\n",
            "Epoch 55/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0043\n",
            "Epoch 56/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0043\n",
            "Epoch 57/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0043\n",
            "Epoch 58/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0043\n",
            "Epoch 59/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0044\n",
            "Epoch 60/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0042\n",
            "Epoch 61/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0044\n",
            "Epoch 62/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0042\n",
            "Epoch 63/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0045\n",
            "Epoch 64/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0041\n",
            "Epoch 65/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0043\n",
            "Epoch 66/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0043\n",
            "Epoch 67/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0042\n",
            "Epoch 68/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0044\n",
            "Epoch 69/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0042\n",
            "Epoch 70/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0044\n",
            "Epoch 71/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0045\n",
            "Epoch 72/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0043\n",
            "Epoch 73/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0042\n",
            "Epoch 74/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0041\n",
            "Epoch 75/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0042\n",
            "49/49 [==============================] - 3s 18ms/step\n",
            "Epoch 1/75\n",
            "73/73 [==============================] - 24s 103ms/step - loss: 0.0149\n",
            "Epoch 2/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0073\n",
            "Epoch 3/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0066\n",
            "Epoch 4/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0064\n",
            "Epoch 5/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0059\n",
            "Epoch 6/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0059\n",
            "Epoch 7/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0058\n",
            "Epoch 8/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0055\n",
            "Epoch 9/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0055\n",
            "Epoch 10/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0053\n",
            "Epoch 11/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0054\n",
            "Epoch 12/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0051\n",
            "Epoch 13/75\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.0057\n",
            "Epoch 14/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0050\n",
            "Epoch 15/75\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.0052\n",
            "Epoch 16/75\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.0050\n",
            "Epoch 17/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0050\n",
            "Epoch 18/75\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.0052\n",
            "Epoch 19/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0050\n",
            "Epoch 20/75\n",
            "73/73 [==============================] - 6s 87ms/step - loss: 0.0051\n",
            "Epoch 21/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0048\n",
            "Epoch 22/75\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.0052\n",
            "Epoch 23/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0051\n",
            "Epoch 24/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0050\n",
            "Epoch 25/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0047\n",
            "Epoch 26/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0048\n",
            "Epoch 27/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0047\n",
            "Epoch 28/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0049\n",
            "Epoch 29/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0051\n",
            "Epoch 30/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0048\n",
            "Epoch 31/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0046\n",
            "Epoch 32/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0047\n",
            "Epoch 33/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0046\n",
            "Epoch 34/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0050\n",
            "Epoch 35/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0046\n",
            "Epoch 36/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0047\n",
            "Epoch 37/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0047\n",
            "Epoch 38/75\n",
            "73/73 [==============================] - 7s 101ms/step - loss: 0.0048\n",
            "Epoch 39/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0048\n",
            "Epoch 40/75\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 0.0046\n",
            "Epoch 41/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0046\n",
            "Epoch 42/75\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.0046\n",
            "Epoch 43/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0047\n",
            "Epoch 44/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0045\n",
            "Epoch 45/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0046\n",
            "Epoch 46/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0046\n",
            "Epoch 47/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0044\n",
            "Epoch 48/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0048\n",
            "Epoch 49/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0044\n",
            "Epoch 50/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0044\n",
            "Epoch 51/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0046\n",
            "Epoch 52/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0044\n",
            "Epoch 53/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0043\n",
            "Epoch 54/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0045\n",
            "Epoch 55/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0045\n",
            "Epoch 56/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0045\n",
            "Epoch 57/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0044\n",
            "Epoch 58/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0043\n",
            "Epoch 59/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0043\n",
            "Epoch 60/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0042\n",
            "Epoch 61/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0042\n",
            "Epoch 62/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0045\n",
            "Epoch 63/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0044\n",
            "Epoch 64/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0045\n",
            "Epoch 65/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0043\n",
            "Epoch 66/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0042\n",
            "Epoch 67/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0042\n",
            "Epoch 68/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0042\n",
            "Epoch 69/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0042\n",
            "Epoch 70/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0043\n",
            "Epoch 71/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0042\n",
            "Epoch 72/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0042\n",
            "Epoch 73/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0041\n",
            "Epoch 74/75\n",
            "73/73 [==============================] - 7s 89ms/step - loss: 0.0043\n",
            "Epoch 75/75\n",
            "73/73 [==============================] - 7s 95ms/step - loss: 0.0042\n",
            "49/49 [==============================] - 3s 19ms/step\n",
            "Epoch 1/75\n",
            "73/73 [==============================] - 21s 84ms/step - loss: 0.0142\n",
            "Epoch 2/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0072\n",
            "Epoch 3/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0067\n",
            "Epoch 4/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0061\n",
            "Epoch 5/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0061\n",
            "Epoch 6/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0058\n",
            "Epoch 7/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0063\n",
            "Epoch 8/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0055\n",
            "Epoch 9/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0060\n",
            "Epoch 10/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0052\n",
            "Epoch 11/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0053\n",
            "Epoch 12/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0054\n",
            "Epoch 13/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0051\n",
            "Epoch 14/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0049\n",
            "Epoch 15/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0049\n",
            "Epoch 16/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0052\n",
            "Epoch 17/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0048\n",
            "Epoch 18/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0049\n",
            "Epoch 19/75\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.0049\n",
            "Epoch 20/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0049\n",
            "Epoch 21/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0049\n",
            "Epoch 22/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0048\n",
            "Epoch 23/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0050\n",
            "Epoch 24/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0048\n",
            "Epoch 25/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0047\n",
            "Epoch 26/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0050\n",
            "Epoch 27/75\n",
            "73/73 [==============================] - 7s 101ms/step - loss: 0.0049\n",
            "Epoch 28/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0049\n",
            "Epoch 29/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0047\n",
            "Epoch 30/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0049\n",
            "Epoch 31/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0048\n",
            "Epoch 32/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0046\n",
            "Epoch 33/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0054\n",
            "Epoch 34/75\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 0.0048\n",
            "Epoch 35/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0048\n",
            "Epoch 36/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0046\n",
            "Epoch 37/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0046\n",
            "Epoch 38/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0049\n",
            "Epoch 39/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0046\n",
            "Epoch 40/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0045\n",
            "Epoch 41/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0045\n",
            "Epoch 42/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0046\n",
            "Epoch 43/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0045\n",
            "Epoch 44/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0046\n",
            "Epoch 45/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0046\n",
            "Epoch 46/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0045\n",
            "Epoch 47/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0045\n",
            "Epoch 48/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0044\n",
            "Epoch 49/75\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.0046\n",
            "Epoch 50/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0044\n",
            "Epoch 51/75\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.0045\n",
            "Epoch 52/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0044\n",
            "Epoch 53/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0043\n",
            "Epoch 54/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0043\n",
            "Epoch 55/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0046\n",
            "Epoch 56/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0045\n",
            "Epoch 57/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0044\n",
            "Epoch 58/75\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.0045\n",
            "Epoch 59/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0046\n",
            "Epoch 60/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0042\n",
            "Epoch 61/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0044\n",
            "Epoch 62/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0043\n",
            "Epoch 63/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0044\n",
            "Epoch 64/75\n",
            "73/73 [==============================] - 8s 103ms/step - loss: 0.0044\n",
            "Epoch 65/75\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.0043\n",
            "Epoch 66/75\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.0042\n",
            "Epoch 67/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0042\n",
            "Epoch 68/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0042\n",
            "Epoch 69/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0043\n",
            "Epoch 70/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0042\n",
            "Epoch 71/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0041\n",
            "Epoch 72/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0043\n",
            "Epoch 73/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0041\n",
            "Epoch 74/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0042\n",
            "Epoch 75/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0042\n",
            "49/49 [==============================] - 3s 19ms/step\n",
            "Epoch 1/75\n",
            "73/73 [==============================] - 21s 84ms/step - loss: 0.0144\n",
            "Epoch 2/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0069\n",
            "Epoch 3/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0067\n",
            "Epoch 4/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0061\n",
            "Epoch 5/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0062\n",
            "Epoch 6/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0058\n",
            "Epoch 7/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0055\n",
            "Epoch 8/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0054\n",
            "Epoch 9/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0056\n",
            "Epoch 10/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0053\n",
            "Epoch 11/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0053\n",
            "Epoch 12/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0054\n",
            "Epoch 13/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0054\n",
            "Epoch 14/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0051\n",
            "Epoch 15/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0049\n",
            "Epoch 16/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0051\n",
            "Epoch 17/75\n",
            "73/73 [==============================] - 7s 102ms/step - loss: 0.0050\n",
            "Epoch 18/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0050\n",
            "Epoch 19/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0048\n",
            "Epoch 20/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0048\n",
            "Epoch 21/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0049\n",
            "Epoch 22/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0049\n",
            "Epoch 23/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0049\n",
            "Epoch 24/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0049\n",
            "Epoch 25/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0047\n",
            "Epoch 26/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0047\n",
            "Epoch 27/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0049\n",
            "Epoch 28/75\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.0048\n",
            "Epoch 29/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0047\n",
            "Epoch 30/75\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.0049\n",
            "Epoch 31/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0046\n",
            "Epoch 32/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0046\n",
            "Epoch 33/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0045\n",
            "Epoch 34/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0047\n",
            "Epoch 35/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0048\n",
            "Epoch 36/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0048\n",
            "Epoch 37/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0046\n",
            "Epoch 38/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0046\n",
            "Epoch 39/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0045\n",
            "Epoch 40/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0048\n",
            "Epoch 41/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0045\n",
            "Epoch 42/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0046\n",
            "Epoch 43/75\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.0045\n",
            "Epoch 44/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0045\n",
            "Epoch 45/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0045\n",
            "Epoch 46/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0045\n",
            "Epoch 47/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0044\n",
            "Epoch 48/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0046\n",
            "Epoch 49/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0045\n",
            "Epoch 50/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0046\n",
            "Epoch 51/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0044\n",
            "Epoch 52/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0044\n",
            "Epoch 53/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0044\n",
            "Epoch 54/75\n",
            "73/73 [==============================] - 7s 102ms/step - loss: 0.0042\n",
            "Epoch 55/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0044\n",
            "Epoch 56/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0046\n",
            "Epoch 57/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0044\n",
            "Epoch 58/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0045\n",
            "Epoch 59/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0042\n",
            "Epoch 60/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0043\n",
            "Epoch 61/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0045\n",
            "Epoch 62/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0042\n",
            "Epoch 63/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0041\n",
            "Epoch 64/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0042\n",
            "Epoch 65/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0041\n",
            "Epoch 66/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0043\n",
            "Epoch 67/75\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.0042\n",
            "Epoch 68/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0041\n",
            "Epoch 69/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0042\n",
            "Epoch 70/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0041\n",
            "Epoch 71/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0042\n",
            "Epoch 72/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0041\n",
            "Epoch 73/75\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.0042\n",
            "Epoch 74/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0041\n",
            "Epoch 75/75\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.0041\n",
            "49/49 [==============================] - 3s 19ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss)"
      ],
      "metadata": {
        "id": "MnuUdKWaqgaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b80937e9-6576-4d0e-e33b-d2a718c5ae55"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.07085843699231552, 0.06635547511276119, 0.06614203326558216, 0.06545133780062588, 0.06555390526118479, 0.06650794837905617, 0.06750376774429398, 0.06572625125827941, 0.06854959536272653, 0.06594965220235643]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(min(loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56ykd7kawkvX",
        "outputId": "aeb3f2eb-558d-44e2-bd23-4aa3d1ef0e01"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.06545133780062588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "5KwbVjdXKn01"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss)"
      ],
      "metadata": {
        "id": "O622nEj3Krt7",
        "outputId": "6451660b-374e-49a3-b087-89f83ebc5322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f75664975b0>]"
            ]
          },
          "metadata": {},
          "execution_count": 109
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3w8c93sq8TSAJJZoJhCxiygRHcNxRBrdBb20qtS926ubTa62Nvn6eLz92812pb9fHWuu9braIGca87EJZsIBA2k5BACCEJhJBlfs8fM9GYBjMhM3Nm+b5fr7yYnPM7Z75njOc75/c75/sTYwxKKaUij83qAJRSSllDE4BSSkUoTQBKKRWhNAEopVSE0gSglFIRKtrqAEYjIyPD5OXlWR2GUkqFlDVr1uw1xmQOXR5SCSAvL4+Kigqrw1BKqZAiIjuHW+5VF5CILBSRTSJSJyK3DrM+TkSe9axfKSJ5nuWXiMj6QT8uESn1rPs3EakXkQNHf1hKKaWO1ogJQESigHuBRUABsFRECoY0uwpoM8ZMA+4CbgcwxjxpjCk1xpQClwLbjTHrPdu8Asz1zWEopZQaLW+uAOYCdcaYbcaYHuAZYPGQNouBRz2vXwDmi4gMabPUsy0AxphPjTFNRxe2UkqpsfImATiA+kG/N3iWDdvGGNMHtAPpQ9p8F3h6tAGKyLUiUiEiFS0tLaPdXCml1BEE5DZQEZkHdBljaka7rTHmfmNMmTGmLDPzHwaxlVJKHSVvEkAjkDvod6dn2bBtRCQasAOtg9ZfzFF8+1dKKeU/3iSA1cB0EZksIrG4T+bLhrRZBlzueX0R8I7xlBkVERvwHQb1/yullLLeiAnA06d/HbAC2Ag8Z4ypFZHbRORCT7MHgXQRqQNuAgbfKnoaUG+M2TZ4vyLyXyLSACSKSIOI/HbshzO8xz7ZwSuVu/y1e6WUCkkSSvMBlJWVmaN5EOyCuz/AnhDDk1ef4IeolFIquInIGmNM2dDlEVELqNiZRlVDO6GU7JRSyt8iIgGUOO10dvexo7XL6lCUUipoREQCKHKkAVDVsN/iSJRSKnhERALIn5hMXLSNqoZ2q0NRSqmgEREJIDrKxqycVL0CUEqpQSIiAYB7ILimsYN+lw4EK6UURFACKMm1c6i3n7o9Wn1aKaUgghLAwEBwpXYDKaUUEEEJYEpGEslx0VTrQLBSSgERlABsNqHQoQPBSik1IGISAECJM42NTZ309LmsDkUppSwXUQmgyGmnp9/FpuZOq0NRSinLRVQCKHHqQLBSSg2IqATgHJfAuMQYHQhWSikiLAGICEXONL0CUEopIiwBgLsy6JY9BzjU0291KEopZamISwBFDjv9LsOGJu0GUkpFtohLACW5A6WhNQEopSJbxCWAianxTEyN0wSglIp4EZcAwF0XSAeClVKRLiITQInTzraWg3R291odilJKWSYiE0CR0w5AdaN2AymlIldEJoBizxPB+kCYUiqSRWQCGJ8US+74BB0IVkpFtIhMAADFOhCslIpwkZsAnHYa2g6x72CP1aEopZQlIjYBDAwE6wQxSqlI5VUCEJGFIrJJROpE5NZh1seJyLOe9StFJM+z/BIRWT/oxyUipZ51x4lItWebP4mI+PLARlLk8NwJpOMASqkINWICEJEo4F5gEVAALBWRgiHNrgLajDHTgLuA2wGMMU8aY0qNMaXApcB2Y8x6zzb3AdcA0z0/C31wPF5LiY9hSmYSlZoAlFIRypsrgLlAnTFmmzGmB3gGWDykzWLgUc/rF4D5w3yjX+rZFhHJBlKNMZ8aYwzwGLDkKI/hqJU407QLSCkVsbxJAA6gftDvDZ5lw7YxxvQB7UD6kDbfBZ4e1L5hhH36XbHTzp7Ow+zu6A70WyullOUCMggsIvOALmNMzVFse62IVIhIRUtLi0/jKvYMBFfW61WAUiryeJMAGoHcQb87PcuGbSMi0YAdaB20/mK+/PY/0N45wj4BMMbcb4wpM8aUZWZmehGu9wqy7UTZREtCKKUikjcJYDUwXUQmi0gs7pP5siFtlgGXe15fBLzj6dtHRGzAd/D0/wMYY5qADhE5wTNWcBnw8piO5CgkxEYxfUKyDgQrpSLSiAnA06d/HbAC2Ag8Z4ypFZHbRORCT7MHgXQRqQNuAgbfKnoaUG+M2TZk1z8BHgDqgK3A8jEdyVEaGAj25CullIoY0d40MsaUA+VDlv160Otu4NtH2PY94IRhllcAhaOI1S+Kc+08W1FPQ9shcscnWh2OUkoFTMQ+CTyg2OGuDKp1gZRSkSbiE8CMrBRio2z6RLBSKuJEfAKIjbZxbHaKXgEopSJOxCcAcE8QU9PYgculA8FKqcihCQD3A2EHDvexbe9Bq0NRSqmA0QTAl1NEal0gpVQk0QQATJuQTEJMlE4RqZSKKJoAgCibUOhI1SsApVRE0QTgUexMo3ZXB739LqtDUUqpgNAE4FHstHO4z8WW3QesDkUppQJCE4CHDgQrpSKNJgCPvPREUuKjqdLS0EqpCKEJwENEKHba9QpAKRUxNAEMUuxM47OmTrp7+60ORSml/E4TwCDFDjt9LsNnzZ1Wh6KUUn6nCWCQ4lwdCFZKRQ5NAIPk2OPJSI7VJ4KVUhFBE8AgIkKRQweClVKRQRPAEMXONOr2HODg4T6rQ1FKKb/SBDBEsdOOy0Dtrg6rQ1FKKb/SBDCEPhGslIoUmgCGyEyJI8cerwPBSqmwpwlgGEX6RLBSKgJoAhhGsTONHa1dtHf1Wh2KUkr5jSaAYRQ77QBUa2E4pVQY0wQwjGKHeyC4UruBlFJhTBPAMOyJMeSlJ1KtA8FKqTCmCeAIipxpOhCslAprXiUAEVkoIptEpE5Ebh1mfZyIPOtZv1JE8gatKxaRT0SkVkSqRSTes/y7IlLlWX67rw7IV0qcdna1d9PSedjqUJRSyi9GTAAiEgXcCywCCoClIlIwpNlVQJsxZhpwF3C7Z9to4AngR8aYWcAZQK+IpAP/Dcz3LM8Skfm+OSTfKHIMDATrVYBSKjx5cwUwF6gzxmwzxvQAzwCLh7RZDDzqef0CMF9EBFgAVBljKgGMMa3GmH5gCrDFGNPi2eYt4FtjOxTfKnTYEYHKeh0HUEqFJ28SgAOoH/R7g2fZsG2MMX1AO5AO5ANGRFaIyFoRucXTvg6YISJ5nquEJUDucG8uIteKSIWIVLS0tAzXxC+S4qKZlpmst4IqpcKWvweBo4FTgEs8/35TROYbY9qAHwPPAh8AO4Bh52E0xtxvjCkzxpRlZmb6OdyvKvYMBBtjAvq+SikVCN4kgEa++u3c6Vk2bBvPN3o70Ir7auF9Y8xeY0wXUA7MATDGvGKMmWeMORHYBGwey4H4Q0munb0Hemhq77Y6FKWU8jlvEsBqYLqITBaRWOBiYNmQNsuAyz2vLwLeMe6vzSuAIhFJ9CSG04ENACIywfPvOOAnwANjPRhfGxgI1ttBlVLhaMQE4OnTvw73yXwj8JwxplZEbhORCz3NHgTSRaQOuAm41bNtG3An7iSyHlhrjHnNs80fRWQD8BHwn8aYoLsCODY7lWibUKkPhCmlwlC0N42MMeW4u28GL/v1oNfdwLePsO0TuG8FHbp86agitUB8TBQzslL0iWClVFjSJ4FHoAPBSqlwpQlgBCVOOx3dfexs7bI6FKWU8ilNACMo8pSG1sqgSqlwowlgBPkTU4iLtukUkUqpsKMJYAQxUTYKclJ1IFgpFXY0AXihxJlGza52+l06EKyUCh+aALxQ7LTT1dPP1pYDVoeilFI+ownACwNzBFfW60CwUip8aALwwpSMZJJio3QgWCkVVjQBeMFmEwoddqq0NLRSEaWnz2V1CH6lCcBLJblpbNzVEfZ/EEopt1Xb91H4mxVs2NVhdSh+ownAS0UOOz39Ljbv7rQ6FKVUALy4toGefhfPr6kfuXGI0gTgpRJnGqBPBCsVCfr6XayobQbglcom+vrD88pfE4CXcscnkJYYQ5XOEaxU2Fu5fR9tXb0sKc1h74HDfLy11eqQ/EITgJdEhCIdCFYqIpRXN5EYG8XvLiwkJT6al9YNnQQxPGgCGIUSZxqbd3dyqGfY6YuVUmGg32VYUdvMmTMnYE+M4bzCbFbUNofl//eaAEahyGmn32XY0BS+dwUoFelW79jH3gM9nFeYDcDi2Tkc7OnnzY27LY7M9zQBjMLAQLDOEaxU+Fpe3URctI0zZmQCcMLkdLJS43k5DLuBNAGMQpY9ngkpcfpEsFJhyuUyvF7bzBkzMkmKc8+Ya7MJF5bm8PfNLew72GNxhL6lCWCUip12vQJQKkytq29jd8dhzivK/sryxaU59LkMr1U3WRSZf2gCGKViZxrb9h6ks7vX6lCUUj5WXt1MbJSNs2ZO+MryguxUpk9IDrtuIE0Ao1TktGMM1DTqQLBS4cQYw/LqJk7LzyAlPuYr60SEJbMdVOxso35f+MwPrglglHQgWKnwVNnQzq72bhYVZg+7/sKSHACWVe4KZFh+pQlglMYnxeIcl6APhCkVZpZXNxETJZx97MRh1+eOT6TsmHG8tK4RY8JjdkBNAEdBB4KVCi/GGMprmjh5Wgb2xJgjtls828GWPQfC5lkgTQBHodiZRv2+Q2F3S5hSkap2Vwf1+w6xqDDra9tdUJRNtE14eX14dANpAjgKxQ73FJHV2g2kVFhYXtNElE04p+DrE8C4pFjOmJHJsvW76HeFfjeQJoCjUOiZI7hK5whWKuQZYyivbubEKemMT4odsf3iUgfNHd2s3Bb6FUK9SgAislBENolInYjcOsz6OBF51rN+pYjkDVpXLCKfiEitiFSLSLxn+VLP71Ui8rqIZPjqoPwtNT6GKZlJOhCsVBjYtLuT7XsPsqjo67/9Dzj72IkkxUbx0vrQfyZgxAQgIlHAvcAioABYKiIFQ5pdBbQZY6YBdwG3e7aNBp4AfmSMmQWcAfR6lv8RONMYUwxUAdf55IgCpNihA8FKhYPy6mZsAgtG6P4ZkBAbxbmFWSyvbqa7N7QrhHpzBTAXqDPGbDPG9ADPAIuHtFkMPOp5/QIwX0QEWABUGWMqAYwxrcaYfkA8P0medqlASI2qFDvT2N1xmN0d3VaHopQag+XVTcydPJ7MlDivt1lS6qDzcB/vfrbHj5H5nzcJwAEMnhSzwbNs2DbGmD6gHUgH8gEjIitEZK2I3OJp0wv8GKjGfeIvAB4c7s1F5FoRqRCRipaWFq8PzN+KB8YBtDCcUiFry+5Otuw58A+1f0Zy0tR0MpLjQr4byN+DwNHAKcAlnn+/KSLzRSQGdwKYDeTg7gL65XA7MMbcb4wpM8aUZWZm+jlc783KsWMTfSJYqVC2vKYZETh3lnfdPwOio2x8oySbdz9rob0rdOuCeZMAGoHcQb87PcuGbePp37cDrbivFt43xuw1xnQB5cAcoBTAGLPVuB+pew44aQzHEXAJsVHkT0zRKwClQlh5dRPHTRrHxNT4UW+7pNRBT7+L5TWhWyHUmwSwGpguIpNFJBa4GFg2pM0y4HLP64uAdzwn9hVAkYgkehLD6cAG3AmjQEQGvtKfA2wc26EE3sATweHyWLhSkWT73oN81tzJolF2/wwodtqZnJEU0t1AIyYAT5/+dbhP5huB54wxtSJym4hc6Gn2IJAuInXATcCtnm3bgDtxJ5H1wFpjzGvGmF3A74D3RaQK9xXBv/v20Pyv2JlGW1cvDW2HrA5FKTVKA9/cF47w9O+RiAiLS3NYuX0fTe2heQ6I9qaRMaYcd/fN4GW/HvS6G/j2EbZ9AvetoEOX/w/wP6MJNtgMHgjOHZ9ocTRKqdFYXt1MaW4ajrSEo97HklIHf3hrC8vW7+KHp0/1YXSBoU8Cj8GMrBRio2w6EKxUiKnf10V1Yzvnefnw15HkZSRRmpvGSyFaG0gTwBjERUcxM1sHgpUKNQPdP0eq/T8aS0pz2NjUwebdnWPeV6BpAhijYqedmsZ2XGFQGEqpSFFe3UyRw+6TrtsLSnKIsgkvheB0kZoAxqjYmUbn4T627T1odShKKS807j/E+vr9Xtf+GUlGchynTMvg5fW7Qu6LoCaAMRoYCK5u1HEApULB6zXNgG+6fwYsmZ1D4/5DVOxs89k+A0ETwBhNy0wmISaKynodB1AqFLxe08TMrBQmZyT5bJ8LCrJIiAm9CqGaAMYoOsrGrJxUnRxGqRCwu6Obip1to679M5KkuGjOKZhIeXUTPX0un+7bnzQB+ECxM43aXe309YfOf3ilItGK2maMYcy3fw5nyewc9nf18vfNwVO0ciSaAHygJNdOd6+LzbsPWB2KUuprlFc3MX1CMtMmpPh836dOz2R8UmxIdQNpAvCBIocOBCsV7Fo6D7Nq+76jrv0zkpgoG+cXZfPWht10dodGhVBNAD6Ql55ESnw0lfpAmFJB640Nzbj81P0zYMnsHA73uVhRu9tv7+FLmgB8wGYTihx2qjUBqBB24HAfP3p8DS+sabA6FL9YXt3MlIwkZkz0fffPgDmTxpE7PoGXQ6QbSBOAjxQ70/isuYPDfaE9R6iKTN29/VzzaAWv1zZz2yu1tB8KjS4Mb7Ud7OGTba0sLMzCPQutf4gIS0odfFS3lz2dwT9drCYAHyl22untN2xsCr16ICqy9fW7uP7pdXyyrZWfnjmVju4+Hvhgm9Vh+dSbG3bT7zI+v/1zOItLHbgMvFIZ/BPFaALwkS+eCNbKoCqEuFyG//XXat7csJvfXTiLfz53JucXZ/Pgh9vZe+Cw1eH5THlNE7njE5iVk+r395o2IZlCR2pIdANpAvARR1oC6UmxOhCsQoYxhn99bSN/XdvATefkc/lJeQD8/Ox8unv7ue+9rdYG6CPtXb18VLeX8wqz/dr9M9iSUgdVDe1sbQnuW8M1AfiIiFDk1IFgFTrueaeOhz7azpUnT+b6s6Z9sXzahGS+NcfJ45/uDNmZrgZ7a+NuevuN327/HM43SnIQgZeDvEKoJgAfKnamsWVPJ109fVaHotTXeuyTHfz+zc18a46T/33+sf/wzfiG+dMxxnD3O3XWBOhDy2uayLHHU+Lppg2EianxnDQ1nZfW7wrqOcM1AfhQscOOy0BNY4fVoSh1RC+ta+TXL9dyTsFEbv9WETbbP3aL5I5PZOncSTy3up6draFb6ryzu5f3N+9lUVHgun8GLC518Pm+LtbVB++4oCYAHyrOHZgjOHj/g6vI9vbG3dz8fCUnTknn7qWziY468ingujOnER0l/OGtLQGM0Lfe+WwPPf0uvz78dSQLC7OIjbYFdTeQJgAfmpAST7Y9XqeIVEFp5bZWfvLkWmblpPKXy8uIj4n62vYTUuO5/MQ8XlrfGJLTHYK79s/E1Dhm544L+Hunxsdw9rETeLWqid4gLRSpCcDHihx2LQ2tgk5NYztXP1qBc1wCj/xgLslx0V5t96PTp5IUG82db2z2c4S+d/BwH+9tamHhrKxhu7kCYXGpg9aDPXxYt9eS9x+JJgAfK8lNY/veg2H3JKUKXdtaDnD5Q6tITYjhiavnMT4p1uttxyXFcvWpk3m9tjnkujbf29TC4T5XQO/+GeqMGZnYE2KCthtIE4CPfVEZVLuBVBDYtf8Qlz64CoDHr5pLtj1h1Pu46pTJjEuM4Y4Quwoor2kiIzmW4/PGWxZDXHQU5xVl88aG3UF5d6AmAB8beCK4SktDK4u1HjjMpQ+upONQL49eOZcpmclHtZ+U+Bh+dPpU3t/cwqrt+3wcpX8c6unn3c/2cO6sLKIs6v4ZsKQ0h66eft7cEHwVQjUB+FhaYizHpCdSpXMEKwt1dvdyxcOraWg7xINXHE+hY2z3wF92Yh4TUuK4Y8WmoL6vfcDfN7fQ1dMfkNo/Izk+bzw59nheCsJuIE0AfqADwcpK3b39XPNYBRubOrjv+3OYO3nsXSAJsVFcf9Y0Vu3Yx/tbgnNAc7DlNU2MS4xhng+OfaxsNuHCUgfvb9lLa5DVV/IqAYjIQhHZJCJ1InLrMOvjRORZz/qVIpI3aF2xiHwiIrUiUi0i8SKSIiLrB/3sFZE/+O6wrFXiTKNx/6GwKqalQkNfv4vrnlrHyu37+P13Sjhr5kSf7fu7x0/COS4h6K8Cunv7eXuju/vn655zCKQls3Podxleqw6uCqEjfjoiEgXcCywCCoClIlIwpNlVQJsxZhpwF3C7Z9to4AngR8aYWcAZQK8xptMYUzrwA+wEXvTRMVmuyKkDwSrwXC7DLX+t4q2N7sqei0sdPt1/bLSNG+dPp7qxnRW1zT7dty99uGUvBw73sbAw8A9/HcnMrFRmZqUEXTeQN+lxLlBnjNlmjOkBngEWD2mzGHjU8/oFYL64n7teAFQZYyoBjDGtxpivzJgiIvnABOCDoz+M4FLosCMClSF225wKXcYYbnt1Ay+ubeTmc/K57MQ8v7zPN2c7mJqZxO/f2Ey/KzivApbXNJMaH81JUzOsDuUrFpc6WPv5/qAqreFNAnAA9YN+b/AsG7aNMaYPaAfSgXzAiMgKEVkrIrcMs/+LgWfNEa4pReRaEakQkYqWlhYvwrVeclw00zKT9YlgFTB/eruORz7ewVWnTOa6QZU9fS06ysZN58xgy54DLKsMrm+zAD19Lt7c0Mw5Be4yDMHkwtIcAF5ev8viSL7k708oGjgFuMTz7zdFZP6QNhcDTx9pB8aY+40xZcaYsszMTP9F6mNFTjtVDe1B3VeqwsMjH23nrrc2c9FxTn513j9W9vS1RYVZFGSnctebW4KuxMHHW/fS0d1nSe2fkTjSEpg7eTwvrW8MmvOCNwmgEcgd9LvTs2zYNp5+fzvQivtq4X1jzF5jTBdQDswZ2EhESoBoY8yaoz6CIFXiTGPvgcM0tQf/vKAqdL20rpHfvrKBBQUT+c9/Gr6yp6/ZbMIvzs3n831dPFdRP/IGAbS8upnkuGhOmR5c3T8DlpQ62NZyMGgqBnuTAFYD00VksojE4v7GvmxIm2XA5Z7XFwHveLp0VgBFIpLoSQynAxsGbbeUr/n2H8oGBoK1G0j5y1sbvqzs+acRKnv62pkzJjBnUhp3v11Hd2//yBsEQG+/ixUbmjn72AnERX99oTurnF+UTWyUjZeCZLrIEf9iPH361+E+mW8EnjPG1IrIbSJyoafZg0C6iNQBNwG3erZtA+7EnUTWA2uNMa8N2v13CNMEUJCdSrRNQq5+igoNn25r5adPraXQy8qeviYi/PO5M2nu6OaJT3cG9L2PZOW2fezv6rW09s9I7IkxnDEjk1cqdwXFILpXJQGNMeW4u28GL/v1oNfdwLePsO0TuG8FHW7dFK8jDTHxMVHkT0zRKwDlcwOVPXPHJ/LwKCp7+tqJU9M5ZVoG9723lYvnTrIsjgHlNU0kxkZxen5wjxUume3gjQ27+WRrq+VdVcE1TB5mSnLtVDXsD5oBHxX6trYc4LKHVmFPiOHxq+aOqrKnP/zi3Bm0Huzh4Q+3WxpHv8vwRm0zZ86cEPCrodE6a+YEUuKig6IbSBOAHxU70+jo7mNna5fVoagwsGv/IS59YCU2gSeunndUlT19rTQ3jbOPncj9H2yjvcu6Euird+xj74EezisM3u6fAfExUSwszOL1mmbLx080AfjRQGnoKq0LpMao9cBhvv/gSjq7+3j0yrlMzkiyOqQv3LwgnwOH+/jz+1sti2F5dRPxMTbOmBHc3T8Dlsx2cOBwH29v3GNpHJoA/GhGVgqx0TaqgnhSaBX8Ort7ufzhVezaf4iHfnA8s3LGVtnT147NTuUbxTk8/NEOWjoDX//K5TIsr2nmjPwJJFk8DuGtE6akMyElzvJuIE0AfhQTZaMgO1UHgtVR6+7t5+pHK/isqZP7LjnO0slNvs7Pz8mnp9/Fve/WBfy9137exp7OwywKwoe/jiTKJlxYksN7m/awv6vHsjg0AfhZidNOza72oLjlS4WW3n4X1z21llU73JU9z5w5weqQjmhyRhIXzXHy1MrPadx/KKDvXV7dTGy0jbOC+PMZzpLZDnr7DeXV1hXW0wTgZ8XONLp6+tnacsDqUFQIcbkMt7xQxVsb93Db4kKfV/b0hxvOng7A3W9vCdh7urt/mjhteiYp8TEBe19fmJWTytTMJEsrhGoC8LNifSJYjdJAZc+/rWvkFwvyufSEY6wOySuOtAS+N28Sz69pYPvewFS8rGzYT1N7N4uCqPSzt0SEJaUOVu3YR0ObNXcKagLwsymZySTFRukTwcprf3x7C498vIOrT5nMT8/0X2VPf/jpmdOIjbLxh7cCM4H88ppmYqKEs4/13cQ3gTRwZbes0poKoZoA/CzKJsxy2KnUKwDlhYc/2s4f3trCt49z8qvz/V/Z09cyU+K44uQ8llXu4rNm/xY8M8bd/XPytAzsiaHV/TNgUnoixx0zjpfXaQIIWyVOOxubOujpC67SuSq4vLi2gd95Knv+xz8VhdzJf8APT5tCcmw0v3/Dv1cBtbs6qN93KCQe/vo6S0pz2LS7k41Nga8QqgkgAIqdafT0udi8u9PqUFSQenPDbv75hSpOmhr4yp6+lpYYy7WnTeHNDbtZ78dnYMqrm4iyCecUhGb3z4Dzi3OItoklzwSE7l9ZCNGBYPV13t/cwk+fdFf2vP+ywFf29IcfnDKZ8Umx/P6NTX7ZvzGG8uomTpqazjiL6yGN1fikWE7Lz+SV9btwBfh2cU0AATBpfCL2hBgdCFb/4JOtrVzzWAVTJyTz6JXWVfb0teS4aH5yxlQ+2LKXT7a2+nz/nzV3sqO1i0Uh3v0zYHFpDrvau1m1Y19A31cTQACICMVOHQhWX1WxYx9XPbqaSeMTeeKquaQlhvY32aG+f8IxTEyN4443Nvm8Iu7y6iZsAgtmhXb3z4BzCiaSGBvFywHuBtIEECDFTjubd3daXv1PBYf19fu54uHVZKXG8+Q180hPjrM6JJ+Lj4nihvnTWbOzjfc2tfh03+U1zcydPJ6MMPncEmOjOXdWFq9VNXG4L3DnCE0AAVLkSKPfZajdFRxzgSrr1DS2c9mDKxmfFMtT15zAhJR4q0Pym++U5TJpfCJ3vLHJZ/3bW3Z3UrfnAEvvNzcAABAYSURBVOcF8cxfR2NxaQ4d3X0+T5ZfRxNAgJTkugeCf7Oshjvf3MwHW1o4cLjP4qhUoG1q7uTSB1eSEh/DU9fMI8sevid/cBdE/NnZ06nd1cHyGt/UvFle04wInDsr9J7+/TqnTMsgIzk2oN1A4THiFAKyUuO5cf503tywm3ve2YLLgE1gZlYqZXnjOO6YcZTljceRZv0kH8o/6vYc4JIHPiU22saTV8/DOS7R6pACYnGpg/ve28qdb25iYWEWUbaxPd9QXt1E2THjmJgaXskzOsrGBcU5PLXqczq6e0kNQG0jTQABIiL8/Jx8fn5OPp3dvayv30/FjjbW7GzjhTUNPPaJe2LtbHu8Oxl4EsLMrJSQvidcue3Ye5BLHvgUEJ68+gTygmhCF3+Lsgk3L8jnR0+s5W/rGrnoOOdR72tbywE+a+7k1xcU+DDC4LFktoNHPt7B69XNfOf4XL+/nyYAC6TEx3Dq9ExOne6evaiv38VnzZ1U7NhHxU53Uni1qgmApNgoSielcdwx4yk7ZhyzJ6WFXNXDSNfQ1sUlD6ykp8/FM9eeyLQJyVaHFHDnzsqiyGHnD29t5sKSHGKjj+5LzUA30sIQLP7mjRKnnbz0RF5a36gJIFJER9kodNgpdNi54uTJADTuP0TFjn2s2dlGxY62r3QbzchK9VwhaLdRsGtqP8T3/rKSzu5enrrmBGZkpVgdkiVE3FcBVzy8mmdXf86lJ+Yd1X6W1zQxe1IaOWH6Ny8iLC518Kd3ttDc3u33MSJNAEHKkZaAo9TxRbXAod1GL65t4PFPtdsomO3p7OaSv6xk38Eenrh6HoWO4JrKMdBOz8/k+Lxx3P1OHRcdl0tC7OieeP68tYuaxg5+dd6xfoowOCyZ7eCPb2/hlcpdXHPaFL++lyaAEHGkbqM1O9vc3UY79n3RbZQYG8Vs7TayVOuBw1zyl5U0d3Tz2JVzKc1Nszoky4kIv1gwg+/e/ymPf7qDa0+bOqrtl9e4/77DtftnwOSMJEqcdl5a36gJQA1vcLfR5SflAdptFCz2d/Xw/QdX8fm+Lh75wVzKgnQeXyvMm5LOafmZ3PfeVpbOnTSqLyblNc0UOezkjg//u6cWlzq47dUN1O3pZNoE/3Ubaj9BGHGkJbj/cBYXUn7jqVT99lwev2ou1581nfSkWF5c28CNz6zn5P98h98uqw3oE4eRoqO7l8seWsXWPQf4y2VlnDg13eqQgs4vFuTT1tXLgx9u93qbxv2HqKzfH1ITv4/FBSXZ2ARe8vM8AXoFEMaS46KH7TZ6vqKeRz7ewZqdbdz7vTlMSg//b1SBcOBwH1c8tIoNuzr486XHcVp+ptUhBaViZxrnzprIAx9s5/IT87yq5vm65+6fcCn+NpIJKfGcPC2DlysbuXlBvt/mhtArgAgy0G30u8WF/PnS49jZepDz//QB5dVNVocW8g719HPVI6upbGjn7qWzmR+iUxQGys0LZnCwp4//eX+rV+2XVzdxbHYqkyPo+YklpQ7q9x1i7edtfnsPrxKAiCwUkU0iUicitw6zPk5EnvWsXykieYPWFYvIJyJSKyLVIhLvWR4rIveLyGYR+UxEvuWrg1IjO3dWFq/dcCpTJyTzkyfX8uuXa7RQ3VHq7u3nmscqWL1jH3d+p4RFYVajxh/yJ6awpNTBox/vYE9H99e2bW7vpmJnG+eF+eDvUOcWZhEfY/NrN9CICUBEooB7gUVAAbBURIY+hncV0GaMmQbcBdzu2TYaeAL4kTFmFnAG0OvZ5lfAHmNMvme/fx/z0ahRyR2fyHM/PJFrTp3MY5/s5Fv3fcyOvQetDiuk9PS5+PETa/iwbi//dVHJF7ftqpH97Ozp9PUb7n237mvbraj1dP9EWGJNjovm7GMn8lp1E739/plO1psrgLlAnTFmmzGmB3gGWDykzWLgUc/rF4D54u60WgBUGWMqAYwxrcaYga+ZVwL/4VnuMsbsHduhqKMRG23jV+cX8MBlZTTuP8QFd3/IK5XWTFAdanr7XVz/9Fre3dTCv3+zaEwlDiLRMelJfLssl6dWfU79vq4jtiuvbiJ/YnJEPkH9zdkO9h3s4YMt/qkQ6k0CcAD1g35v8Cwbto0xpg9oB9KBfMCIyAoRWSsitwCIyMBN0f/Xs/x5ERm201RErhWRChGpaGkJXJnUSHN2wUReu+FUZmSlcP3T6/iXv1Vrl9DX6Ot38fNn17Oidje/+UYB35s3yeqQQtIN86chIvzp7S3Drm/pPMyqHftYGCGDv0Odlp/JuMQYv3UD+XsQOBo4BbjE8+83RWS+Z7kT+NgYMwf4BLhjuB0YY+43xpQZY8oyM/WuCn9ypCXwzLUn8MPTp/DUys9Zcu9HbG05YHVYQcflMtzyQhWvVjXxy0Uz+YGnfIcavWx7ApeecAx/Xdsw7N/aitpmjIHzIuT2z6FiomycX5zNGxua/VI+3psE0AgMrkrk9Cwbto2n398OtOK+WnjfGLPXGNMFlANzPOu6gBc92z/vWa4sFhNl45eLjuXhK45nd0c337j7Q15aF9hp6oKZy2X4l79V8+K6Rm4+J58fnj66p1nVP/rxGVOJj4nirjc3/8O612uamZKRxIyJkVlDCWDp3En86rxjGWMV7WF5kwBWA9NFZLKIxAIXA8uGtFkGXO55fRHwjnFPAroCKBKRRE9iOB3Y4Fn3Cu5BYYD5wIYxHYnyqTNnTqD8xlOZlZPKz55dz61/reJQT2R3CRlj+N0rtTyzup7rzpzG9fOnWx1SWMhIjuPKkyfzalUTtbu+nDd738EePtnWyqKiLL/dBx8KZuXYufTEPBJjff/Y1ogJwNOnfx3uk/lG4DljTK2I3CYiF3qaPQiki0gdcBNwq2fbNuBO3ElkPbDWGPOaZ5v/BfxWRKqAS4GbfXdYyhey7Qk8fc0J/OSMqTyzup4l935E3Z5Oq8OyhDGGfy/fyKOf7OSaUydz84J8q0MKK9ecNoXU+GjufOPLq4A3NzTT7zIR8/CXFcT9ZTw0lJWVmYqKCqvDiEh/39zCTc+up6unn39dUsi3IuyOlztWbOKed+u4/MRj+O2FsyL6G6m/3PtuHf+9YhMv/uQk5kwax+UPrWL73oP8/Z/P0M97jERkjTGmbOhyfRJYeeX0/EzKbzyVYqedm5+v5BfPV9LVExlzGt/99hbuebeOpXNz+c039OTvL1eclEdGcix3rNhEe1cvH9XtjfjuH3/TBKC8NjE1nievnscNZ03jr2sbWHzPR2zeHd5dQn/++1Z+/+Zm/mm2g39bUoTNHyNxCoCkuGh+csY0Pt7ayu9eraXPZThPu3/8ShOAGpXoKBs3LZjB41fOo62rlwvv+ZDnKuoJpa5Ebz380Xb+Y/lnXFCczX9dVKwn/wD43rxJZNvjeXFtI460BIqdkT2Jjr9pAlBH5ZTpGZTfeApzJo3jlhequPm5Sg764T5lqzy5cie/e2UDCwomctd3S3WGtQCJj4niBs/dVQsLtfvH37QctDpqE1LiefyqedzzTh1/fHszlQ37ufeSOczMSrU6tDF5YU0Dv/pbDWfOyOTu780mRk/+AXXRcU52d3TznTL/T4oe6fQvW41JlE248ezpPHn1CXR097H4no94etXnIdsl9PL6Rm55oZJTpmVw3/ePIy56dPPWqrGLibLxs7Pzw3bi92CiCUD5xIlT0ym/4VTmTh7PL1+s5sZn1vvl0XV/er2miZueq6Qsbzx/uayM+Bg9+avwpglA+UxmShyP/mAuv1iQz6tVu/jG3R9+5cnOYPb2xt1c//Q6Spx2HrrieBJi9eSvwp8mAOVTNptw3VnTefqaE+jq6eOb/+9jHv90Z1B3Cb2/uYUfP7GWY7NTeeTKuSTH6dCYigz6l678Yt4Ud5fQTc9V8n9equHTba38xz8VkRofY1lMxhj2d/XS1N5Nc8chdu3vpnH/IR76cDtTJyTz2JVzLY1PqUDTBKD8Jj05joevOJ4/v7+NO97YRE1jO/csnUORH+7tHnxyb2o/9JV/m9u7v/i9u/erMyvZBGZPGsf9lx5HWuLIk5MrFU60FpAKiIod+7j+6XW0HujhV+cfy2UnHuP1Pd7GGNq6emlqP0Rzeze72rtpbj9E0/5uz7f54U/uUTZhYkocWfZ4su0JZNvjv3ydFk+2PZ7M5Di9x1+FvSPVAtIEoAKm7WAPNz9fyTuf7WHhrCxuv6iY1PjoL07uTfu7aeropmn/oa98a29q7+Zw3/An9+y0BPdJPTWe7LQvT/I59gQykmP15K4UmgBUkHC5DA98uI3/en0TCTFR9PS7hj25Z6UOfFsf+Bl0ck9LICM5jigtzaCUV46UAHQMQAWUzSZce9pUyvLG8/TKzxmXFEtWajw5afFkeU7yenJXKjA0AShLzJk0jjmTxlkdhlIRTTtIlVIqQmkCUEqpCKUJQCmlIpQmAKWUilCaAJRSKkJpAlBKqQilCUAppSKUJgCllIpQIVUKQkRagJ1HuXkGsNeH4YQ6/Ty+pJ/FV+nn8aVw+SyOMcZkDl0YUglgLESkYrhaGJFKP48v6WfxVfp5fCncPwvtAlJKqQilCUAppSJUJCWA+60OIMjo5/El/Sy+Sj+PL4X1ZxExYwBKKaW+KpKuAJRSSg2iCUAppSJU2CcAEVkoIptEpE5EbrU6HiuJSK6IvCsiG0SkVkRutDqmYCAiUSKyTkRetToWK4lImoi8ICKfichGETnR6pisJCI/9/x/UiMiT4tIvNUx+VpYJwARiQLuBRYBBcBSESmwNipL9QE3G2MKgBOAn0b45zHgRmCj1UEEgT8CrxtjZgIlRPBnIiIO4AagzBhTCEQBF1sble+FdQIA5gJ1xphtxpge4BlgscUxWcYY02SMWet53Yn7f3CHtVFZS0ScwPnAA1bHYiURsQOnAQ8CGGN6jDH7rY3KctFAgohEA4nALovj8blwTwAOoH7Q7w1E+AlvgIjkAbOBldZGYrk/ALcALqsDsdhkoAV42NMd9oCIJFkdlFWMMY3AHcDnQBPQbox5w9qofC/cE4AahogkA38FfmaM6bA6HquIyAXAHmPMGqtjCQLRwBzgPmPMbOAgELFjZiIyDndvwWQgB0gSke9bG5XvhXsCaARyB/3u9CyLWCISg/vk/6Qx5kWr47HYycCFIrIDd/fgWSLyhLUhWaYBaDDGDFwRvoA7IUSqs4HtxpgWY0wv8CJwksUx+Vy4J4DVwHQRmSwisbgHcZZZHJNlRERw9/FuNMbcaXU8VjPG/NIY4zTG5OH+23jHGBN23/K8YYxpBupFZIZn0Xxgg4UhWe1z4AQRSfT8fzOfMBwUj7Y6AH8yxvSJyHXACtyj+A8ZY2otDstKJwOXAtUist6z7F+MMeUWxqSCx/XAk54vS9uAH1gcj2WMMStF5AVgLe6759YRhmUhtBSEUkpFqHDvAlJKKXUEmgCUUipCaQJQSqkIpQlAKaUilCYApZSKUJoAlFIqQmkCUEqpCPX/AbjrpUfqfbj/AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}