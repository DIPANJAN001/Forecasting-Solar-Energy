{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DIPANJAN001/Forecasting-Solar-Energy/blob/master/bestresult09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzs_vH9vlX74",
        "outputId": "51bc0f33-da30-42a2-cf8a-e7da46123540"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Boruta in /usr/local/lib/python3.8/dist-packages (0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.0.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.17.1->Boruta) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.17.1->Boruta) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install Boruta\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from boruta import BorutaPy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import concatenate\n",
        "from keras import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Bidirectional\n",
        "from keras import layers\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import load_model\n",
        "from keras.layers import Input\n",
        "from sklearn.decomposition import PCA "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "lDilv4v2lz-w"
      },
      "outputs": [],
      "source": [
        "def lstm_data_transform(x_data, y_data, num_steps):\n",
        "    \"\"\" Changes data to the format for LSTM training \n",
        "for sliding window approach \"\"\"\n",
        "    # Prepare the list for the transformed data\n",
        "    X, y = list(), list()\n",
        "    # Loop of the entire data set\n",
        "    for i in range(x_data.shape[0]):\n",
        "        # compute a new (sliding window) index\n",
        "        end_ix = i + num_steps\n",
        "        # if index is larger than the size of the dataset, we stop\n",
        "        if end_ix >= x_data.shape[0]:\n",
        "            break\n",
        "        # Get a sequence of data for x\n",
        "        seq_X = x_data[i:end_ix]\n",
        "        # Get only the last element of the sequency for y\n",
        "        seq_y = y_data[end_ix]\n",
        "        # Append the list with sequencies\n",
        "        X.append(seq_X)\n",
        "        y.append(seq_y)\n",
        "    # Make final arrays\n",
        "    x_array = np.array(X)\n",
        "    y_array = np.array(y)\n",
        "    return x_array, y_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "iQt_oZP7QczL"
      },
      "outputs": [],
      "source": [
        "df=pd.read_excel(\"/content/pv_09.xlsx\")\n",
        "weather_input1=df.drop('power_normed',axis=1)\n",
        "weather_input=weather_input1.drop('time_idx',axis=1)\n",
        "solpow=df['power_normed']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoPnMw4oQQlc",
        "outputId": "7a07f713-ad80-4eed-9124-12648e936281"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: \t1 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t2 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t3 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t4 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t5 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t6 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t7 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t8 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t4\n",
            "Rejected: \t32\n",
            "Iteration: \t9 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t4\n",
            "Rejected: \t32\n",
            "Iteration: \t10 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t4\n",
            "Rejected: \t32\n",
            "Iteration: \t11 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t4\n",
            "Rejected: \t32\n",
            "Iteration: \t12 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t4\n",
            "Rejected: \t32\n",
            "Iteration: \t13 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t4\n",
            "Rejected: \t32\n",
            "Iteration: \t14 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t4\n",
            "Rejected: \t32\n",
            "Iteration: \t15 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t4\n",
            "Rejected: \t32\n",
            "Iteration: \t16 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t4\n",
            "Rejected: \t32\n",
            "Iteration: \t17 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t4\n",
            "Rejected: \t32\n",
            "Iteration: \t18 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t4\n",
            "Rejected: \t32\n",
            "Iteration: \t19 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t3\n",
            "Rejected: \t32\n",
            "Iteration: \t20 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t3\n",
            "Rejected: \t32\n",
            "Iteration: \t21 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t3\n",
            "Rejected: \t32\n",
            "Iteration: \t22 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t3\n",
            "Rejected: \t32\n",
            "Iteration: \t23 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t3\n",
            "Rejected: \t32\n",
            "Iteration: \t24 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t3\n",
            "Rejected: \t32\n",
            "Iteration: \t25 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t3\n",
            "Rejected: \t32\n",
            "Iteration: \t26 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t3\n",
            "Rejected: \t32\n",
            "Iteration: \t27 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t3\n",
            "Rejected: \t32\n",
            "Iteration: \t28 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t3\n",
            "Rejected: \t32\n",
            "Iteration: \t29 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t3\n",
            "Rejected: \t32\n",
            "Iteration: \t30 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t3\n",
            "Rejected: \t32\n",
            "Iteration: \t31 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t3\n",
            "Rejected: \t32\n",
            "Iteration: \t32 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t33 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t34 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t35 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t36 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t37 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t38 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t39 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t40 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t41 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t42 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t43 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t44 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t45 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t46 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t47 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t48 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t49 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t50 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t51 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t52 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t53 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t54 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t55 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t56 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t57 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t58 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t59 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t60 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t61 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t62 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t63 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t64 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t65 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t66 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t67 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t68 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t69 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t70 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t71 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t72 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t73 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t74 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t75 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t76 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t77 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t78 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t79 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t80 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t81 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t82 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t83 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t84 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t85 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t86 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t87 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t88 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t89 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t90 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t91 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t92 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t93 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t94 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t95 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t96 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t97 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t98 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "Iteration: \t99 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t32\n",
            "\n",
            "\n",
            "BorutaPy finished running.\n",
            "\n",
            "Iteration: \t100 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t1\n",
            "Rejected: \t32\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BorutaPy(estimator=RandomForestRegressor(max_depth=7, n_estimators=83,\n",
              "                                         random_state=RandomState(MT19937) at 0x7F2F15FF2B40),\n",
              "         n_estimators='auto',\n",
              "         random_state=RandomState(MT19937) at 0x7F2F15FF2B40, verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "rfc = RandomForestRegressor(random_state=1, n_estimators=1000, max_depth=7)\n",
        "boruta_selector = BorutaPy(rfc, n_estimators='auto', verbose=2, random_state=1)\n",
        "boruta_selector.fit(np.array(weather_input), np.array(solpow)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "u2NoSDCGUFNU"
      },
      "outputs": [],
      "source": [
        "X_important_train = boruta_selector.transform(np.array(weather_input))\n",
        "num_steps = 3\n",
        "# training set\n",
        "(x_transformed_train,\n",
        " y_transformed_train) = lstm_data_transform(X_important_train,solpow , num_steps=num_steps)\n",
        "assert x_transformed_train.shape[0] == y_transformed_train.shape[0]\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_transformed_train,y_transformed_train,test_size=0.25, random_state=42,shuffle=False)\n",
        "#X_train_,X_val,y_train_,y_val=train_test_split(X_train,y_train,test_size=0.2, random_state=42,shuffle=False)\n",
        "inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdKjqiCK5m_T",
        "outputId": "c49114ad-f44e-4600-c3bc-55e67aa1908a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 3, 15) dtype=float32 (created by layer 'input_3')>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "inputs1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "V27z-GjNapD4"
      },
      "outputs": [],
      "source": [
        "from keras import optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "uxD0diT8a4c2"
      },
      "outputs": [],
      "source": [
        "opt=optimizers.Adam(learning_rate=0.003)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "YM0Epc0yvWnJ"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "\n",
        "class CustomAdam(optimizers.Adam):\n",
        "    def __init__(self, new_idea_param=0.1, *args, **kwargs):\n",
        "        self.new_idea_param = new_idea_param\n",
        "        super(CustomAdam, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [K.update_add(self.iterations, 1)]\n",
        "\n",
        "        lr = self.lr\n",
        "        if self.initial_decay > 0:\n",
        "            lr *= (1. / (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n",
        "\n",
        "        t = K.cast(self.iterations, K.floatx()) + 1\n",
        "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        new_idea_t = self.new_idea_param * (K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        self.weights = [self.iterations] + ms + vs\n",
        "\n",
        "        for p, g, m, v in zip(params, grads, ms, vs):\n",
        "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
        "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
        "            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon) - new_idea_t * g\n",
        "\n",
        "            self.updates.append(K.update(m, m_t))\n",
        "            self.updates.append(K.update(v, v_t))\n",
        "            self.updates.append(K.update(p, p_t))\n",
        "        return self.updates"
      ],
      "metadata": {
        "id": "g8F6yCGl21Sz"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "\n",
        "class GradientAdam(optimizers.Adam):\n",
        "    def __init__(self, gradient_param=0.1, *args, **kwargs):\n",
        "        self.gradient_param = gradient_param\n",
        "        super(GradientAdam, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [K.update_add(self.iterations, 1)]\n",
        "\n",
        "        lr = self.lr\n",
        "        if self.initial_decay > 0:\n",
        "            lr *= (1. / (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n",
        "\n",
        "        t = K.cast(self.iterations, K.floatx()) + 1\n",
        "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        gradient_t = self.gradient_param * grads\n",
        "\n",
        "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        self.weights = [self.iterations] + ms + vs\n",
        "\n",
        "        for p, g, m, v, g_t in zip(params, grads, ms, vs, gradient_t):\n",
        "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
        "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
        "            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon) + g_t\n",
        "\n",
        "            self.updates.append(K.update(m, m_t))\n",
        "            self.updates.append(K.update(v, v_t))\n",
        "            self.updates.append(K.update(p, p_t))\n",
        "        return self.updates\n"
      ],
      "metadata": {
        "id": "J_gyZaJU8f4W"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "t0f48T0zsiAs"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "class HalvAdam(Adam):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.prev_gradients = None\n",
        "\n",
        "    @tf.function\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [math_ops.cast(x, \"float32\") for x in grads]\n",
        "\n",
        "        if self.prev_gradients is not None:\n",
        "            for i in range(len(grads)):\n",
        "                if (grads[i] * self.prev_gradients[i] < 0):\n",
        "                    self.updates[i] = self.updates[i] / 2\n",
        "\n",
        "        self.prev_gradients = grads\n",
        "        return self.updates"
      ],
      "metadata": {
        "id": "MpStRslgCRBO"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "class AdaptiveAdam(Adam):\n",
        "    def __init__(self, *args, factor=0.5, patience=5, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.wait = 0\n",
        "        self.best_loss = float('inf')\n",
        "        self.best_weights = None\n",
        "\n",
        "    @tf.function\n",
        "    def get_updates(self, loss, params):\n",
        "        current_loss = loss()\n",
        "        if current_loss < self.best_loss:\n",
        "            self.best_loss = current_loss\n",
        "            self.best_weights = params\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.wait = 0\n",
        "                self.lr = self.lr * self.factor\n",
        "                params = self.best_weights\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [math_ops.cast(g, \"float32\") for g in grads]\n",
        "        return self.updates\n"
      ],
      "metadata": {
        "id": "PmHcGR7JJLo_"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "class MomentumAdam(Adam):\n",
        "    def __init__(self, *args, momentum=0.9, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.momentum = momentum\n",
        "        self.velocities = [tf.Variable(tf.zeros_like(p), trainable=False) for p in self.weights]\n",
        "\n",
        "    @tf.function\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = []\n",
        "        for p, g, v in zip(params, grads, self.velocities):\n",
        "            v_t = self.momentum * v - self.lr * g\n",
        "            p_t = p + v_t\n",
        "            self.updates.append(p_t)\n",
        "            self.updates.append(v_t)\n",
        "        return self.updates\n"
      ],
      "metadata": {
        "id": "Zqo9SvzjbTtq"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "cSM9vzEq3G3U"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "nq9ZwBIrI_qj"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "18n5dRvpuI5T"
      },
      "outputs": [],
      "source": [
        "def define_model():\n",
        "\n",
        "\n",
        "  fe2_0 = Bidirectional(LSTM(256, activation='LeakyReLU',return_sequences = True))(inputs1)\n",
        "  fe2_1 = Dropout(0.6)(fe2_0)\n",
        "  fe2_2 = Bidirectional(LSTM(64, activation='LeakyReLU',return_sequences = True))(fe2_1)\n",
        "  fe2_3= Dropout(0.5)(fe2_2)\n",
        "  fe2_4=Bidirectional(LSTM(4, activation='LeakyReLU'))(fe2_3)\n",
        "  out2_1=Dense(1, activation='relu')(fe2_4)\n",
        "\n",
        "  fe3_0 =Bidirectional(LSTM(128, activation='LeakyReLU',return_sequences = True))(inputs1)\n",
        "  fe3_1 = Dropout(0.6)(fe3_0)\n",
        "  fe3_2 = Bidirectional(LSTM(96, activation='LeakyReLU',return_sequences = True))(fe3_1)\n",
        "  fe3_3= Dropout(0.5)(fe3_2)\n",
        "  fe3_4=Bidirectional(LSTM(8, activation='LeakyReLU'))(fe3_3)#16\n",
        "  out3_1=Dense(1, activation='relu')(fe3_4)\n",
        " \n",
        " \n",
        "\n",
        "  output = layers.average([out2_1, out3_1])\n",
        "  #merged3 = concatenate([out2_1,out3_1], name='concat3')\n",
        "  #output = Dense(1, activation='relu')( merged3)\n",
        "  \n",
        "\n",
        "  model = Model(inputs=[inputs1], outputs=[output])\n",
        "  \n",
        " \n",
        "  return model\n",
        "mdl=define_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss=[]"
      ],
      "metadata": {
        "id": "P5UqekV1_q7F"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import clone_model"
      ],
      "metadata": {
        "id": "9zy5UX8p_zSl"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "dAICp2p5OCER"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "9iwWrmDs0z7O"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GlobalMinimaSearch(weights):\n",
        "  if len(loss)>9:\n",
        "   return\n",
        "  \n",
        "  initial_weights =weights\n",
        "  model=clone_model(mdl)\n",
        "  model.set_weights(weights)\n",
        "  model.compile(optimizer=HalvAdam(learning_rate=0.003), loss='mean_squared_error')\n",
        "  model.fit(X_train, y_train, epochs=120, batch_size=128)\n",
        "  y= model.predict(X_test)\n",
        "  loss.append(np.sqrt(mean_squared_error(y,y_test)))\n",
        "  best_weights= model.get_weights()\n",
        "  \n",
        "\n",
        "     \n",
        "\n",
        "  params_1 =[final_weight + (final_weight - initial_weight) for initial_weight, final_weight in zip(initial_weights, best_weights)]\n",
        "  #GlobalMinimaSearch(params_1)\n",
        "\n",
        "\n",
        "  params_2 =[final_weight - (final_weight - initial_weight) for initial_weight, final_weight in zip(initial_weights, best_weights)]\n",
        "  GlobalMinimaSearch(params_2)\n",
        "  \n",
        " "
      ],
      "metadata": {
        "id": "FxpviTJb_nUR"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GlobalMinimaSearch(mdl.get_weights())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuddmGCf_1dR",
        "outputId": "c4b88a5c-831a-4b88-d430-d2d139ec8c98"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "36/36 [==============================] - 22s 150ms/step - loss: 0.0196\n",
            "Epoch 2/120\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.0080\n",
            "Epoch 3/120\n",
            "36/36 [==============================] - 6s 159ms/step - loss: 0.0081\n",
            "Epoch 4/120\n",
            "36/36 [==============================] - 7s 194ms/step - loss: 0.0065\n",
            "Epoch 5/120\n",
            "36/36 [==============================] - 7s 192ms/step - loss: 0.0060\n",
            "Epoch 6/120\n",
            "36/36 [==============================] - 5s 147ms/step - loss: 0.0060\n",
            "Epoch 7/120\n",
            "36/36 [==============================] - 9s 250ms/step - loss: 0.0062\n",
            "Epoch 8/120\n",
            "36/36 [==============================] - 5s 148ms/step - loss: 0.0055\n",
            "Epoch 9/120\n",
            "36/36 [==============================] - 7s 195ms/step - loss: 0.0056\n",
            "Epoch 10/120\n",
            "36/36 [==============================] - 5s 147ms/step - loss: 0.0058\n",
            "Epoch 11/120\n",
            "36/36 [==============================] - 6s 160ms/step - loss: 0.0058\n",
            "Epoch 12/120\n",
            "36/36 [==============================] - 7s 179ms/step - loss: 0.0054\n",
            "Epoch 13/120\n",
            "36/36 [==============================] - 8s 216ms/step - loss: 0.0054\n",
            "Epoch 14/120\n",
            "36/36 [==============================] - 6s 171ms/step - loss: 0.0051\n",
            "Epoch 15/120\n",
            "36/36 [==============================] - 5s 151ms/step - loss: 0.0052\n",
            "Epoch 16/120\n",
            "36/36 [==============================] - 7s 196ms/step - loss: 0.0053\n",
            "Epoch 17/120\n",
            "36/36 [==============================] - 5s 147ms/step - loss: 0.0051\n",
            "Epoch 18/120\n",
            "36/36 [==============================] - 7s 194ms/step - loss: 0.0049\n",
            "Epoch 19/120\n",
            "36/36 [==============================] - 5s 147ms/step - loss: 0.0052\n",
            "Epoch 20/120\n",
            "36/36 [==============================] - 7s 194ms/step - loss: 0.0053\n",
            "Epoch 21/120\n",
            "36/36 [==============================] - 7s 191ms/step - loss: 0.0054\n",
            "Epoch 22/120\n",
            "36/36 [==============================] - 7s 198ms/step - loss: 0.0051\n",
            "Epoch 23/120\n",
            "36/36 [==============================] - 5s 147ms/step - loss: 0.0049\n",
            "Epoch 24/120\n",
            "36/36 [==============================] - 6s 172ms/step - loss: 0.0049\n",
            "Epoch 25/120\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.0049\n",
            "Epoch 26/120\n",
            "36/36 [==============================] - 5s 150ms/step - loss: 0.0056\n",
            "Epoch 27/120\n",
            "36/36 [==============================] - 7s 195ms/step - loss: 0.0048\n",
            "Epoch 28/120\n",
            "36/36 [==============================] - 5s 151ms/step - loss: 0.0050\n",
            "Epoch 29/120\n",
            "36/36 [==============================] - 7s 198ms/step - loss: 0.0047\n",
            "Epoch 30/120\n",
            "36/36 [==============================] - 7s 198ms/step - loss: 0.0048\n",
            "Epoch 31/120\n",
            "36/36 [==============================] - 7s 198ms/step - loss: 0.0049\n",
            "Epoch 32/120\n",
            "36/36 [==============================] - 5s 149ms/step - loss: 0.0048\n",
            "Epoch 33/120\n",
            "36/36 [==============================] - 7s 197ms/step - loss: 0.0046\n",
            "Epoch 34/120\n",
            "36/36 [==============================] - 5s 151ms/step - loss: 0.0048\n",
            "Epoch 35/120\n",
            "36/36 [==============================] - 7s 188ms/step - loss: 0.0046\n",
            "Epoch 36/120\n",
            "36/36 [==============================] - 6s 156ms/step - loss: 0.0050\n",
            "Epoch 37/120\n",
            "36/36 [==============================] - 6s 157ms/step - loss: 0.0047\n",
            "Epoch 38/120\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.0048\n",
            "Epoch 39/120\n",
            "36/36 [==============================] - 5s 147ms/step - loss: 0.0047\n",
            "Epoch 40/120\n",
            "36/36 [==============================] - 7s 195ms/step - loss: 0.0046\n",
            "Epoch 41/120\n",
            "36/36 [==============================] - 7s 199ms/step - loss: 0.0048\n",
            "Epoch 42/120\n",
            "36/36 [==============================] - 9s 246ms/step - loss: 0.0046\n",
            "Epoch 43/120\n",
            "36/36 [==============================] - 5s 149ms/step - loss: 0.0047\n",
            "Epoch 44/120\n",
            "36/36 [==============================] - 7s 195ms/step - loss: 0.0046\n",
            "Epoch 45/120\n",
            "36/36 [==============================] - 5s 148ms/step - loss: 0.0047\n",
            "Epoch 46/120\n",
            "36/36 [==============================] - 7s 196ms/step - loss: 0.0046\n",
            "Epoch 47/120\n",
            "36/36 [==============================] - 5s 148ms/step - loss: 0.0045\n",
            "Epoch 48/120\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0046\n",
            "Epoch 49/120\n",
            "36/36 [==============================] - 8s 209ms/step - loss: 0.0044\n",
            "Epoch 50/120\n",
            "36/36 [==============================] - 7s 187ms/step - loss: 0.0047\n",
            "Epoch 51/120\n",
            "36/36 [==============================] - 6s 159ms/step - loss: 0.0045\n",
            "Epoch 52/120\n",
            "36/36 [==============================] - 5s 148ms/step - loss: 0.0044\n",
            "Epoch 53/120\n",
            "36/36 [==============================] - 7s 190ms/step - loss: 0.0044\n",
            "Epoch 54/120\n",
            "36/36 [==============================] - 5s 147ms/step - loss: 0.0045\n",
            "Epoch 55/120\n",
            "36/36 [==============================] - 7s 196ms/step - loss: 0.0044\n",
            "Epoch 56/120\n",
            "36/36 [==============================] - 5s 145ms/step - loss: 0.0045\n",
            "Epoch 57/120\n",
            "36/36 [==============================] - 7s 196ms/step - loss: 0.0046\n",
            "Epoch 58/120\n",
            "36/36 [==============================] - 7s 188ms/step - loss: 0.0045\n",
            "Epoch 59/120\n",
            "36/36 [==============================] - 7s 194ms/step - loss: 0.0045\n",
            "Epoch 60/120\n",
            "36/36 [==============================] - 5s 145ms/step - loss: 0.0046\n",
            "Epoch 61/120\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0044\n",
            "Epoch 62/120\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0043\n",
            "Epoch 63/120\n",
            "36/36 [==============================] - 5s 148ms/step - loss: 0.0045\n",
            "Epoch 64/120\n",
            "36/36 [==============================] - 7s 195ms/step - loss: 0.0044\n",
            "Epoch 65/120\n",
            "36/36 [==============================] - 5s 149ms/step - loss: 0.0045\n",
            "Epoch 66/120\n",
            "36/36 [==============================] - 8s 233ms/step - loss: 0.0045\n",
            "Epoch 67/120\n",
            "36/36 [==============================] - 6s 157ms/step - loss: 0.0046\n",
            "Epoch 68/120\n",
            "36/36 [==============================] - 7s 196ms/step - loss: 0.0043\n",
            "Epoch 69/120\n",
            "36/36 [==============================] - 5s 152ms/step - loss: 0.0044\n",
            "Epoch 70/120\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0044\n",
            "Epoch 71/120\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0044\n",
            "Epoch 72/120\n",
            "36/36 [==============================] - 5s 150ms/step - loss: 0.0044\n",
            "Epoch 73/120\n",
            "36/36 [==============================] - 7s 198ms/step - loss: 0.0072\n",
            "Epoch 74/120\n",
            "36/36 [==============================] - 5s 149ms/step - loss: 0.0076\n",
            "Epoch 75/120\n",
            "36/36 [==============================] - 9s 249ms/step - loss: 0.0058\n",
            "Epoch 76/120\n",
            "36/36 [==============================] - 5s 146ms/step - loss: 0.0050\n",
            "Epoch 77/120\n",
            "36/36 [==============================] - 6s 171ms/step - loss: 0.0049\n",
            "Epoch 78/120\n",
            "36/36 [==============================] - 8s 218ms/step - loss: 0.0050\n",
            "Epoch 79/120\n",
            "36/36 [==============================] - 5s 147ms/step - loss: 0.0045\n",
            "Epoch 80/120\n",
            "36/36 [==============================] - 7s 197ms/step - loss: 0.0047\n",
            "Epoch 81/120\n",
            "36/36 [==============================] - 5s 146ms/step - loss: 0.0048\n",
            "Epoch 82/120\n",
            "36/36 [==============================] - 7s 196ms/step - loss: 0.0046\n",
            "Epoch 83/120\n",
            "36/36 [==============================] - 7s 197ms/step - loss: 0.0047\n",
            "Epoch 84/120\n",
            "36/36 [==============================] - 7s 196ms/step - loss: 0.0045\n",
            "Epoch 85/120\n",
            "36/36 [==============================] - 5s 149ms/step - loss: 0.0045\n",
            "Epoch 86/120\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0044\n",
            "Epoch 87/120\n",
            "36/36 [==============================] - 6s 172ms/step - loss: 0.0044\n",
            "Epoch 88/120\n",
            "36/36 [==============================] - 5s 147ms/step - loss: 0.0044\n",
            "Epoch 89/120\n",
            "36/36 [==============================] - 7s 195ms/step - loss: 0.0044\n",
            "Epoch 90/120\n",
            "36/36 [==============================] - 5s 148ms/step - loss: 0.0044\n",
            "Epoch 91/120\n",
            "36/36 [==============================] - 8s 218ms/step - loss: 0.0046\n",
            "Epoch 92/120\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0044\n",
            "Epoch 93/120\n",
            "36/36 [==============================] - 7s 197ms/step - loss: 0.0044\n",
            "Epoch 94/120\n",
            "36/36 [==============================] - 5s 148ms/step - loss: 0.0043\n",
            "Epoch 95/120\n",
            "36/36 [==============================] - 7s 193ms/step - loss: 0.0044\n",
            "Epoch 96/120\n",
            "36/36 [==============================] - 5s 145ms/step - loss: 0.0044\n",
            "Epoch 97/120\n",
            "36/36 [==============================] - 6s 165ms/step - loss: 0.0042\n",
            "Epoch 98/120\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0043\n",
            "Epoch 99/120\n",
            "36/36 [==============================] - 5s 148ms/step - loss: 0.0043\n",
            "Epoch 100/120\n",
            "36/36 [==============================] - 9s 244ms/step - loss: 0.0044\n",
            "Epoch 101/120\n",
            "36/36 [==============================] - 5s 145ms/step - loss: 0.0041\n",
            "Epoch 102/120\n",
            "36/36 [==============================] - 7s 192ms/step - loss: 0.0041\n",
            "Epoch 103/120\n",
            "36/36 [==============================] - 5s 146ms/step - loss: 0.0041\n",
            "Epoch 104/120\n",
            "36/36 [==============================] - 7s 192ms/step - loss: 0.0041\n",
            "Epoch 105/120\n",
            "36/36 [==============================] - 5s 145ms/step - loss: 0.0042\n",
            "Epoch 106/120\n",
            "36/36 [==============================] - 6s 165ms/step - loss: 0.0041\n",
            "Epoch 107/120\n",
            "36/36 [==============================] - 6s 172ms/step - loss: 0.0042\n",
            "Epoch 108/120\n",
            "36/36 [==============================] - 5s 146ms/step - loss: 0.0040\n",
            "Epoch 109/120\n",
            "36/36 [==============================] - 9s 247ms/step - loss: 0.0041\n",
            "Epoch 110/120\n",
            "36/36 [==============================] - 5s 150ms/step - loss: 0.0042\n",
            "Epoch 111/120\n",
            "36/36 [==============================] - 6s 181ms/step - loss: 0.0042\n",
            "Epoch 112/120\n",
            "36/36 [==============================] - 6s 157ms/step - loss: 0.0040\n",
            "Epoch 113/120\n",
            "36/36 [==============================] - 8s 216ms/step - loss: 0.0041\n",
            "Epoch 114/120\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0040\n",
            "Epoch 115/120\n",
            "36/36 [==============================] - 5s 147ms/step - loss: 0.0040\n",
            "Epoch 116/120\n",
            "36/36 [==============================] - 7s 197ms/step - loss: 0.0041\n",
            "Epoch 117/120\n",
            "36/36 [==============================] - 7s 197ms/step - loss: 0.0040\n",
            "Epoch 118/120\n",
            "36/36 [==============================] - 7s 194ms/step - loss: 0.0042\n",
            "Epoch 119/120\n",
            "36/36 [==============================] - 5s 148ms/step - loss: 0.0040\n",
            "Epoch 120/120\n",
            "36/36 [==============================] - 7s 195ms/step - loss: 0.0041\n",
            "48/48 [==============================] - 3s 23ms/step\n",
            "Epoch 1/120\n",
            "36/36 [==============================] - 22s 182ms/step - loss: 0.0193\n",
            "Epoch 2/120\n",
            "36/36 [==============================] - 6s 156ms/step - loss: 0.0078\n",
            "Epoch 3/120\n",
            "36/36 [==============================] - 7s 195ms/step - loss: 0.0067\n",
            "Epoch 4/120\n",
            "36/36 [==============================] - 5s 139ms/step - loss: 0.0061\n",
            "Epoch 5/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0064\n",
            "Epoch 6/120\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0065\n",
            "Epoch 7/120\n",
            "36/36 [==============================] - 5s 135ms/step - loss: 0.0057\n",
            "Epoch 8/120\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0056\n",
            "Epoch 9/120\n",
            "36/36 [==============================] - 5s 142ms/step - loss: 0.0056\n",
            "Epoch 10/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0055\n",
            "Epoch 11/120\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0054\n",
            "Epoch 12/120\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.0058\n",
            "Epoch 13/120\n",
            "36/36 [==============================] - 6s 181ms/step - loss: 0.0059\n",
            "Epoch 14/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0053\n",
            "Epoch 15/120\n",
            "36/36 [==============================] - 5s 153ms/step - loss: 0.0055\n",
            "Epoch 16/120\n",
            "36/36 [==============================] - 6s 160ms/step - loss: 0.0054\n",
            "Epoch 17/120\n",
            "36/36 [==============================] - 5s 135ms/step - loss: 0.0051\n",
            "Epoch 18/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0051\n",
            "Epoch 19/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0052\n",
            "Epoch 20/120\n",
            "36/36 [==============================] - 6s 154ms/step - loss: 0.0051\n",
            "Epoch 21/120\n",
            "36/36 [==============================] - 8s 210ms/step - loss: 0.0051\n",
            "Epoch 22/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0050\n",
            "Epoch 23/120\n",
            "36/36 [==============================] - 7s 181ms/step - loss: 0.0049\n",
            "Epoch 24/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0048\n",
            "Epoch 25/120\n",
            "36/36 [==============================] - 6s 182ms/step - loss: 0.0050\n",
            "Epoch 26/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0050\n",
            "Epoch 27/120\n",
            "36/36 [==============================] - 6s 160ms/step - loss: 0.0050\n",
            "Epoch 28/120\n",
            "36/36 [==============================] - 7s 205ms/step - loss: 0.0048\n",
            "Epoch 29/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0050\n",
            "Epoch 30/120\n",
            "36/36 [==============================] - 6s 175ms/step - loss: 0.0047\n",
            "Epoch 31/120\n",
            "36/36 [==============================] - 7s 189ms/step - loss: 0.0047\n",
            "Epoch 32/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0048\n",
            "Epoch 33/120\n",
            "36/36 [==============================] - 7s 183ms/step - loss: 0.0052\n",
            "Epoch 34/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0048\n",
            "Epoch 35/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0051\n",
            "Epoch 36/120\n",
            "36/36 [==============================] - 6s 182ms/step - loss: 0.0047\n",
            "Epoch 37/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0047\n",
            "Epoch 38/120\n",
            "36/36 [==============================] - 7s 183ms/step - loss: 0.0047\n",
            "Epoch 39/120\n",
            "36/36 [==============================] - 5s 150ms/step - loss: 0.0046\n",
            "Epoch 40/120\n",
            "36/36 [==============================] - 7s 194ms/step - loss: 0.0045\n",
            "Epoch 41/120\n",
            "36/36 [==============================] - 5s 147ms/step - loss: 0.0045\n",
            "Epoch 42/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0046\n",
            "Epoch 43/120\n",
            "36/36 [==============================] - 7s 183ms/step - loss: 0.0047\n",
            "Epoch 44/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0045\n",
            "Epoch 45/120\n",
            "36/36 [==============================] - 6s 171ms/step - loss: 0.0045\n",
            "Epoch 46/120\n",
            "36/36 [==============================] - 5s 146ms/step - loss: 0.0045\n",
            "Epoch 47/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0047\n",
            "Epoch 48/120\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.0045\n",
            "Epoch 49/120\n",
            "36/36 [==============================] - 6s 181ms/step - loss: 0.0047\n",
            "Epoch 50/120\n",
            "36/36 [==============================] - 6s 181ms/step - loss: 0.0045\n",
            "Epoch 51/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0045\n",
            "Epoch 52/120\n",
            "36/36 [==============================] - 5s 145ms/step - loss: 0.0044\n",
            "Epoch 53/120\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0045\n",
            "Epoch 54/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0048\n",
            "Epoch 55/120\n",
            "36/36 [==============================] - 6s 181ms/step - loss: 0.0046\n",
            "Epoch 56/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0052\n",
            "Epoch 57/120\n",
            "36/36 [==============================] - 5s 147ms/step - loss: 0.0049\n",
            "Epoch 58/120\n",
            "36/36 [==============================] - 8s 217ms/step - loss: 0.0044\n",
            "Epoch 59/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0045\n",
            "Epoch 60/120\n",
            "36/36 [==============================] - 6s 181ms/step - loss: 0.0044\n",
            "Epoch 61/120\n",
            "36/36 [==============================] - 5s 135ms/step - loss: 0.0045\n",
            "Epoch 62/120\n",
            "36/36 [==============================] - 7s 183ms/step - loss: 0.0044\n",
            "Epoch 63/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0044\n",
            "Epoch 64/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0044\n",
            "Epoch 65/120\n",
            "36/36 [==============================] - 7s 183ms/step - loss: 0.0044\n",
            "Epoch 66/120\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0051\n",
            "Epoch 67/120\n",
            "36/36 [==============================] - 8s 223ms/step - loss: 0.0043\n",
            "Epoch 68/120\n",
            "36/36 [==============================] - 5s 140ms/step - loss: 0.0044\n",
            "Epoch 69/120\n",
            "36/36 [==============================] - 6s 166ms/step - loss: 0.0041\n",
            "Epoch 70/120\n",
            "36/36 [==============================] - 5s 146ms/step - loss: 0.0044\n",
            "Epoch 71/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0044\n",
            "Epoch 72/120\n",
            "36/36 [==============================] - 6s 181ms/step - loss: 0.0043\n",
            "Epoch 73/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0042\n",
            "Epoch 74/120\n",
            "36/36 [==============================] - 6s 154ms/step - loss: 0.0043\n",
            "Epoch 75/120\n",
            "36/36 [==============================] - 6s 156ms/step - loss: 0.0043\n",
            "Epoch 76/120\n",
            "36/36 [==============================] - 5s 135ms/step - loss: 0.0043\n",
            "Epoch 77/120\n",
            "36/36 [==============================] - 8s 228ms/step - loss: 0.0044\n",
            "Epoch 78/120\n",
            "36/36 [==============================] - 5s 136ms/step - loss: 0.0044\n",
            "Epoch 79/120\n",
            "36/36 [==============================] - 5s 152ms/step - loss: 0.0043\n",
            "Epoch 80/120\n",
            "36/36 [==============================] - 6s 164ms/step - loss: 0.0044\n",
            "Epoch 81/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0042\n",
            "Epoch 82/120\n",
            "36/36 [==============================] - 7s 183ms/step - loss: 0.0043\n",
            "Epoch 83/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0043\n",
            "Epoch 84/120\n",
            "36/36 [==============================] - 5s 145ms/step - loss: 0.0042\n",
            "Epoch 85/120\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0042\n",
            "Epoch 86/120\n",
            "36/36 [==============================] - 7s 186ms/step - loss: 0.0045\n",
            "Epoch 87/120\n",
            "36/36 [==============================] - 7s 183ms/step - loss: 0.0044\n",
            "Epoch 88/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0042\n",
            "Epoch 89/120\n",
            "36/36 [==============================] - 7s 183ms/step - loss: 0.0042\n",
            "Epoch 90/120\n",
            "36/36 [==============================] - 5s 135ms/step - loss: 0.0042\n",
            "Epoch 91/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0041\n",
            "Epoch 92/120\n",
            "36/36 [==============================] - 7s 179ms/step - loss: 0.0041\n",
            "Epoch 93/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0045\n",
            "Epoch 94/120\n",
            "36/36 [==============================] - 6s 182ms/step - loss: 0.0042\n",
            "Epoch 95/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0041\n",
            "Epoch 96/120\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0043\n",
            "Epoch 97/120\n",
            "36/36 [==============================] - 5s 139ms/step - loss: 0.0043\n",
            "Epoch 98/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0043\n",
            "Epoch 99/120\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.0041\n",
            "Epoch 100/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0042\n",
            "Epoch 101/120\n",
            "36/36 [==============================] - 6s 171ms/step - loss: 0.0041\n",
            "Epoch 102/120\n",
            "36/36 [==============================] - 5s 142ms/step - loss: 0.0041\n",
            "Epoch 103/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0042\n",
            "Epoch 104/120\n",
            "36/36 [==============================] - 6s 181ms/step - loss: 0.0041\n",
            "Epoch 105/120\n",
            "36/36 [==============================] - 8s 235ms/step - loss: 0.0041\n",
            "Epoch 106/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0040\n",
            "Epoch 107/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0040\n",
            "Epoch 108/120\n",
            "36/36 [==============================] - 7s 183ms/step - loss: 0.0041\n",
            "Epoch 109/120\n",
            "36/36 [==============================] - 5s 135ms/step - loss: 0.0042\n",
            "Epoch 110/120\n",
            "36/36 [==============================] - 5s 139ms/step - loss: 0.0041\n",
            "Epoch 111/120\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0038\n",
            "Epoch 112/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0042\n",
            "Epoch 113/120\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.0040\n",
            "Epoch 114/120\n",
            "36/36 [==============================] - 7s 183ms/step - loss: 0.0041\n",
            "Epoch 115/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0040\n",
            "Epoch 116/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0039\n",
            "Epoch 117/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0039\n",
            "Epoch 118/120\n",
            "36/36 [==============================] - 6s 181ms/step - loss: 0.0038\n",
            "Epoch 119/120\n",
            "36/36 [==============================] - 5s 136ms/step - loss: 0.0039\n",
            "Epoch 120/120\n",
            "36/36 [==============================] - 6s 176ms/step - loss: 0.0039\n",
            "48/48 [==============================] - 3s 21ms/step\n",
            "Epoch 1/120\n",
            "36/36 [==============================] - 23s 162ms/step - loss: 0.0209\n",
            "Epoch 2/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0086\n",
            "Epoch 3/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0070\n",
            "Epoch 4/120\n",
            "36/36 [==============================] - 5s 127ms/step - loss: 0.0065\n",
            "Epoch 5/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0060\n",
            "Epoch 6/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0062\n",
            "Epoch 7/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0062\n",
            "Epoch 8/120\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0055\n",
            "Epoch 9/120\n",
            "36/36 [==============================] - 6s 162ms/step - loss: 0.0058\n",
            "Epoch 10/120\n",
            "36/36 [==============================] - 6s 162ms/step - loss: 0.0054\n",
            "Epoch 11/120\n",
            "36/36 [==============================] - 8s 209ms/step - loss: 0.0060\n",
            "Epoch 12/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0061\n",
            "Epoch 13/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0053\n",
            "Epoch 14/120\n",
            "36/36 [==============================] - 5s 127ms/step - loss: 0.0053\n",
            "Epoch 15/120\n",
            "36/36 [==============================] - 5s 146ms/step - loss: 0.0052\n",
            "Epoch 16/120\n",
            "36/36 [==============================] - 6s 159ms/step - loss: 0.0056\n",
            "Epoch 17/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0052\n",
            "Epoch 18/120\n",
            "36/36 [==============================] - 7s 196ms/step - loss: 0.0052\n",
            "Epoch 19/120\n",
            "36/36 [==============================] - 6s 158ms/step - loss: 0.0052\n",
            "Epoch 20/120\n",
            "36/36 [==============================] - 6s 171ms/step - loss: 0.0051\n",
            "Epoch 21/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0052\n",
            "Epoch 22/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0050\n",
            "Epoch 23/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0048\n",
            "Epoch 24/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0047\n",
            "Epoch 25/120\n",
            "36/36 [==============================] - 5s 145ms/step - loss: 0.0049\n",
            "Epoch 26/120\n",
            "36/36 [==============================] - 6s 157ms/step - loss: 0.0051\n",
            "Epoch 27/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0049\n",
            "Epoch 28/120\n",
            "36/36 [==============================] - 7s 192ms/step - loss: 0.0052\n",
            "Epoch 29/120\n",
            "36/36 [==============================] - 6s 160ms/step - loss: 0.0047\n",
            "Epoch 30/120\n",
            "36/36 [==============================] - 5s 135ms/step - loss: 0.0053\n",
            "Epoch 31/120\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0048\n",
            "Epoch 32/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0046\n",
            "Epoch 33/120\n",
            "36/36 [==============================] - 6s 172ms/step - loss: 0.0047\n",
            "Epoch 34/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0047\n",
            "Epoch 35/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0047\n",
            "Epoch 36/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0048\n",
            "Epoch 37/120\n",
            "36/36 [==============================] - 5s 127ms/step - loss: 0.0048\n",
            "Epoch 38/120\n",
            "36/36 [==============================] - 5s 150ms/step - loss: 0.0049\n",
            "Epoch 39/120\n",
            "36/36 [==============================] - 7s 205ms/step - loss: 0.0046\n",
            "Epoch 40/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0047\n",
            "Epoch 41/120\n",
            "36/36 [==============================] - 5s 152ms/step - loss: 0.0049\n",
            "Epoch 42/120\n",
            "36/36 [==============================] - 6s 152ms/step - loss: 0.0049\n",
            "Epoch 43/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0049\n",
            "Epoch 44/120\n",
            "36/36 [==============================] - 6s 176ms/step - loss: 0.0046\n",
            "Epoch 45/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0047\n",
            "Epoch 46/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0048\n",
            "Epoch 47/120\n",
            "36/36 [==============================] - 6s 175ms/step - loss: 0.0046\n",
            "Epoch 48/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0045\n",
            "Epoch 49/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0046\n",
            "Epoch 50/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0047\n",
            "Epoch 51/120\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0047\n",
            "Epoch 52/120\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0046\n",
            "Epoch 53/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0045\n",
            "Epoch 54/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0045\n",
            "Epoch 55/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0045\n",
            "Epoch 56/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0045\n",
            "Epoch 57/120\n",
            "36/36 [==============================] - 8s 224ms/step - loss: 0.0043\n",
            "Epoch 58/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0046\n",
            "Epoch 59/120\n",
            "36/36 [==============================] - 6s 157ms/step - loss: 0.0043\n",
            "Epoch 60/120\n",
            "36/36 [==============================] - 5s 146ms/step - loss: 0.0045\n",
            "Epoch 61/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0044\n",
            "Epoch 62/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0044\n",
            "Epoch 63/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0044\n",
            "Epoch 64/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0043\n",
            "Epoch 65/120\n",
            "36/36 [==============================] - 6s 172ms/step - loss: 0.0045\n",
            "Epoch 66/120\n",
            "36/36 [==============================] - 5s 127ms/step - loss: 0.0045\n",
            "Epoch 67/120\n",
            "36/36 [==============================] - 7s 194ms/step - loss: 0.0042\n",
            "Epoch 68/120\n",
            "36/36 [==============================] - 6s 161ms/step - loss: 0.0042\n",
            "Epoch 69/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0043\n",
            "Epoch 70/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0044\n",
            "Epoch 71/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0045\n",
            "Epoch 72/120\n",
            "36/36 [==============================] - 5s 127ms/step - loss: 0.0043\n",
            "Epoch 73/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0044\n",
            "Epoch 74/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0043\n",
            "Epoch 75/120\n",
            "36/36 [==============================] - 6s 161ms/step - loss: 0.0042\n",
            "Epoch 76/120\n",
            "36/36 [==============================] - 5s 138ms/step - loss: 0.0043\n",
            "Epoch 77/120\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0044\n",
            "Epoch 78/120\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0041\n",
            "Epoch 79/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0043\n",
            "Epoch 80/120\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.0044\n",
            "Epoch 81/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0043\n",
            "Epoch 82/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0042\n",
            "Epoch 83/120\n",
            "36/36 [==============================] - 7s 183ms/step - loss: 0.0041\n",
            "Epoch 84/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0042\n",
            "Epoch 85/120\n",
            "36/36 [==============================] - 5s 147ms/step - loss: 0.0043\n",
            "Epoch 86/120\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0042\n",
            "Epoch 87/120\n",
            "36/36 [==============================] - 6s 162ms/step - loss: 0.0042\n",
            "Epoch 88/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0040\n",
            "Epoch 89/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0042\n",
            "Epoch 90/120\n",
            "36/36 [==============================] - 6s 165ms/step - loss: 0.0041\n",
            "Epoch 91/120\n",
            "36/36 [==============================] - 7s 188ms/step - loss: 0.0041\n",
            "Epoch 92/120\n",
            "36/36 [==============================] - 5s 139ms/step - loss: 0.0041\n",
            "Epoch 93/120\n",
            "36/36 [==============================] - 6s 163ms/step - loss: 0.0045\n",
            "Epoch 94/120\n",
            "36/36 [==============================] - 5s 126ms/step - loss: 0.0042\n",
            "Epoch 95/120\n",
            "36/36 [==============================] - 6s 181ms/step - loss: 0.0044\n",
            "Epoch 96/120\n",
            "36/36 [==============================] - 6s 172ms/step - loss: 0.0042\n",
            "Epoch 97/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0040\n",
            "Epoch 98/120\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.0041\n",
            "Epoch 99/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0042\n",
            "Epoch 100/120\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0043\n",
            "Epoch 101/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0040\n",
            "Epoch 102/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0042\n",
            "Epoch 103/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0040\n",
            "Epoch 104/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0041\n",
            "Epoch 105/120\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0039\n",
            "Epoch 106/120\n",
            "36/36 [==============================] - 7s 187ms/step - loss: 0.0044\n",
            "Epoch 107/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0040\n",
            "Epoch 108/120\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.0039\n",
            "Epoch 109/120\n",
            "36/36 [==============================] - 5s 135ms/step - loss: 0.0041\n",
            "Epoch 110/120\n",
            "36/36 [==============================] - 5s 127ms/step - loss: 0.0040\n",
            "Epoch 111/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0044\n",
            "Epoch 112/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0043\n",
            "Epoch 113/120\n",
            "36/36 [==============================] - 5s 141ms/step - loss: 0.0041\n",
            "Epoch 114/120\n",
            "36/36 [==============================] - 6s 162ms/step - loss: 0.0041\n",
            "Epoch 115/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0040\n",
            "Epoch 116/120\n",
            "36/36 [==============================] - 6s 181ms/step - loss: 0.0039\n",
            "Epoch 117/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0042\n",
            "Epoch 118/120\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.0039\n",
            "Epoch 119/120\n",
            "36/36 [==============================] - 5s 138ms/step - loss: 0.0041\n",
            "Epoch 120/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0042\n",
            "48/48 [==============================] - 4s 39ms/step\n",
            "Epoch 1/120\n",
            "36/36 [==============================] - 22s 154ms/step - loss: 0.0224\n",
            "Epoch 2/120\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.0077\n",
            "Epoch 3/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0073\n",
            "Epoch 4/120\n",
            "36/36 [==============================] - 6s 161ms/step - loss: 0.0065\n",
            "Epoch 5/120\n",
            "36/36 [==============================] - 5s 143ms/step - loss: 0.0063\n",
            "Epoch 6/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0067\n",
            "Epoch 7/120\n",
            "36/36 [==============================] - 8s 221ms/step - loss: 0.0062\n",
            "Epoch 8/120\n",
            "36/36 [==============================] - 5s 137ms/step - loss: 0.0058\n",
            "Epoch 9/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0056\n",
            "Epoch 10/120\n",
            "36/36 [==============================] - 8s 219ms/step - loss: 0.0057\n",
            "Epoch 11/120\n",
            "36/36 [==============================] - 5s 138ms/step - loss: 0.0057\n",
            "Epoch 12/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0055\n",
            "Epoch 13/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0053\n",
            "Epoch 14/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0053\n",
            "Epoch 15/120\n",
            "36/36 [==============================] - 6s 160ms/step - loss: 0.0052\n",
            "Epoch 16/120\n",
            "36/36 [==============================] - 5s 142ms/step - loss: 0.0052\n",
            "Epoch 17/120\n",
            "36/36 [==============================] - 5s 126ms/step - loss: 0.0055\n",
            "Epoch 18/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0052\n",
            "Epoch 19/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0050\n",
            "Epoch 20/120\n",
            "36/36 [==============================] - 8s 208ms/step - loss: 0.0050\n",
            "Epoch 21/120\n",
            "36/36 [==============================] - 5s 135ms/step - loss: 0.0048\n",
            "Epoch 22/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0052\n",
            "Epoch 23/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0050\n",
            "Epoch 24/120\n",
            "36/36 [==============================] - 5s 127ms/step - loss: 0.0050\n",
            "Epoch 25/120\n",
            "36/36 [==============================] - 5s 136ms/step - loss: 0.0050\n",
            "Epoch 26/120\n",
            "36/36 [==============================] - 6s 165ms/step - loss: 0.0049\n",
            "Epoch 27/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0049\n",
            "Epoch 28/120\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0047\n",
            "Epoch 29/120\n",
            "36/36 [==============================] - 5s 143ms/step - loss: 0.0047\n",
            "Epoch 30/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0047\n",
            "Epoch 31/120\n",
            "36/36 [==============================] - 6s 157ms/step - loss: 0.0049\n",
            "Epoch 32/120\n",
            "36/36 [==============================] - 5s 127ms/step - loss: 0.0046\n",
            "Epoch 33/120\n",
            "36/36 [==============================] - 6s 175ms/step - loss: 0.0048\n",
            "Epoch 34/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0051\n",
            "Epoch 35/120\n",
            "36/36 [==============================] - 5s 127ms/step - loss: 0.0047\n",
            "Epoch 36/120\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0050\n",
            "Epoch 37/120\n",
            "36/36 [==============================] - 5s 126ms/step - loss: 0.0050\n",
            "Epoch 38/120\n",
            "36/36 [==============================] - 5s 146ms/step - loss: 0.0047\n",
            "Epoch 39/120\n",
            "36/36 [==============================] - 7s 207ms/step - loss: 0.0048\n",
            "Epoch 40/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0048\n",
            "Epoch 41/120\n",
            "36/36 [==============================] - 6s 175ms/step - loss: 0.0046\n",
            "Epoch 42/120\n",
            "36/36 [==============================] - 5s 126ms/step - loss: 0.0045\n",
            "Epoch 43/120\n",
            "36/36 [==============================] - 5s 150ms/step - loss: 0.0045\n",
            "Epoch 44/120\n",
            "36/36 [==============================] - 5s 150ms/step - loss: 0.0050\n",
            "Epoch 45/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0048\n",
            "Epoch 46/120\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.0047\n",
            "Epoch 47/120\n",
            "36/36 [==============================] - 7s 183ms/step - loss: 0.0046\n",
            "Epoch 48/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0045\n",
            "Epoch 49/120\n",
            "36/36 [==============================] - 6s 176ms/step - loss: 0.0046\n",
            "Epoch 50/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0045\n",
            "Epoch 51/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0047\n",
            "Epoch 52/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0044\n",
            "Epoch 53/120\n",
            "36/36 [==============================] - 6s 162ms/step - loss: 0.0045\n",
            "Epoch 54/120\n",
            "36/36 [==============================] - 5s 142ms/step - loss: 0.0046\n",
            "Epoch 55/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0043\n",
            "Epoch 56/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0044\n",
            "Epoch 57/120\n",
            "36/36 [==============================] - 5s 127ms/step - loss: 0.0044\n",
            "Epoch 58/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0047\n",
            "Epoch 59/120\n",
            "36/36 [==============================] - 8s 220ms/step - loss: 0.0043\n",
            "Epoch 60/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0044\n",
            "Epoch 61/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0045\n",
            "Epoch 62/120\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0046\n",
            "Epoch 63/120\n",
            "36/36 [==============================] - 5s 127ms/step - loss: 0.0044\n",
            "Epoch 64/120\n",
            "36/36 [==============================] - 6s 172ms/step - loss: 0.0044\n",
            "Epoch 65/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0043\n",
            "Epoch 66/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0046\n",
            "Epoch 67/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0045\n",
            "Epoch 68/120\n",
            "36/36 [==============================] - 6s 176ms/step - loss: 0.0043\n",
            "Epoch 69/120\n",
            "36/36 [==============================] - 6s 176ms/step - loss: 0.0044\n",
            "Epoch 70/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0043\n",
            "Epoch 71/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0043\n",
            "Epoch 72/120\n",
            "36/36 [==============================] - 6s 176ms/step - loss: 0.0044\n",
            "Epoch 73/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0047\n",
            "Epoch 74/120\n",
            "36/36 [==============================] - 6s 157ms/step - loss: 0.0044\n",
            "Epoch 75/120\n",
            "36/36 [==============================] - 5s 147ms/step - loss: 0.0044\n",
            "Epoch 76/120\n",
            "36/36 [==============================] - 5s 126ms/step - loss: 0.0043\n",
            "Epoch 77/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0044\n",
            "Epoch 78/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0042\n",
            "Epoch 79/120\n",
            "36/36 [==============================] - 6s 166ms/step - loss: 0.0048\n",
            "Epoch 80/120\n",
            "36/36 [==============================] - 5s 137ms/step - loss: 0.0044\n",
            "Epoch 81/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0043\n",
            "Epoch 82/120\n",
            "36/36 [==============================] - 6s 175ms/step - loss: 0.0043\n",
            "Epoch 83/120\n",
            "36/36 [==============================] - 5s 127ms/step - loss: 0.0043\n",
            "Epoch 84/120\n",
            "36/36 [==============================] - 5s 135ms/step - loss: 0.0043\n",
            "Epoch 85/120\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.0043\n",
            "Epoch 86/120\n",
            "36/36 [==============================] - 5s 127ms/step - loss: 0.0042\n",
            "Epoch 87/120\n",
            "36/36 [==============================] - 6s 176ms/step - loss: 0.0044\n",
            "Epoch 88/120\n",
            "36/36 [==============================] - 8s 229ms/step - loss: 0.0046\n",
            "Epoch 89/120\n",
            "36/36 [==============================] - 5s 147ms/step - loss: 0.0043\n",
            "Epoch 90/120\n",
            "36/36 [==============================] - 6s 166ms/step - loss: 0.0043\n",
            "Epoch 91/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0043\n",
            "Epoch 92/120\n",
            "36/36 [==============================] - 6s 181ms/step - loss: 0.0042\n",
            "Epoch 93/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0043\n",
            "Epoch 94/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0044\n",
            "Epoch 95/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0041\n",
            "Epoch 96/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0042\n",
            "Epoch 97/120\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0041\n",
            "Epoch 98/120\n",
            "36/36 [==============================] - 7s 189ms/step - loss: 0.0042\n",
            "Epoch 99/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0043\n",
            "Epoch 100/120\n",
            "36/36 [==============================] - 6s 175ms/step - loss: 0.0041\n",
            "Epoch 101/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0041\n",
            "Epoch 102/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0041\n",
            "Epoch 103/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0043\n",
            "Epoch 104/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0042\n",
            "Epoch 105/120\n",
            "36/36 [==============================] - 5s 149ms/step - loss: 0.0041\n",
            "Epoch 106/120\n",
            "36/36 [==============================] - 6s 158ms/step - loss: 0.0041\n",
            "Epoch 107/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0042\n",
            "Epoch 108/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0040\n",
            "Epoch 109/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0039\n",
            "Epoch 110/120\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.0040\n",
            "Epoch 111/120\n",
            "36/36 [==============================] - 5s 139ms/step - loss: 0.0040\n",
            "Epoch 112/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0043\n",
            "Epoch 113/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0041\n",
            "Epoch 114/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0044\n",
            "Epoch 115/120\n",
            "36/36 [==============================] - 5s 148ms/step - loss: 0.0044\n",
            "Epoch 116/120\n",
            "36/36 [==============================] - 6s 160ms/step - loss: 0.0042\n",
            "Epoch 117/120\n",
            "36/36 [==============================] - 6s 175ms/step - loss: 0.0044\n",
            "Epoch 118/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0041\n",
            "Epoch 119/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0041\n",
            "Epoch 120/120\n",
            "36/36 [==============================] - 6s 159ms/step - loss: 0.0040\n",
            "48/48 [==============================] - 3s 22ms/step\n",
            "Epoch 1/120\n",
            "36/36 [==============================] - 25s 130ms/step - loss: 0.0206\n",
            "Epoch 2/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0078\n",
            "Epoch 3/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0071\n",
            "Epoch 4/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0067\n",
            "Epoch 5/120\n",
            "36/36 [==============================] - 6s 162ms/step - loss: 0.0060\n",
            "Epoch 6/120\n",
            "36/36 [==============================] - 5s 147ms/step - loss: 0.0062\n",
            "Epoch 7/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0061\n",
            "Epoch 8/120\n",
            "36/36 [==============================] - 7s 210ms/step - loss: 0.0060\n",
            "Epoch 9/120\n",
            "36/36 [==============================] - 5s 147ms/step - loss: 0.0063\n",
            "Epoch 10/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0061\n",
            "Epoch 11/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0057\n",
            "Epoch 12/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0054\n",
            "Epoch 13/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0055\n",
            "Epoch 14/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0054\n",
            "Epoch 15/120\n",
            "36/36 [==============================] - 6s 158ms/step - loss: 0.0055\n",
            "Epoch 16/120\n",
            "36/36 [==============================] - 5s 147ms/step - loss: 0.0054\n",
            "Epoch 17/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0054\n",
            "Epoch 18/120\n",
            "36/36 [==============================] - 7s 204ms/step - loss: 0.0050\n",
            "Epoch 19/120\n",
            "36/36 [==============================] - 6s 153ms/step - loss: 0.0054\n",
            "Epoch 20/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0049\n",
            "Epoch 21/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0050\n",
            "Epoch 22/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0049\n",
            "Epoch 23/120\n",
            "36/36 [==============================] - 6s 160ms/step - loss: 0.0049\n",
            "Epoch 24/120\n",
            "36/36 [==============================] - 5s 141ms/step - loss: 0.0050\n",
            "Epoch 25/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0050\n",
            "Epoch 26/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0050\n",
            "Epoch 27/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0050\n",
            "Epoch 28/120\n",
            "36/36 [==============================] - 7s 198ms/step - loss: 0.0048\n",
            "Epoch 29/120\n",
            "36/36 [==============================] - 6s 156ms/step - loss: 0.0046\n",
            "Epoch 30/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0048\n",
            "Epoch 31/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0049\n",
            "Epoch 32/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0049\n",
            "Epoch 33/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0048\n",
            "Epoch 34/120\n",
            "36/36 [==============================] - 6s 176ms/step - loss: 0.0053\n",
            "Epoch 35/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0050\n",
            "Epoch 36/120\n",
            "36/36 [==============================] - 6s 175ms/step - loss: 0.0053\n",
            "Epoch 37/120\n",
            "36/36 [==============================] - 6s 164ms/step - loss: 0.0048\n",
            "Epoch 38/120\n",
            "36/36 [==============================] - 6s 165ms/step - loss: 0.0048\n",
            "Epoch 39/120\n",
            "36/36 [==============================] - 8s 209ms/step - loss: 0.0049\n",
            "Epoch 40/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0049\n",
            "Epoch 41/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0047\n",
            "Epoch 42/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0049\n",
            "Epoch 43/120\n",
            "36/36 [==============================] - 6s 163ms/step - loss: 0.0046\n",
            "Epoch 44/120\n",
            "36/36 [==============================] - 5s 144ms/step - loss: 0.0050\n",
            "Epoch 45/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0048\n",
            "Epoch 46/120\n",
            "36/36 [==============================] - 7s 206ms/step - loss: 0.0047\n",
            "Epoch 47/120\n",
            "36/36 [==============================] - 5s 149ms/step - loss: 0.0050\n",
            "Epoch 48/120\n",
            "36/36 [==============================] - 6s 171ms/step - loss: 0.0045\n",
            "Epoch 49/120\n",
            "36/36 [==============================] - 5s 146ms/step - loss: 0.0046\n",
            "Epoch 50/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0047\n",
            "Epoch 51/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0047\n",
            "Epoch 52/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0047\n",
            "Epoch 53/120\n",
            "36/36 [==============================] - 6s 161ms/step - loss: 0.0045\n",
            "Epoch 54/120\n",
            "36/36 [==============================] - 5s 145ms/step - loss: 0.0043\n",
            "Epoch 55/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0045\n",
            "Epoch 56/120\n",
            "36/36 [==============================] - 7s 205ms/step - loss: 0.0045\n",
            "Epoch 57/120\n",
            "36/36 [==============================] - 6s 154ms/step - loss: 0.0044\n",
            "Epoch 58/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0047\n",
            "Epoch 59/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0045\n",
            "Epoch 60/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0046\n",
            "Epoch 61/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0043\n",
            "Epoch 62/120\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0044\n",
            "Epoch 63/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0046\n",
            "Epoch 64/120\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0044\n",
            "Epoch 65/120\n",
            "36/36 [==============================] - 6s 158ms/step - loss: 0.0044\n",
            "Epoch 66/120\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0043\n",
            "Epoch 67/120\n",
            "36/36 [==============================] - 6s 159ms/step - loss: 0.0042\n",
            "Epoch 68/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0043\n",
            "Epoch 69/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0042\n",
            "Epoch 70/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0045\n",
            "Epoch 71/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0043\n",
            "Epoch 72/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0044\n",
            "Epoch 73/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0042\n",
            "Epoch 74/120\n",
            "36/36 [==============================] - 6s 162ms/step - loss: 0.0043\n",
            "Epoch 75/120\n",
            "36/36 [==============================] - 7s 193ms/step - loss: 0.0042\n",
            "Epoch 76/120\n",
            "36/36 [==============================] - 5s 145ms/step - loss: 0.0043\n",
            "Epoch 77/120\n",
            "36/36 [==============================] - 6s 163ms/step - loss: 0.0044\n",
            "Epoch 78/120\n",
            "36/36 [==============================] - 6s 172ms/step - loss: 0.0043\n",
            "Epoch 79/120\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.0043\n",
            "Epoch 80/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0040\n",
            "Epoch 81/120\n",
            "36/36 [==============================] - 6s 157ms/step - loss: 0.0043\n",
            "Epoch 82/120\n",
            "36/36 [==============================] - 5s 149ms/step - loss: 0.0042\n",
            "Epoch 83/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0041\n",
            "Epoch 84/120\n",
            "36/36 [==============================] - 7s 206ms/step - loss: 0.0041\n",
            "Epoch 85/120\n",
            "36/36 [==============================] - 6s 152ms/step - loss: 0.0042\n",
            "Epoch 86/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0043\n",
            "Epoch 87/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0043\n",
            "Epoch 88/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0043\n",
            "Epoch 89/120\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0041\n",
            "Epoch 90/120\n",
            "36/36 [==============================] - 5s 138ms/step - loss: 0.0044\n",
            "Epoch 91/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0040\n",
            "Epoch 92/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0041\n",
            "Epoch 93/120\n",
            "36/36 [==============================] - 5s 142ms/step - loss: 0.0043\n",
            "Epoch 94/120\n",
            "36/36 [==============================] - 8s 214ms/step - loss: 0.0040\n",
            "Epoch 95/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0042\n",
            "Epoch 96/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0040\n",
            "Epoch 97/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0041\n",
            "Epoch 98/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0041\n",
            "Epoch 99/120\n",
            "36/36 [==============================] - 6s 159ms/step - loss: 0.0039\n",
            "Epoch 100/120\n",
            "36/36 [==============================] - 5s 144ms/step - loss: 0.0041\n",
            "Epoch 101/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0048\n",
            "Epoch 102/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0044\n",
            "Epoch 103/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0041\n",
            "Epoch 104/120\n",
            "36/36 [==============================] - 6s 176ms/step - loss: 0.0044\n",
            "Epoch 105/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0041\n",
            "Epoch 106/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0041\n",
            "Epoch 107/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0042\n",
            "Epoch 108/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0045\n",
            "Epoch 109/120\n",
            "36/36 [==============================] - 5s 139ms/step - loss: 0.0040\n",
            "Epoch 110/120\n",
            "36/36 [==============================] - 6s 163ms/step - loss: 0.0043\n",
            "Epoch 111/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0041\n",
            "Epoch 112/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0039\n",
            "Epoch 113/120\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0040\n",
            "Epoch 114/120\n",
            "36/36 [==============================] - 5s 150ms/step - loss: 0.0041\n",
            "Epoch 115/120\n",
            "36/36 [==============================] - 6s 156ms/step - loss: 0.0040\n",
            "Epoch 116/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0044\n",
            "Epoch 117/120\n",
            "36/36 [==============================] - 7s 190ms/step - loss: 0.0054\n",
            "Epoch 118/120\n",
            "36/36 [==============================] - 6s 163ms/step - loss: 0.0046\n",
            "Epoch 119/120\n",
            "36/36 [==============================] - 5s 150ms/step - loss: 0.0044\n",
            "Epoch 120/120\n",
            "36/36 [==============================] - 6s 153ms/step - loss: 0.0044\n",
            "48/48 [==============================] - 3s 21ms/step\n",
            "Epoch 1/120\n",
            "36/36 [==============================] - 23s 178ms/step - loss: 0.0208\n",
            "Epoch 2/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0088\n",
            "Epoch 3/120\n",
            "36/36 [==============================] - 6s 162ms/step - loss: 0.0073\n",
            "Epoch 4/120\n",
            "36/36 [==============================] - 5s 144ms/step - loss: 0.0065\n",
            "Epoch 5/120\n",
            "36/36 [==============================] - 5s 142ms/step - loss: 0.0060\n",
            "Epoch 6/120\n",
            "36/36 [==============================] - 8s 213ms/step - loss: 0.0066\n",
            "Epoch 7/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0059\n",
            "Epoch 8/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0058\n",
            "Epoch 9/120\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.0058\n",
            "Epoch 10/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0058\n",
            "Epoch 11/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0055\n",
            "Epoch 12/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0054\n",
            "Epoch 13/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0054\n",
            "Epoch 14/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0052\n",
            "Epoch 15/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0056\n",
            "Epoch 16/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0052\n",
            "Epoch 17/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0053\n",
            "Epoch 18/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0050\n",
            "Epoch 19/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0050\n",
            "Epoch 20/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0051\n",
            "Epoch 21/120\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0049\n",
            "Epoch 22/120\n",
            "36/36 [==============================] - 5s 138ms/step - loss: 0.0050\n",
            "Epoch 23/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0049\n",
            "Epoch 24/120\n",
            "36/36 [==============================] - 8s 213ms/step - loss: 0.0051\n",
            "Epoch 25/120\n",
            "36/36 [==============================] - 5s 140ms/step - loss: 0.0049\n",
            "Epoch 26/120\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0048\n",
            "Epoch 27/120\n",
            "36/36 [==============================] - 5s 136ms/step - loss: 0.0048\n",
            "Epoch 28/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0052\n",
            "Epoch 29/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0051\n",
            "Epoch 30/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0051\n",
            "Epoch 31/120\n",
            "36/36 [==============================] - 7s 208ms/step - loss: 0.0046\n",
            "Epoch 32/120\n",
            "36/36 [==============================] - 6s 151ms/step - loss: 0.0048\n",
            "Epoch 33/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0047\n",
            "Epoch 34/120\n",
            "36/36 [==============================] - 8s 230ms/step - loss: 0.0050\n",
            "Epoch 35/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0050\n",
            "Epoch 36/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0049\n",
            "Epoch 37/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0048\n",
            "Epoch 38/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0047\n",
            "Epoch 39/120\n",
            "36/36 [==============================] - 6s 160ms/step - loss: 0.0047\n",
            "Epoch 40/120\n",
            "36/36 [==============================] - 5s 147ms/step - loss: 0.0046\n",
            "Epoch 41/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0047\n",
            "Epoch 42/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0048\n",
            "Epoch 43/120\n",
            "36/36 [==============================] - 6s 166ms/step - loss: 0.0046\n",
            "Epoch 44/120\n",
            "36/36 [==============================] - 7s 179ms/step - loss: 0.0046\n",
            "Epoch 45/120\n",
            "36/36 [==============================] - 5s 137ms/step - loss: 0.0046\n",
            "Epoch 46/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0046\n",
            "Epoch 47/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0045\n",
            "Epoch 48/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0045\n",
            "Epoch 49/120\n",
            "36/36 [==============================] - 5s 141ms/step - loss: 0.0045\n",
            "Epoch 50/120\n",
            "36/36 [==============================] - 6s 163ms/step - loss: 0.0049\n",
            "Epoch 51/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0045\n",
            "Epoch 52/120\n",
            "36/36 [==============================] - 7s 188ms/step - loss: 0.0044\n",
            "Epoch 53/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0047\n",
            "Epoch 54/120\n",
            "36/36 [==============================] - 6s 167ms/step - loss: 0.0046\n",
            "Epoch 55/120\n",
            "36/36 [==============================] - 5s 143ms/step - loss: 0.0045\n",
            "Epoch 56/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0048\n",
            "Epoch 57/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0045\n",
            "Epoch 58/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0044\n",
            "Epoch 59/120\n",
            "36/36 [==============================] - 5s 135ms/step - loss: 0.0046\n",
            "Epoch 60/120\n",
            "36/36 [==============================] - 6s 171ms/step - loss: 0.0045\n",
            "Epoch 61/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0044\n",
            "Epoch 62/120\n",
            "36/36 [==============================] - 6s 175ms/step - loss: 0.0043\n",
            "Epoch 63/120\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0044\n",
            "Epoch 64/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0044\n",
            "Epoch 65/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0044\n",
            "Epoch 66/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0046\n",
            "Epoch 67/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0044\n",
            "Epoch 68/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0044\n",
            "Epoch 69/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0044\n",
            "Epoch 70/120\n",
            "36/36 [==============================] - 7s 199ms/step - loss: 0.0044\n",
            "Epoch 71/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0045\n",
            "Epoch 72/120\n",
            "36/36 [==============================] - 6s 166ms/step - loss: 0.0043\n",
            "Epoch 73/120\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.0044\n",
            "Epoch 74/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0046\n",
            "Epoch 75/120\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.0043\n",
            "Epoch 76/120\n",
            "36/36 [==============================] - 5s 140ms/step - loss: 0.0044\n",
            "Epoch 77/120\n",
            "36/36 [==============================] - 5s 135ms/step - loss: 0.0044\n",
            "Epoch 78/120\n",
            "36/36 [==============================] - 6s 181ms/step - loss: 0.0043\n",
            "Epoch 79/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0043\n",
            "Epoch 80/120\n",
            "36/36 [==============================] - 5s 151ms/step - loss: 0.0042\n",
            "Epoch 81/120\n",
            "36/36 [==============================] - 7s 207ms/step - loss: 0.0042\n",
            "Epoch 82/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0040\n",
            "Epoch 83/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0042\n",
            "Epoch 84/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0041\n",
            "Epoch 85/120\n",
            "36/36 [==============================] - 6s 167ms/step - loss: 0.0043\n",
            "Epoch 86/120\n",
            "36/36 [==============================] - 5s 144ms/step - loss: 0.0043\n",
            "Epoch 87/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0042\n",
            "Epoch 88/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0043\n",
            "Epoch 89/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0042\n",
            "Epoch 90/120\n",
            "36/36 [==============================] - 5s 148ms/step - loss: 0.0042\n",
            "Epoch 91/120\n",
            "36/36 [==============================] - 8s 209ms/step - loss: 0.0042\n",
            "Epoch 92/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0041\n",
            "Epoch 93/120\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0041\n",
            "Epoch 94/120\n",
            "36/36 [==============================] - 5s 139ms/step - loss: 0.0040\n",
            "Epoch 95/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0042\n",
            "Epoch 96/120\n",
            "36/36 [==============================] - 6s 182ms/step - loss: 0.0041\n",
            "Epoch 97/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0040\n",
            "Epoch 98/120\n",
            "36/36 [==============================] - 5s 145ms/step - loss: 0.0041\n",
            "Epoch 99/120\n",
            "36/36 [==============================] - 6s 163ms/step - loss: 0.0041\n",
            "Epoch 100/120\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.0062\n",
            "Epoch 101/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0045\n",
            "Epoch 102/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0046\n",
            "Epoch 103/120\n",
            "36/36 [==============================] - 6s 161ms/step - loss: 0.0041\n",
            "Epoch 104/120\n",
            "36/36 [==============================] - 5s 144ms/step - loss: 0.0043\n",
            "Epoch 105/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0042\n",
            "Epoch 106/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0041\n",
            "Epoch 107/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0042\n",
            "Epoch 108/120\n",
            "36/36 [==============================] - 5s 142ms/step - loss: 0.0041\n",
            "Epoch 109/120\n",
            "36/36 [==============================] - 9s 249ms/step - loss: 0.0041\n",
            "Epoch 110/120\n",
            "36/36 [==============================] - 5s 150ms/step - loss: 0.0043\n",
            "Epoch 111/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0043\n",
            "Epoch 112/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0041\n",
            "Epoch 113/120\n",
            "36/36 [==============================] - 5s 136ms/step - loss: 0.0040\n",
            "Epoch 114/120\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0040\n",
            "Epoch 115/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0042\n",
            "Epoch 116/120\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.0039\n",
            "Epoch 117/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0042\n",
            "Epoch 118/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0040\n",
            "Epoch 119/120\n",
            "36/36 [==============================] - 8s 234ms/step - loss: 0.0040\n",
            "Epoch 120/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0039\n",
            "48/48 [==============================] - 3s 23ms/step\n",
            "Epoch 1/120\n",
            "36/36 [==============================] - 23s 183ms/step - loss: 0.0196\n",
            "Epoch 2/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0085\n",
            "Epoch 3/120\n",
            "36/36 [==============================] - 7s 194ms/step - loss: 0.0071\n",
            "Epoch 4/120\n",
            "36/36 [==============================] - 6s 164ms/step - loss: 0.0064\n",
            "Epoch 5/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0061\n",
            "Epoch 6/120\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.0063\n",
            "Epoch 7/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0062\n",
            "Epoch 8/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0058\n",
            "Epoch 9/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0058\n",
            "Epoch 10/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0056\n",
            "Epoch 11/120\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.0054\n",
            "Epoch 12/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0056\n",
            "Epoch 13/120\n",
            "36/36 [==============================] - 6s 156ms/step - loss: 0.0053\n",
            "Epoch 14/120\n",
            "36/36 [==============================] - 6s 166ms/step - loss: 0.0051\n",
            "Epoch 15/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0053\n",
            "Epoch 16/120\n",
            "36/36 [==============================] - 6s 182ms/step - loss: 0.0053\n",
            "Epoch 17/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0050\n",
            "Epoch 18/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0050\n",
            "Epoch 19/120\n",
            "36/36 [==============================] - 7s 183ms/step - loss: 0.0052\n",
            "Epoch 20/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0052\n",
            "Epoch 21/120\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0053\n",
            "Epoch 22/120\n",
            "36/36 [==============================] - 9s 237ms/step - loss: 0.0050\n",
            "Epoch 23/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0049\n",
            "Epoch 24/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0049\n",
            "Epoch 25/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0052\n",
            "Epoch 26/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0051\n",
            "Epoch 27/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0050\n",
            "Epoch 28/120\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0051\n",
            "Epoch 29/120\n",
            "36/36 [==============================] - 5s 138ms/step - loss: 0.0048\n",
            "Epoch 30/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0049\n",
            "Epoch 31/120\n",
            "36/36 [==============================] - 8s 220ms/step - loss: 0.0048\n",
            "Epoch 32/120\n",
            "36/36 [==============================] - 5s 143ms/step - loss: 0.0046\n",
            "Epoch 33/120\n",
            "36/36 [==============================] - 5s 140ms/step - loss: 0.0046\n",
            "Epoch 34/120\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0048\n",
            "Epoch 35/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0048\n",
            "Epoch 36/120\n",
            "36/36 [==============================] - 6s 181ms/step - loss: 0.0046\n",
            "Epoch 37/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0046\n",
            "Epoch 38/120\n",
            "36/36 [==============================] - 5s 135ms/step - loss: 0.0045\n",
            "Epoch 39/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0049\n",
            "Epoch 40/120\n",
            "36/36 [==============================] - 6s 159ms/step - loss: 0.0049\n",
            "Epoch 41/120\n",
            "36/36 [==============================] - 7s 207ms/step - loss: 0.0046\n",
            "Epoch 42/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0046\n",
            "Epoch 43/120\n",
            "36/36 [==============================] - 5s 147ms/step - loss: 0.0047\n",
            "Epoch 44/120\n",
            "36/36 [==============================] - 6s 160ms/step - loss: 0.0044\n",
            "Epoch 45/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0044\n",
            "Epoch 46/120\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.0046\n",
            "Epoch 47/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0045\n",
            "Epoch 48/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0047\n",
            "Epoch 49/120\n",
            "36/36 [==============================] - 7s 183ms/step - loss: 0.0046\n",
            "Epoch 50/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0046\n",
            "Epoch 51/120\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.0045\n",
            "Epoch 52/120\n",
            "36/36 [==============================] - 5s 135ms/step - loss: 0.0045\n",
            "Epoch 53/120\n",
            "36/36 [==============================] - 6s 155ms/step - loss: 0.0048\n",
            "Epoch 54/120\n",
            "36/36 [==============================] - 6s 157ms/step - loss: 0.0047\n",
            "Epoch 55/120\n",
            "36/36 [==============================] - 5s 144ms/step - loss: 0.0044\n",
            "Epoch 56/120\n",
            "36/36 [==============================] - 7s 183ms/step - loss: 0.0044\n",
            "Epoch 57/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0047\n",
            "Epoch 58/120\n",
            "36/36 [==============================] - 5s 147ms/step - loss: 0.0045\n",
            "Epoch 59/120\n",
            "36/36 [==============================] - 8s 211ms/step - loss: 0.0044\n",
            "Epoch 60/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0046\n",
            "Epoch 61/120\n",
            "36/36 [==============================] - 8s 211ms/step - loss: 0.0044\n",
            "Epoch 62/120\n",
            "36/36 [==============================] - 5s 149ms/step - loss: 0.0045\n",
            "Epoch 63/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0044\n",
            "Epoch 64/120\n",
            "36/36 [==============================] - 6s 181ms/step - loss: 0.0044\n",
            "Epoch 65/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0043\n",
            "Epoch 66/120\n",
            "36/36 [==============================] - 5s 149ms/step - loss: 0.0042\n",
            "Epoch 67/120\n",
            "36/36 [==============================] - 6s 162ms/step - loss: 0.0045\n",
            "Epoch 68/120\n",
            "36/36 [==============================] - 6s 157ms/step - loss: 0.0043\n",
            "Epoch 69/120\n",
            "36/36 [==============================] - 7s 204ms/step - loss: 0.0045\n",
            "Epoch 70/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0044\n",
            "Epoch 71/120\n",
            "36/36 [==============================] - 5s 152ms/step - loss: 0.0042\n",
            "Epoch 72/120\n",
            "36/36 [==============================] - 6s 161ms/step - loss: 0.0044\n",
            "Epoch 73/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0045\n",
            "Epoch 74/120\n",
            "36/36 [==============================] - 6s 181ms/step - loss: 0.0045\n",
            "Epoch 75/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0042\n",
            "Epoch 76/120\n",
            "36/36 [==============================] - 5s 139ms/step - loss: 0.0043\n",
            "Epoch 77/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0042\n",
            "Epoch 78/120\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0043\n",
            "Epoch 79/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0045\n",
            "Epoch 80/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0043\n",
            "Epoch 81/120\n",
            "36/36 [==============================] - 5s 152ms/step - loss: 0.0042\n",
            "Epoch 82/120\n",
            "36/36 [==============================] - 6s 157ms/step - loss: 0.0043\n",
            "Epoch 83/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0043\n",
            "Epoch 84/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0043\n",
            "Epoch 85/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0041\n",
            "Epoch 86/120\n",
            "36/36 [==============================] - 5s 140ms/step - loss: 0.0040\n",
            "Epoch 87/120\n",
            "36/36 [==============================] - 8s 220ms/step - loss: 0.0042\n",
            "Epoch 88/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0045\n",
            "Epoch 89/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0041\n",
            "Epoch 90/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0040\n",
            "Epoch 91/120\n",
            "36/36 [==============================] - 5s 146ms/step - loss: 0.0042\n",
            "Epoch 92/120\n",
            "36/36 [==============================] - 6s 162ms/step - loss: 0.0042\n",
            "Epoch 93/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0042\n",
            "Epoch 94/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0044\n",
            "Epoch 95/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0043\n",
            "Epoch 96/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0043\n",
            "Epoch 97/120\n",
            "36/36 [==============================] - 8s 234ms/step - loss: 0.0043\n",
            "Epoch 98/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0041\n",
            "Epoch 99/120\n",
            "36/36 [==============================] - 5s 135ms/step - loss: 0.0040\n",
            "Epoch 100/120\n",
            "36/36 [==============================] - 8s 219ms/step - loss: 0.0041\n",
            "Epoch 101/120\n",
            "36/36 [==============================] - 5s 137ms/step - loss: 0.0043\n",
            "Epoch 102/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0041\n",
            "Epoch 103/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0039\n",
            "Epoch 104/120\n",
            "36/36 [==============================] - 5s 151ms/step - loss: 0.0039\n",
            "Epoch 105/120\n",
            "36/36 [==============================] - 6s 160ms/step - loss: 0.0039\n",
            "Epoch 106/120\n",
            "36/36 [==============================] - 7s 183ms/step - loss: 0.0046\n",
            "Epoch 107/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0041\n",
            "Epoch 108/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0040\n",
            "Epoch 109/120\n",
            "36/36 [==============================] - 6s 175ms/step - loss: 0.0040\n",
            "Epoch 110/120\n",
            "36/36 [==============================] - 5s 138ms/step - loss: 0.0042\n",
            "Epoch 111/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0041\n",
            "Epoch 112/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0040\n",
            "Epoch 113/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0040\n",
            "Epoch 114/120\n",
            "36/36 [==============================] - 6s 158ms/step - loss: 0.0040\n",
            "Epoch 115/120\n",
            "36/36 [==============================] - 7s 188ms/step - loss: 0.0039\n",
            "Epoch 116/120\n",
            "36/36 [==============================] - 5s 144ms/step - loss: 0.0038\n",
            "Epoch 117/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0041\n",
            "Epoch 118/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0042\n",
            "Epoch 119/120\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0041\n",
            "Epoch 120/120\n",
            "36/36 [==============================] - 5s 138ms/step - loss: 0.0040\n",
            "48/48 [==============================] - 3s 27ms/step\n",
            "Epoch 1/120\n",
            "36/36 [==============================] - 23s 156ms/step - loss: 0.0206\n",
            "Epoch 2/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0078\n",
            "Epoch 3/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0070\n",
            "Epoch 4/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0072\n",
            "Epoch 5/120\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0063\n",
            "Epoch 6/120\n",
            "36/36 [==============================] - 7s 187ms/step - loss: 0.0059\n",
            "Epoch 7/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0060\n",
            "Epoch 8/120\n",
            "36/36 [==============================] - 6s 171ms/step - loss: 0.0057\n",
            "Epoch 9/120\n",
            "36/36 [==============================] - 7s 183ms/step - loss: 0.0058\n",
            "Epoch 10/120\n",
            "36/36 [==============================] - 5s 149ms/step - loss: 0.0054\n",
            "Epoch 11/120\n",
            "36/36 [==============================] - 6s 163ms/step - loss: 0.0054\n",
            "Epoch 12/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0056\n",
            "Epoch 13/120\n",
            "36/36 [==============================] - 6s 181ms/step - loss: 0.0053\n",
            "Epoch 14/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0055\n",
            "Epoch 15/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0054\n",
            "Epoch 16/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0054\n",
            "Epoch 17/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0052\n",
            "Epoch 18/120\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0053\n",
            "Epoch 19/120\n",
            "36/36 [==============================] - 7s 187ms/step - loss: 0.0051\n",
            "Epoch 20/120\n",
            "36/36 [==============================] - 5s 147ms/step - loss: 0.0053\n",
            "Epoch 21/120\n",
            "36/36 [==============================] - 6s 162ms/step - loss: 0.0053\n",
            "Epoch 22/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0050\n",
            "Epoch 23/120\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.0051\n",
            "Epoch 24/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0049\n",
            "Epoch 25/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0049\n",
            "Epoch 26/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0049\n",
            "Epoch 27/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0048\n",
            "Epoch 28/120\n",
            "36/36 [==============================] - 6s 176ms/step - loss: 0.0052\n",
            "Epoch 29/120\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0049\n",
            "Epoch 30/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0049\n",
            "Epoch 31/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0050\n",
            "Epoch 32/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0047\n",
            "Epoch 33/120\n",
            "36/36 [==============================] - 5s 141ms/step - loss: 0.0047\n",
            "Epoch 34/120\n",
            "36/36 [==============================] - 6s 172ms/step - loss: 0.0046\n",
            "Epoch 35/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0048\n",
            "Epoch 36/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0048\n",
            "Epoch 37/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0047\n",
            "Epoch 38/120\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0047\n",
            "Epoch 39/120\n",
            "36/36 [==============================] - 7s 188ms/step - loss: 0.0047\n",
            "Epoch 40/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0048\n",
            "Epoch 41/120\n",
            "36/36 [==============================] - 6s 163ms/step - loss: 0.0047\n",
            "Epoch 42/120\n",
            "36/36 [==============================] - 5s 147ms/step - loss: 0.0047\n",
            "Epoch 43/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0044\n",
            "Epoch 44/120\n",
            "36/36 [==============================] - 7s 190ms/step - loss: 0.0045\n",
            "Epoch 45/120\n",
            "36/36 [==============================] - 6s 172ms/step - loss: 0.0049\n",
            "Epoch 46/120\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0049\n",
            "Epoch 47/120\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0049\n",
            "Epoch 48/120\n",
            "36/36 [==============================] - 7s 200ms/step - loss: 0.0047\n",
            "Epoch 49/120\n",
            "36/36 [==============================] - 5s 138ms/step - loss: 0.0045\n",
            "Epoch 50/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0046\n",
            "Epoch 51/120\n",
            "36/36 [==============================] - 7s 183ms/step - loss: 0.0045\n",
            "Epoch 52/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0046\n",
            "Epoch 53/120\n",
            "36/36 [==============================] - 6s 162ms/step - loss: 0.0044\n",
            "Epoch 54/120\n",
            "36/36 [==============================] - 6s 152ms/step - loss: 0.0044\n",
            "Epoch 55/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0045\n",
            "Epoch 56/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0043\n",
            "Epoch 57/120\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.0044\n",
            "Epoch 58/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0045\n",
            "Epoch 59/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0044\n",
            "Epoch 60/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0044\n",
            "Epoch 61/120\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.0045\n",
            "Epoch 62/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0043\n",
            "Epoch 63/120\n",
            "36/36 [==============================] - 6s 163ms/step - loss: 0.0043\n",
            "Epoch 64/120\n",
            "36/36 [==============================] - 5s 144ms/step - loss: 0.0043\n",
            "Epoch 65/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0044\n",
            "Epoch 66/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0043\n",
            "Epoch 67/120\n",
            "36/36 [==============================] - 7s 183ms/step - loss: 0.0044\n",
            "Epoch 68/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0044\n",
            "Epoch 69/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0043\n",
            "Epoch 70/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0043\n",
            "Epoch 71/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0042\n",
            "Epoch 72/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0043\n",
            "Epoch 73/120\n",
            "36/36 [==============================] - 6s 162ms/step - loss: 0.0042\n",
            "Epoch 74/120\n",
            "36/36 [==============================] - 5s 148ms/step - loss: 0.0044\n",
            "Epoch 75/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0044\n",
            "Epoch 76/120\n",
            "36/36 [==============================] - 7s 209ms/step - loss: 0.0043\n",
            "Epoch 77/120\n",
            "36/36 [==============================] - 6s 153ms/step - loss: 0.0044\n",
            "Epoch 78/120\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0042\n",
            "Epoch 79/120\n",
            "36/36 [==============================] - 5s 136ms/step - loss: 0.0042\n",
            "Epoch 80/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0043\n",
            "Epoch 81/120\n",
            "36/36 [==============================] - 6s 181ms/step - loss: 0.0042\n",
            "Epoch 82/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0042\n",
            "Epoch 83/120\n",
            "36/36 [==============================] - 5s 153ms/step - loss: 0.0041\n",
            "Epoch 84/120\n",
            "36/36 [==============================] - 7s 205ms/step - loss: 0.0041\n",
            "Epoch 85/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0042\n",
            "Epoch 86/120\n",
            "36/36 [==============================] - 8s 237ms/step - loss: 0.0043\n",
            "Epoch 87/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0043\n",
            "Epoch 88/120\n",
            "36/36 [==============================] - 5s 142ms/step - loss: 0.0045\n",
            "Epoch 89/120\n",
            "36/36 [==============================] - 6s 171ms/step - loss: 0.0045\n",
            "Epoch 90/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0042\n",
            "Epoch 91/120\n",
            "36/36 [==============================] - 7s 183ms/step - loss: 0.0041\n",
            "Epoch 92/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0041\n",
            "Epoch 93/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0041\n",
            "Epoch 94/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0040\n",
            "Epoch 95/120\n",
            "36/36 [==============================] - 5s 139ms/step - loss: 0.0041\n",
            "Epoch 96/120\n",
            "36/36 [==============================] - 8s 219ms/step - loss: 0.0040\n",
            "Epoch 97/120\n",
            "36/36 [==============================] - 5s 135ms/step - loss: 0.0042\n",
            "Epoch 98/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0041\n",
            "Epoch 99/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0042\n",
            "Epoch 100/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0039\n",
            "Epoch 101/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0042\n",
            "Epoch 102/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0041\n",
            "Epoch 103/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0041\n",
            "Epoch 104/120\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.0043\n",
            "Epoch 105/120\n",
            "36/36 [==============================] - 6s 163ms/step - loss: 0.0040\n",
            "Epoch 106/120\n",
            "36/36 [==============================] - 7s 195ms/step - loss: 0.0043\n",
            "Epoch 107/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0042\n",
            "Epoch 108/120\n",
            "36/36 [==============================] - 5s 139ms/step - loss: 0.0040\n",
            "Epoch 109/120\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0041\n",
            "Epoch 110/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0042\n",
            "Epoch 111/120\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.0041\n",
            "Epoch 112/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0040\n",
            "Epoch 113/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0040\n",
            "Epoch 114/120\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.0041\n",
            "Epoch 115/120\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0040\n",
            "Epoch 116/120\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0040\n",
            "Epoch 117/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0067\n",
            "Epoch 118/120\n",
            "36/36 [==============================] - 5s 145ms/step - loss: 0.0048\n",
            "Epoch 119/120\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.0046\n",
            "Epoch 120/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0046\n",
            "48/48 [==============================] - 3s 38ms/step\n",
            "Epoch 1/120\n",
            "36/36 [==============================] - 25s 168ms/step - loss: 0.0184\n",
            "Epoch 2/120\n",
            "36/36 [==============================] - 6s 176ms/step - loss: 0.0078\n",
            "Epoch 3/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0068\n",
            "Epoch 4/120\n",
            "36/36 [==============================] - 5s 145ms/step - loss: 0.0065\n",
            "Epoch 5/120\n",
            "36/36 [==============================] - 6s 164ms/step - loss: 0.0062\n",
            "Epoch 6/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0058\n",
            "Epoch 7/120\n",
            "36/36 [==============================] - 6s 176ms/step - loss: 0.0061\n",
            "Epoch 8/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0060\n",
            "Epoch 9/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0059\n",
            "Epoch 10/120\n",
            "36/36 [==============================] - 7s 201ms/step - loss: 0.0054\n",
            "Epoch 11/120\n",
            "36/36 [==============================] - 6s 153ms/step - loss: 0.0054\n",
            "Epoch 12/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0055\n",
            "Epoch 13/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0053\n",
            "Epoch 14/120\n",
            "36/36 [==============================] - 5s 128ms/step - loss: 0.0055\n",
            "Epoch 15/120\n",
            "36/36 [==============================] - 6s 181ms/step - loss: 0.0053\n",
            "Epoch 16/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0052\n",
            "Epoch 17/120\n",
            "36/36 [==============================] - 6s 164ms/step - loss: 0.0050\n",
            "Epoch 18/120\n",
            "36/36 [==============================] - 5s 145ms/step - loss: 0.0050\n",
            "Epoch 19/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0055\n",
            "Epoch 20/120\n",
            "36/36 [==============================] - 7s 203ms/step - loss: 0.0050\n",
            "Epoch 21/120\n",
            "36/36 [==============================] - 6s 156ms/step - loss: 0.0048\n",
            "Epoch 22/120\n",
            "36/36 [==============================] - 5s 151ms/step - loss: 0.0052\n",
            "Epoch 23/120\n",
            "36/36 [==============================] - 6s 159ms/step - loss: 0.0050\n",
            "Epoch 24/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0048\n",
            "Epoch 25/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0050\n",
            "Epoch 26/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0049\n",
            "Epoch 27/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0049\n",
            "Epoch 28/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0047\n",
            "Epoch 29/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0048\n",
            "Epoch 30/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0047\n",
            "Epoch 31/120\n",
            "36/36 [==============================] - 7s 180ms/step - loss: 0.0047\n",
            "Epoch 32/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0048\n",
            "Epoch 33/120\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0049\n",
            "Epoch 34/120\n",
            "36/36 [==============================] - 5s 138ms/step - loss: 0.0050\n",
            "Epoch 35/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0048\n",
            "Epoch 36/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0048\n",
            "Epoch 37/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0047\n",
            "Epoch 38/120\n",
            "36/36 [==============================] - 5s 141ms/step - loss: 0.0048\n",
            "Epoch 39/120\n",
            "36/36 [==============================] - 6s 166ms/step - loss: 0.0047\n",
            "Epoch 40/120\n",
            "36/36 [==============================] - 8s 222ms/step - loss: 0.0046\n",
            "Epoch 41/120\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0045\n",
            "Epoch 42/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0046\n",
            "Epoch 43/120\n",
            "36/36 [==============================] - 6s 161ms/step - loss: 0.0045\n",
            "Epoch 44/120\n",
            "36/36 [==============================] - 5s 147ms/step - loss: 0.0045\n",
            "Epoch 45/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0047\n",
            "Epoch 46/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0047\n",
            "Epoch 47/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0046\n",
            "Epoch 48/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0047\n",
            "Epoch 49/120\n",
            "36/36 [==============================] - 7s 191ms/step - loss: 0.0046\n",
            "Epoch 50/120\n",
            "36/36 [==============================] - 6s 159ms/step - loss: 0.0046\n",
            "Epoch 51/120\n",
            "36/36 [==============================] - 7s 190ms/step - loss: 0.0045\n",
            "Epoch 52/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0045\n",
            "Epoch 53/120\n",
            "36/36 [==============================] - 5s 145ms/step - loss: 0.0045\n",
            "Epoch 54/120\n",
            "36/36 [==============================] - 6s 163ms/step - loss: 0.0047\n",
            "Epoch 55/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0044\n",
            "Epoch 56/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0044\n",
            "Epoch 57/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0045\n",
            "Epoch 58/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0044\n",
            "Epoch 59/120\n",
            "36/36 [==============================] - 7s 200ms/step - loss: 0.0044\n",
            "Epoch 60/120\n",
            "36/36 [==============================] - 6s 157ms/step - loss: 0.0045\n",
            "Epoch 61/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0047\n",
            "Epoch 62/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0046\n",
            "Epoch 63/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0044\n",
            "Epoch 64/120\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0043\n",
            "Epoch 65/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0044\n",
            "Epoch 66/120\n",
            "36/36 [==============================] - 6s 166ms/step - loss: 0.0045\n",
            "Epoch 67/120\n",
            "36/36 [==============================] - 5s 141ms/step - loss: 0.0043\n",
            "Epoch 68/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0045\n",
            "Epoch 69/120\n",
            "36/36 [==============================] - 7s 205ms/step - loss: 0.0043\n",
            "Epoch 70/120\n",
            "36/36 [==============================] - 6s 152ms/step - loss: 0.0044\n",
            "Epoch 71/120\n",
            "36/36 [==============================] - 5s 144ms/step - loss: 0.0045\n",
            "Epoch 72/120\n",
            "36/36 [==============================] - 6s 164ms/step - loss: 0.0043\n",
            "Epoch 73/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0042\n",
            "Epoch 74/120\n",
            "36/36 [==============================] - 6s 176ms/step - loss: 0.0043\n",
            "Epoch 75/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0045\n",
            "Epoch 76/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0042\n",
            "Epoch 77/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0043\n",
            "Epoch 78/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0043\n",
            "Epoch 79/120\n",
            "36/36 [==============================] - 7s 192ms/step - loss: 0.0042\n",
            "Epoch 80/120\n",
            "36/36 [==============================] - 8s 216ms/step - loss: 0.0042\n",
            "Epoch 81/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0043\n",
            "Epoch 82/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0043\n",
            "Epoch 83/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0043\n",
            "Epoch 84/120\n",
            "36/36 [==============================] - 5s 138ms/step - loss: 0.0042\n",
            "Epoch 85/120\n",
            "36/36 [==============================] - 6s 172ms/step - loss: 0.0044\n",
            "Epoch 86/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0041\n",
            "Epoch 87/120\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0043\n",
            "Epoch 88/120\n",
            "36/36 [==============================] - 5s 138ms/step - loss: 0.0043\n",
            "Epoch 89/120\n",
            "36/36 [==============================] - 7s 189ms/step - loss: 0.0042\n",
            "Epoch 90/120\n",
            "36/36 [==============================] - 6s 164ms/step - loss: 0.0044\n",
            "Epoch 91/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0042\n",
            "Epoch 92/120\n",
            "36/36 [==============================] - 6s 175ms/step - loss: 0.0041\n",
            "Epoch 93/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0041\n",
            "Epoch 94/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0042\n",
            "Epoch 95/120\n",
            "36/36 [==============================] - 6s 181ms/step - loss: 0.0045\n",
            "Epoch 96/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0041\n",
            "Epoch 97/120\n",
            "36/36 [==============================] - 5s 145ms/step - loss: 0.0070\n",
            "Epoch 98/120\n",
            "36/36 [==============================] - 6s 166ms/step - loss: 0.0044\n",
            "Epoch 99/120\n",
            "36/36 [==============================] - 6s 175ms/step - loss: 0.0043\n",
            "Epoch 100/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0042\n",
            "Epoch 101/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0042\n",
            "Epoch 102/120\n",
            "36/36 [==============================] - 6s 158ms/step - loss: 0.0042\n",
            "Epoch 103/120\n",
            "36/36 [==============================] - 5s 150ms/step - loss: 0.0044\n",
            "Epoch 104/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0041\n",
            "Epoch 105/120\n",
            "36/36 [==============================] - 6s 181ms/step - loss: 0.0042\n",
            "Epoch 106/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0041\n",
            "Epoch 107/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0041\n",
            "Epoch 108/120\n",
            "36/36 [==============================] - 7s 198ms/step - loss: 0.0042\n",
            "Epoch 109/120\n",
            "36/36 [==============================] - 6s 155ms/step - loss: 0.0041\n",
            "Epoch 110/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0040\n",
            "Epoch 111/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0040\n",
            "Epoch 112/120\n",
            "36/36 [==============================] - 5s 143ms/step - loss: 0.0043\n",
            "Epoch 113/120\n",
            "36/36 [==============================] - 6s 171ms/step - loss: 0.0042\n",
            "Epoch 114/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0040\n",
            "Epoch 115/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0040\n",
            "Epoch 116/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0041\n",
            "Epoch 117/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0041\n",
            "Epoch 118/120\n",
            "36/36 [==============================] - 8s 214ms/step - loss: 0.0039\n",
            "Epoch 119/120\n",
            "36/36 [==============================] - 5s 145ms/step - loss: 0.0039\n",
            "Epoch 120/120\n",
            "36/36 [==============================] - 7s 183ms/step - loss: 0.0040\n",
            "48/48 [==============================] - 3s 23ms/step\n",
            "Epoch 1/120\n",
            "36/36 [==============================] - 21s 133ms/step - loss: 0.0195\n",
            "Epoch 2/120\n",
            "36/36 [==============================] - 5s 146ms/step - loss: 0.0078\n",
            "Epoch 3/120\n",
            "36/36 [==============================] - 8s 214ms/step - loss: 0.0073\n",
            "Epoch 4/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0065\n",
            "Epoch 5/120\n",
            "36/36 [==============================] - 6s 155ms/step - loss: 0.0062\n",
            "Epoch 6/120\n",
            "36/36 [==============================] - 5s 149ms/step - loss: 0.0057\n",
            "Epoch 7/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0061\n",
            "Epoch 8/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0057\n",
            "Epoch 9/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0060\n",
            "Epoch 10/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0057\n",
            "Epoch 11/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0058\n",
            "Epoch 12/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0055\n",
            "Epoch 13/120\n",
            "36/36 [==============================] - 8s 224ms/step - loss: 0.0053\n",
            "Epoch 14/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0053\n",
            "Epoch 15/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0052\n",
            "Epoch 16/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0051\n",
            "Epoch 17/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0051\n",
            "Epoch 18/120\n",
            "36/36 [==============================] - 6s 156ms/step - loss: 0.0051\n",
            "Epoch 19/120\n",
            "36/36 [==============================] - 6s 152ms/step - loss: 0.0051\n",
            "Epoch 20/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0050\n",
            "Epoch 21/120\n",
            "36/36 [==============================] - 6s 181ms/step - loss: 0.0053\n",
            "Epoch 22/120\n",
            "36/36 [==============================] - 5s 147ms/step - loss: 0.0049\n",
            "Epoch 23/120\n",
            "36/36 [==============================] - 7s 194ms/step - loss: 0.0049\n",
            "Epoch 24/120\n",
            "36/36 [==============================] - 5s 145ms/step - loss: 0.0052\n",
            "Epoch 25/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0052\n",
            "Epoch 26/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0048\n",
            "Epoch 27/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0048\n",
            "Epoch 28/120\n",
            "36/36 [==============================] - 5s 141ms/step - loss: 0.0050\n",
            "Epoch 29/120\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0051\n",
            "Epoch 30/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0048\n",
            "Epoch 31/120\n",
            "36/36 [==============================] - 6s 176ms/step - loss: 0.0047\n",
            "Epoch 32/120\n",
            "36/36 [==============================] - 6s 157ms/step - loss: 0.0051\n",
            "Epoch 33/120\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.0050\n",
            "Epoch 34/120\n",
            "36/36 [==============================] - 6s 154ms/step - loss: 0.0047\n",
            "Epoch 35/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0048\n",
            "Epoch 36/120\n",
            "36/36 [==============================] - 7s 202ms/step - loss: 0.0046\n",
            "Epoch 37/120\n",
            "36/36 [==============================] - 6s 162ms/step - loss: 0.0046\n",
            "Epoch 38/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0045\n",
            "Epoch 39/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0046\n",
            "Epoch 40/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0046\n",
            "Epoch 41/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0045\n",
            "Epoch 42/120\n",
            "36/36 [==============================] - 8s 226ms/step - loss: 0.0045\n",
            "Epoch 43/120\n",
            "36/36 [==============================] - 5s 135ms/step - loss: 0.0046\n",
            "Epoch 44/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0046\n",
            "Epoch 45/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0045\n",
            "Epoch 46/120\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.0048\n",
            "Epoch 47/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0045\n",
            "Epoch 48/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0046\n",
            "Epoch 49/120\n",
            "36/36 [==============================] - 6s 155ms/step - loss: 0.0046\n",
            "Epoch 50/120\n",
            "36/36 [==============================] - 6s 155ms/step - loss: 0.0045\n",
            "Epoch 51/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0043\n",
            "Epoch 52/120\n",
            "36/36 [==============================] - 7s 198ms/step - loss: 0.0046\n",
            "Epoch 53/120\n",
            "36/36 [==============================] - 6s 163ms/step - loss: 0.0045\n",
            "Epoch 54/120\n",
            "36/36 [==============================] - 5s 142ms/step - loss: 0.0047\n",
            "Epoch 55/120\n",
            "36/36 [==============================] - 6s 181ms/step - loss: 0.0045\n",
            "Epoch 56/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0046\n",
            "Epoch 57/120\n",
            "36/36 [==============================] - 5s 150ms/step - loss: 0.0049\n",
            "Epoch 58/120\n",
            "36/36 [==============================] - 6s 159ms/step - loss: 0.0045\n",
            "Epoch 59/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0046\n",
            "Epoch 60/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0042\n",
            "Epoch 61/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0043\n",
            "Epoch 62/120\n",
            "36/36 [==============================] - 6s 167ms/step - loss: 0.0044\n",
            "Epoch 63/120\n",
            "36/36 [==============================] - 7s 194ms/step - loss: 0.0047\n",
            "Epoch 64/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0044\n",
            "Epoch 65/120\n",
            "36/36 [==============================] - 6s 153ms/step - loss: 0.0043\n",
            "Epoch 66/120\n",
            "36/36 [==============================] - 6s 156ms/step - loss: 0.0045\n",
            "Epoch 67/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0043\n",
            "Epoch 68/120\n",
            "36/36 [==============================] - 6s 182ms/step - loss: 0.0043\n",
            "Epoch 69/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0043\n",
            "Epoch 70/120\n",
            "36/36 [==============================] - 5s 129ms/step - loss: 0.0044\n",
            "Epoch 71/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0043\n",
            "Epoch 72/120\n",
            "36/36 [==============================] - 6s 155ms/step - loss: 0.0043\n",
            "Epoch 73/120\n",
            "36/36 [==============================] - 7s 203ms/step - loss: 0.0042\n",
            "Epoch 74/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0044\n",
            "Epoch 75/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0043\n",
            "Epoch 76/120\n",
            "36/36 [==============================] - 8s 226ms/step - loss: 0.0043\n",
            "Epoch 77/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0042\n",
            "Epoch 78/120\n",
            "36/36 [==============================] - 6s 181ms/step - loss: 0.0042\n",
            "Epoch 79/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0043\n",
            "Epoch 80/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0043\n",
            "Epoch 81/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0043\n",
            "Epoch 82/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0042\n",
            "Epoch 83/120\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.0042\n",
            "Epoch 84/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0042\n",
            "Epoch 85/120\n",
            "36/36 [==============================] - 5s 140ms/step - loss: 0.0042\n",
            "Epoch 86/120\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0041\n",
            "Epoch 87/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0043\n",
            "Epoch 88/120\n",
            "36/36 [==============================] - 6s 177ms/step - loss: 0.0041\n",
            "Epoch 89/120\n",
            "36/36 [==============================] - 5s 135ms/step - loss: 0.0041\n",
            "Epoch 90/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0041\n",
            "Epoch 91/120\n",
            "36/36 [==============================] - 7s 187ms/step - loss: 0.0039\n",
            "Epoch 92/120\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0041\n",
            "Epoch 93/120\n",
            "36/36 [==============================] - 6s 181ms/step - loss: 0.0041\n",
            "Epoch 94/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0042\n",
            "Epoch 95/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0042\n",
            "Epoch 96/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0041\n",
            "Epoch 97/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0040\n",
            "Epoch 98/120\n",
            "36/36 [==============================] - 6s 162ms/step - loss: 0.0042\n",
            "Epoch 99/120\n",
            "36/36 [==============================] - 5s 149ms/step - loss: 0.0043\n",
            "Epoch 100/120\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.0042\n",
            "Epoch 101/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0040\n",
            "Epoch 102/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0039\n",
            "Epoch 103/120\n",
            "36/36 [==============================] - 5s 141ms/step - loss: 0.0042\n",
            "Epoch 104/120\n",
            "36/36 [==============================] - 6s 178ms/step - loss: 0.0040\n",
            "Epoch 105/120\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0040\n",
            "Epoch 106/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0040\n",
            "Epoch 107/120\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 0.0040\n",
            "Epoch 108/120\n",
            "36/36 [==============================] - 5s 150ms/step - loss: 0.0040\n",
            "Epoch 109/120\n",
            "36/36 [==============================] - 6s 160ms/step - loss: 0.0039\n",
            "Epoch 110/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0039\n",
            "Epoch 111/120\n",
            "36/36 [==============================] - 6s 179ms/step - loss: 0.0040\n",
            "Epoch 112/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0040\n",
            "Epoch 113/120\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.0040\n",
            "Epoch 114/120\n",
            "36/36 [==============================] - 7s 207ms/step - loss: 0.0040\n",
            "Epoch 115/120\n",
            "36/36 [==============================] - 6s 151ms/step - loss: 0.0039\n",
            "Epoch 116/120\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.0040\n",
            "Epoch 117/120\n",
            "36/36 [==============================] - 7s 181ms/step - loss: 0.0040\n",
            "Epoch 118/120\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0039\n",
            "Epoch 119/120\n",
            "36/36 [==============================] - 5s 138ms/step - loss: 0.0040\n",
            "Epoch 120/120\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.0038\n",
            "48/48 [==============================] - 4s 37ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss)"
      ],
      "metadata": {
        "id": "MnuUdKWaqgaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0825f825-e06d-4d0e-b291-0d34392ba58d"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.08306927059626716, 0.0850357295033951, 0.08557550969275769, 0.08358768988258575, 0.085867252976157, 0.08545770282564386, 0.08347494704333855, 0.08660480558916019, 0.08638300165051803, 0.08580869153173323]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(min(loss))"
      ],
      "metadata": {
        "id": "56ykd7kawkvX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aee49589-c56b-4e3e-cd38-6f09dbd4155b"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.08306927059626716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "5KwbVjdXKn01"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss)"
      ],
      "metadata": {
        "id": "O622nEj3Krt7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "4103856a-f9e3-457a-b98f-20911bce5bc5"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2ef0d683d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}