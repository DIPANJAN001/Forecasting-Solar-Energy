{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DIPANJAN001/Forecasting-Solar-Energy/blob/master/bestresult02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzs_vH9vlX74",
        "outputId": "03011a50-7772-45ea-bc5f-61f916f26546"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Boruta\n",
            "  Downloading Boruta-0.3-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 KB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.17.1->Boruta) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.17.1->Boruta) (3.1.0)\n",
            "Installing collected packages: Boruta\n",
            "Successfully installed Boruta-0.3\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install Boruta\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from boruta import BorutaPy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import concatenate\n",
        "from keras import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Bidirectional\n",
        "from keras import layers\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import load_model\n",
        "from keras.layers import Input\n",
        "from sklearn.decomposition import PCA "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lDilv4v2lz-w"
      },
      "outputs": [],
      "source": [
        "def lstm_data_transform(x_data, y_data, num_steps):\n",
        "    \"\"\" Changes data to the format for LSTM training \n",
        "for sliding window approach \"\"\"\n",
        "    # Prepare the list for the transformed data\n",
        "    X, y = list(), list()\n",
        "    # Loop of the entire data set\n",
        "    for i in range(x_data.shape[0]):\n",
        "        # compute a new (sliding window) index\n",
        "        end_ix = i + num_steps\n",
        "        # if index is larger than the size of the dataset, we stop\n",
        "        if end_ix >= x_data.shape[0]:\n",
        "            break\n",
        "        # Get a sequence of data for x\n",
        "        seq_X = x_data[i:end_ix]\n",
        "        # Get only the last element of the sequency for y\n",
        "        seq_y = y_data[end_ix]\n",
        "        # Append the list with sequencies\n",
        "        X.append(seq_X)\n",
        "        y.append(seq_y)\n",
        "    # Make final arrays\n",
        "    x_array = np.array(X)\n",
        "    y_array = np.array(y)\n",
        "    return x_array, y_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iQt_oZP7QczL"
      },
      "outputs": [],
      "source": [
        "df=pd.read_excel(\"/content/pv_02.xlsx\")\n",
        "weather_input1=df.drop('power_normed',axis=1)\n",
        "weather_input=weather_input1.drop('time_idx',axis=1)\n",
        "solpow=df['power_normed']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoPnMw4oQQlc",
        "outputId": "c949e583-7d57-4c83-e157-e9e3a6f0d54e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: \t1 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t2 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t3 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t4 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t5 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t6 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t7 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t8 / 100\n",
            "Confirmed: \t6\n",
            "Tentative: \t15\n",
            "Rejected: \t28\n",
            "Iteration: \t9 / 100\n",
            "Confirmed: \t6\n",
            "Tentative: \t15\n",
            "Rejected: \t28\n",
            "Iteration: \t10 / 100\n",
            "Confirmed: \t6\n",
            "Tentative: \t15\n",
            "Rejected: \t28\n",
            "Iteration: \t11 / 100\n",
            "Confirmed: \t6\n",
            "Tentative: \t15\n",
            "Rejected: \t28\n",
            "Iteration: \t12 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t11\n",
            "Rejected: \t30\n",
            "Iteration: \t13 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t11\n",
            "Rejected: \t30\n",
            "Iteration: \t14 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t11\n",
            "Rejected: \t30\n",
            "Iteration: \t15 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t11\n",
            "Rejected: \t30\n",
            "Iteration: \t16 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t8\n",
            "Rejected: \t30\n",
            "Iteration: \t17 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t8\n",
            "Rejected: \t30\n",
            "Iteration: \t18 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t8\n",
            "Rejected: \t30\n",
            "Iteration: \t19 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t7\n",
            "Rejected: \t31\n",
            "Iteration: \t20 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t7\n",
            "Rejected: \t31\n",
            "Iteration: \t21 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t7\n",
            "Rejected: \t31\n",
            "Iteration: \t22 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t6\n",
            "Rejected: \t31\n",
            "Iteration: \t23 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t6\n",
            "Rejected: \t31\n",
            "Iteration: \t24 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t6\n",
            "Rejected: \t31\n",
            "Iteration: \t25 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t6\n",
            "Rejected: \t31\n",
            "Iteration: \t26 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t6\n",
            "Rejected: \t31\n",
            "Iteration: \t27 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t6\n",
            "Rejected: \t31\n",
            "Iteration: \t28 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t6\n",
            "Rejected: \t31\n",
            "Iteration: \t29 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t6\n",
            "Rejected: \t31\n",
            "Iteration: \t30 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t6\n",
            "Rejected: \t31\n",
            "Iteration: \t31 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t6\n",
            "Rejected: \t31\n",
            "Iteration: \t32 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t6\n",
            "Rejected: \t31\n",
            "Iteration: \t33 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t6\n",
            "Rejected: \t31\n",
            "Iteration: \t34 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t6\n",
            "Rejected: \t31\n",
            "Iteration: \t35 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t6\n",
            "Rejected: \t31\n",
            "Iteration: \t36 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t6\n",
            "Rejected: \t31\n",
            "Iteration: \t37 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t6\n",
            "Rejected: \t31\n",
            "Iteration: \t38 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t6\n",
            "Rejected: \t31\n",
            "Iteration: \t39 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t6\n",
            "Rejected: \t31\n",
            "Iteration: \t40 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t5\n",
            "Rejected: \t31\n",
            "Iteration: \t41 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t5\n",
            "Rejected: \t31\n",
            "Iteration: \t42 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t5\n",
            "Rejected: \t31\n",
            "Iteration: \t43 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t4\n",
            "Rejected: \t31\n",
            "Iteration: \t44 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t4\n",
            "Rejected: \t31\n",
            "Iteration: \t45 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t4\n",
            "Rejected: \t31\n",
            "Iteration: \t46 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t4\n",
            "Rejected: \t31\n",
            "Iteration: \t47 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t4\n",
            "Rejected: \t31\n",
            "Iteration: \t48 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t4\n",
            "Rejected: \t31\n",
            "Iteration: \t49 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t4\n",
            "Rejected: \t31\n",
            "Iteration: \t50 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t4\n",
            "Rejected: \t31\n",
            "Iteration: \t51 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t52 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t53 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t54 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t55 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t56 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t57 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t58 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t59 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t60 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t61 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t62 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t63 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t64 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t65 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t66 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t67 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t68 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t69 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t70 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t71 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t72 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t73 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t74 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t75 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t76 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t77 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t78 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t79 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t80 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t81 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t82 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t83 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t84 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t85 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t86 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t87 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t88 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t89 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t90 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t91 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t92 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t93 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t94 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t95 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t96 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t97 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t98 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "Iteration: \t99 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t3\n",
            "Rejected: \t31\n",
            "\n",
            "\n",
            "BorutaPy finished running.\n",
            "\n",
            "Iteration: \t100 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BorutaPy(estimator=RandomForestRegressor(max_depth=7, n_estimators=85,\n",
              "                                         random_state=RandomState(MT19937) at 0x7FEEE70A5840),\n",
              "         n_estimators='auto',\n",
              "         random_state=RandomState(MT19937) at 0x7FEEE70A5840, verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "rfc = RandomForestRegressor(random_state=1, n_estimators=1000, max_depth=7)\n",
        "boruta_selector = BorutaPy(rfc, n_estimators='auto', verbose=2, random_state=1)\n",
        "boruta_selector.fit(np.array(weather_input), np.array(solpow)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "u2NoSDCGUFNU"
      },
      "outputs": [],
      "source": [
        "X_important_train = boruta_selector.transform(np.array(weather_input))\n",
        "num_steps = 3\n",
        "# training set\n",
        "(x_transformed_train,\n",
        " y_transformed_train) = lstm_data_transform(X_important_train,solpow , num_steps=num_steps)\n",
        "assert x_transformed_train.shape[0] == y_transformed_train.shape[0]\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_transformed_train,y_transformed_train,test_size=0.25, random_state=42,shuffle=False)\n",
        "#X_train_,X_val,y_train_,y_val=train_test_split(X_train,y_train,test_size=0.2, random_state=42,shuffle=False)\n",
        "inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdKjqiCK5m_T",
        "outputId": "aee464b0-11c1-4763-93a2-914cb6aac4e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 3, 15) dtype=float32 (created by layer 'input_1')>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "inputs1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "V27z-GjNapD4"
      },
      "outputs": [],
      "source": [
        "from keras import optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uxD0diT8a4c2"
      },
      "outputs": [],
      "source": [
        "opt=optimizers.Adam(learning_rate=0.003)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YM0Epc0yvWnJ"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "\n",
        "class CustomAdam(optimizers.Adam):\n",
        "    def __init__(self, new_idea_param=0.1, *args, **kwargs):\n",
        "        self.new_idea_param = new_idea_param\n",
        "        super(CustomAdam, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [K.update_add(self.iterations, 1)]\n",
        "\n",
        "        lr = self.lr\n",
        "        if self.initial_decay > 0:\n",
        "            lr *= (1. / (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n",
        "\n",
        "        t = K.cast(self.iterations, K.floatx()) + 1\n",
        "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        new_idea_t = self.new_idea_param * (K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        self.weights = [self.iterations] + ms + vs\n",
        "\n",
        "        for p, g, m, v in zip(params, grads, ms, vs):\n",
        "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
        "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
        "            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon) - new_idea_t * g\n",
        "\n",
        "            self.updates.append(K.update(m, m_t))\n",
        "            self.updates.append(K.update(v, v_t))\n",
        "            self.updates.append(K.update(p, p_t))\n",
        "        return self.updates"
      ],
      "metadata": {
        "id": "g8F6yCGl21Sz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "\n",
        "class GradientAdam(optimizers.Adam):\n",
        "    def __init__(self, gradient_param=0.1, *args, **kwargs):\n",
        "        self.gradient_param = gradient_param\n",
        "        super(GradientAdam, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [K.update_add(self.iterations, 1)]\n",
        "\n",
        "        lr = self.lr\n",
        "        if self.initial_decay > 0:\n",
        "            lr *= (1. / (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n",
        "\n",
        "        t = K.cast(self.iterations, K.floatx()) + 1\n",
        "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        gradient_t = self.gradient_param * grads\n",
        "\n",
        "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        self.weights = [self.iterations] + ms + vs\n",
        "\n",
        "        for p, g, m, v, g_t in zip(params, grads, ms, vs, gradient_t):\n",
        "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
        "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
        "            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon) + g_t\n",
        "\n",
        "            self.updates.append(K.update(m, m_t))\n",
        "            self.updates.append(K.update(v, v_t))\n",
        "            self.updates.append(K.update(p, p_t))\n",
        "        return self.updates\n"
      ],
      "metadata": {
        "id": "J_gyZaJU8f4W"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "t0f48T0zsiAs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "class HalvAdam(Adam):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.prev_gradients = None\n",
        "\n",
        "    @tf.function\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [math_ops.cast(x, \"float32\") for x in grads]\n",
        "\n",
        "        if self.prev_gradients is not None:\n",
        "            for i in range(len(grads)):\n",
        "                if (grads[i] * self.prev_gradients[i] < 0):\n",
        "                    self.updates[i] = self.updates[i] / 2\n",
        "\n",
        "        self.prev_gradients = grads\n",
        "        return self.updates"
      ],
      "metadata": {
        "id": "MpStRslgCRBO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "class AdaptiveAdam(Adam):\n",
        "    def __init__(self, *args, factor=0.5, patience=5, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.wait = 0\n",
        "        self.best_loss = float('inf')\n",
        "        self.best_weights = None\n",
        "\n",
        "    @tf.function\n",
        "    def get_updates(self, loss, params):\n",
        "        current_loss = loss()\n",
        "        if current_loss < self.best_loss:\n",
        "            self.best_loss = current_loss\n",
        "            self.best_weights = params\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.wait = 0\n",
        "                self.lr = self.lr * self.factor\n",
        "                params = self.best_weights\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [math_ops.cast(g, \"float32\") for g in grads]\n",
        "        return self.updates\n"
      ],
      "metadata": {
        "id": "PmHcGR7JJLo_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "class MomentumAdam(Adam):\n",
        "    def __init__(self, *args, momentum=0.9, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.momentum = momentum\n",
        "        self.velocities = [tf.Variable(tf.zeros_like(p), trainable=False) for p in self.weights]\n",
        "\n",
        "    @tf.function\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = []\n",
        "        for p, g, v in zip(params, grads, self.velocities):\n",
        "            v_t = self.momentum * v - self.lr * g\n",
        "            p_t = p + v_t\n",
        "            self.updates.append(p_t)\n",
        "            self.updates.append(v_t)\n",
        "        return self.updates\n"
      ],
      "metadata": {
        "id": "Zqo9SvzjbTtq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "cSM9vzEq3G3U"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "nq9ZwBIrI_qj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "18n5dRvpuI5T"
      },
      "outputs": [],
      "source": [
        "def define_model():\n",
        "\n",
        "\n",
        "  fe2_0 = Bidirectional(LSTM(256, activation='LeakyReLU',return_sequences = True))(inputs1)\n",
        "  fe2_1 = Dropout(0.6)(fe2_0)\n",
        "  fe2_2 = Bidirectional(LSTM(64, activation='LeakyReLU',return_sequences = True))(fe2_1)\n",
        "  fe2_3= Dropout(0.5)(fe2_2)\n",
        "  fe2_4=Bidirectional(LSTM(4, activation='LeakyReLU'))(fe2_3)\n",
        "  out2_1=Dense(1, activation='relu')(fe2_4)\n",
        "\n",
        "  fe3_0 =Bidirectional(LSTM(128, activation='LeakyReLU',return_sequences = True))(inputs1)\n",
        "  fe3_1 = Dropout(0.6)(fe3_0)\n",
        "  fe3_2 = Bidirectional(LSTM(96, activation='LeakyReLU',return_sequences = True))(fe3_1)\n",
        "  fe3_3= Dropout(0.5)(fe3_2)\n",
        "  fe3_4=Bidirectional(LSTM(8, activation='LeakyReLU'))(fe3_3)#16\n",
        "  out3_1=Dense(1, activation='relu')(fe3_4)\n",
        " \n",
        " \n",
        "\n",
        "  output = layers.average([out2_1, out3_1])\n",
        "  #merged3 = concatenate([out2_1,out3_1], name='concat3')\n",
        "  #output = Dense(1, activation='relu')( merged3)\n",
        "  \n",
        "\n",
        "  model = Model(inputs=[inputs1], outputs=[output])\n",
        "  \n",
        " \n",
        "  return model\n",
        "mdl=define_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss=[]"
      ],
      "metadata": {
        "id": "P5UqekV1_q7F"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import clone_model"
      ],
      "metadata": {
        "id": "9zy5UX8p_zSl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "dAICp2p5OCER"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "9iwWrmDs0z7O"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GlobalMinimaSearch(weights):\n",
        "  if len(loss)>9:\n",
        "   return\n",
        "  \n",
        "  initial_weights =weights\n",
        "  model=clone_model(mdl)\n",
        "  model.set_weights(weights)\n",
        "  model.compile(optimizer=HalvAdam(learning_rate=0.003), loss='mean_squared_error')\n",
        "  model.fit(X_train, y_train, epochs=120, batch_size=128)\n",
        "  y= model.predict(X_test)\n",
        "  loss.append(np.sqrt(mean_squared_error(y,y_test)))\n",
        "  best_weights= model.get_weights()\n",
        "  \n",
        "\n",
        "     \n",
        "\n",
        "  params_1 =[final_weight + (final_weight - initial_weight) for initial_weight, final_weight in zip(initial_weights, best_weights)]\n",
        "  #GlobalMinimaSearch(params_1)\n",
        "\n",
        "\n",
        "  params_2 =[final_weight - (final_weight - initial_weight) for initial_weight, final_weight in zip(initial_weights, best_weights)]\n",
        "  GlobalMinimaSearch(params_2)\n",
        "  \n",
        " "
      ],
      "metadata": {
        "id": "FxpviTJb_nUR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GlobalMinimaSearch(mdl.get_weights())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XuddmGCf_1dR",
        "outputId": "ea610032-f5a2-455f-9ab5-28fb9a427507"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "37/37 [==============================] - 21s 157ms/step - loss: 0.0151\n",
            "Epoch 2/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0066\n",
            "Epoch 3/120\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 0.0062\n",
            "Epoch 4/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0053\n",
            "Epoch 5/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0054\n",
            "Epoch 6/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0051\n",
            "Epoch 7/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0048\n",
            "Epoch 8/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0050\n",
            "Epoch 9/120\n",
            "37/37 [==============================] - 5s 147ms/step - loss: 0.0051\n",
            "Epoch 10/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0046\n",
            "Epoch 11/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0046\n",
            "Epoch 12/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0047\n",
            "Epoch 13/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0048\n",
            "Epoch 14/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0045\n",
            "Epoch 15/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0045\n",
            "Epoch 16/120\n",
            "37/37 [==============================] - 5s 143ms/step - loss: 0.0048\n",
            "Epoch 17/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0043\n",
            "Epoch 18/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0046\n",
            "Epoch 19/120\n",
            "37/37 [==============================] - 7s 189ms/step - loss: 0.0042\n",
            "Epoch 20/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0044\n",
            "Epoch 21/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0044\n",
            "Epoch 22/120\n",
            "37/37 [==============================] - 5s 147ms/step - loss: 0.0043\n",
            "Epoch 23/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0043\n",
            "Epoch 24/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0042\n",
            "Epoch 25/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0042\n",
            "Epoch 26/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0043\n",
            "Epoch 27/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0044\n",
            "Epoch 28/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0042\n",
            "Epoch 29/120\n",
            "37/37 [==============================] - 5s 143ms/step - loss: 0.0041\n",
            "Epoch 30/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0042\n",
            "Epoch 31/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0042\n",
            "Epoch 32/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0043\n",
            "Epoch 33/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0041\n",
            "Epoch 34/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0040\n",
            "Epoch 35/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0042\n",
            "Epoch 36/120\n",
            "37/37 [==============================] - 4s 122ms/step - loss: 0.0043\n",
            "Epoch 37/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0042\n",
            "Epoch 38/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0041\n",
            "Epoch 39/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0041\n",
            "Epoch 40/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0041\n",
            "Epoch 41/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0041\n",
            "Epoch 42/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0040\n",
            "Epoch 43/120\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 0.0040\n",
            "Epoch 44/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0040\n",
            "Epoch 45/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0041\n",
            "Epoch 46/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0042\n",
            "Epoch 47/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0040\n",
            "Epoch 48/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0041\n",
            "Epoch 49/120\n",
            "37/37 [==============================] - 4s 122ms/step - loss: 0.0039\n",
            "Epoch 50/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0040\n",
            "Epoch 51/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0040\n",
            "Epoch 52/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0041\n",
            "Epoch 53/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0039\n",
            "Epoch 54/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0039\n",
            "Epoch 55/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0039\n",
            "Epoch 56/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0039\n",
            "Epoch 57/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0041\n",
            "Epoch 58/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0039\n",
            "Epoch 59/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0038\n",
            "Epoch 60/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0040\n",
            "Epoch 61/120\n",
            "37/37 [==============================] - 7s 190ms/step - loss: 0.0038\n",
            "Epoch 62/120\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 0.0039\n",
            "Epoch 63/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0038\n",
            "Epoch 64/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0039\n",
            "Epoch 65/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0038\n",
            "Epoch 66/120\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 0.0039\n",
            "Epoch 67/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0040\n",
            "Epoch 68/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0038\n",
            "Epoch 69/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0038\n",
            "Epoch 70/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0037\n",
            "Epoch 71/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0038\n",
            "Epoch 72/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0038\n",
            "Epoch 73/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0038\n",
            "Epoch 74/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0039\n",
            "Epoch 75/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0038\n",
            "Epoch 76/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0038\n",
            "Epoch 77/120\n",
            "37/37 [==============================] - 4s 117ms/step - loss: 0.0040\n",
            "Epoch 78/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0061\n",
            "Epoch 79/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0068\n",
            "Epoch 80/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0043\n",
            "Epoch 81/120\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.0051\n",
            "Epoch 82/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0042\n",
            "Epoch 83/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0043\n",
            "Epoch 84/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0197\n",
            "Epoch 85/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0045\n",
            "Epoch 86/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0040\n",
            "Epoch 87/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0110\n",
            "Epoch 88/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0041\n",
            "Epoch 89/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0040\n",
            "Epoch 90/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0040\n",
            "Epoch 91/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0040\n",
            "Epoch 92/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0039\n",
            "Epoch 93/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0040\n",
            "Epoch 94/120\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.0039\n",
            "Epoch 95/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0040\n",
            "Epoch 96/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0039\n",
            "Epoch 97/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0038\n",
            "Epoch 98/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0039\n",
            "Epoch 99/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0040\n",
            "Epoch 100/120\n",
            "37/37 [==============================] - 6s 148ms/step - loss: 0.0041\n",
            "Epoch 101/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0039\n",
            "Epoch 102/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0038\n",
            "Epoch 103/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0038\n",
            "Epoch 104/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0040\n",
            "Epoch 105/120\n",
            "37/37 [==============================] - 7s 193ms/step - loss: 0.0039\n",
            "Epoch 106/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0037\n",
            "Epoch 107/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0038\n",
            "Epoch 108/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0037\n",
            "Epoch 109/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0040\n",
            "Epoch 110/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0037\n",
            "Epoch 111/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0037\n",
            "Epoch 112/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0037\n",
            "Epoch 113/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0039\n",
            "Epoch 114/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0038\n",
            "Epoch 115/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0038\n",
            "Epoch 116/120\n",
            "37/37 [==============================] - 5s 143ms/step - loss: 0.0040\n",
            "Epoch 117/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0038\n",
            "Epoch 118/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0037\n",
            "Epoch 119/120\n",
            "37/37 [==============================] - 4s 122ms/step - loss: 0.0038\n",
            "Epoch 120/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0038\n",
            "50/50 [==============================] - 3s 19ms/step\n",
            "Epoch 1/120\n",
            "37/37 [==============================] - 20s 125ms/step - loss: 0.0162\n",
            "Epoch 2/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0063\n",
            "Epoch 3/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0057\n",
            "Epoch 4/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0055\n",
            "Epoch 5/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0055\n",
            "Epoch 6/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0053\n",
            "Epoch 7/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0051\n",
            "Epoch 8/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0048\n",
            "Epoch 9/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0048\n",
            "Epoch 10/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0047\n",
            "Epoch 11/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0048\n",
            "Epoch 12/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0045\n",
            "Epoch 13/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0044\n",
            "Epoch 14/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0046\n",
            "Epoch 15/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0047\n",
            "Epoch 16/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0043\n",
            "Epoch 17/120\n",
            "37/37 [==============================] - 5s 147ms/step - loss: 0.0046\n",
            "Epoch 18/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0046\n",
            "Epoch 19/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0045\n",
            "Epoch 20/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0044\n",
            "Epoch 21/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0046\n",
            "Epoch 22/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0043\n",
            "Epoch 23/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0044\n",
            "Epoch 24/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0044\n",
            "Epoch 25/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0042\n",
            "Epoch 26/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0043\n",
            "Epoch 27/120\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.0042\n",
            "Epoch 28/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0042\n",
            "Epoch 29/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0041\n",
            "Epoch 30/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0042\n",
            "Epoch 31/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0044\n",
            "Epoch 32/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0045\n",
            "Epoch 33/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0040\n",
            "Epoch 34/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0041\n",
            "Epoch 35/120\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 0.0041\n",
            "Epoch 36/120\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 0.0041\n",
            "Epoch 37/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0043\n",
            "Epoch 38/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0039\n",
            "Epoch 39/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0040\n",
            "Epoch 40/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0041\n",
            "Epoch 41/120\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.0042\n",
            "Epoch 42/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0040\n",
            "Epoch 43/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0042\n",
            "Epoch 44/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0044\n",
            "Epoch 45/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0040\n",
            "Epoch 46/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0040\n",
            "Epoch 47/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0039\n",
            "Epoch 48/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0040\n",
            "Epoch 49/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0040\n",
            "Epoch 50/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0041\n",
            "Epoch 51/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0041\n",
            "Epoch 52/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0040\n",
            "Epoch 53/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0039\n",
            "Epoch 54/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0039\n",
            "Epoch 55/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0042\n",
            "Epoch 56/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0040\n",
            "Epoch 57/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0040\n",
            "Epoch 58/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0041\n",
            "Epoch 59/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0039\n",
            "Epoch 60/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0039\n",
            "Epoch 61/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0039\n",
            "Epoch 62/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0038\n",
            "Epoch 63/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0040\n",
            "Epoch 64/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0042\n",
            "Epoch 65/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0039\n",
            "Epoch 66/120\n",
            "37/37 [==============================] - 5s 143ms/step - loss: 0.0038\n",
            "Epoch 67/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0038\n",
            "Epoch 68/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0040\n",
            "Epoch 69/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0038\n",
            "Epoch 70/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0038\n",
            "Epoch 71/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0038\n",
            "Epoch 72/120\n",
            "37/37 [==============================] - 6s 149ms/step - loss: 0.0038\n",
            "Epoch 73/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0040\n",
            "Epoch 74/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0040\n",
            "Epoch 75/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0038\n",
            "Epoch 76/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0038\n",
            "Epoch 77/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0037\n",
            "Epoch 78/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0038\n",
            "Epoch 79/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0037\n",
            "Epoch 80/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0037\n",
            "Epoch 81/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0037\n",
            "Epoch 82/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0038\n",
            "Epoch 83/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0039\n",
            "Epoch 84/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0038\n",
            "Epoch 85/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0038\n",
            "Epoch 86/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0038\n",
            "Epoch 87/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0039\n",
            "Epoch 88/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0037\n",
            "Epoch 89/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0038\n",
            "Epoch 90/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0038\n",
            "Epoch 91/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0037\n",
            "Epoch 92/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0038\n",
            "Epoch 93/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0037\n",
            "Epoch 94/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0037\n",
            "Epoch 95/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0036\n",
            "Epoch 96/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0037\n",
            "Epoch 97/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0036\n",
            "Epoch 98/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0037\n",
            "Epoch 99/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0037\n",
            "Epoch 100/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0038\n",
            "Epoch 101/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0036\n",
            "Epoch 102/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0036\n",
            "Epoch 103/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0038\n",
            "Epoch 104/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0037\n",
            "Epoch 105/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0037\n",
            "Epoch 106/120\n",
            "37/37 [==============================] - 7s 186ms/step - loss: 0.0036\n",
            "Epoch 107/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0036\n",
            "Epoch 108/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0037\n",
            "Epoch 109/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0036\n",
            "Epoch 110/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0035\n",
            "Epoch 111/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0037\n",
            "Epoch 112/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0036\n",
            "Epoch 113/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0037\n",
            "Epoch 114/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0036\n",
            "Epoch 115/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0034\n",
            "Epoch 116/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0036\n",
            "Epoch 117/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0038\n",
            "Epoch 118/120\n",
            "37/37 [==============================] - 5s 148ms/step - loss: 0.0036\n",
            "Epoch 119/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0035\n",
            "Epoch 120/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0039\n",
            "50/50 [==============================] - 4s 37ms/step\n",
            "Epoch 1/120\n",
            "37/37 [==============================] - 20s 120ms/step - loss: 0.0142\n",
            "Epoch 2/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0065\n",
            "Epoch 3/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0057\n",
            "Epoch 4/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0057\n",
            "Epoch 5/120\n",
            "37/37 [==============================] - 5s 143ms/step - loss: 0.0054\n",
            "Epoch 6/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0053\n",
            "Epoch 7/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0049\n",
            "Epoch 8/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0050\n",
            "Epoch 9/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0045\n",
            "Epoch 10/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0046\n",
            "Epoch 11/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0048\n",
            "Epoch 12/120\n",
            "37/37 [==============================] - 5s 148ms/step - loss: 0.0045\n",
            "Epoch 13/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0047\n",
            "Epoch 14/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0046\n",
            "Epoch 15/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0046\n",
            "Epoch 16/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0043\n",
            "Epoch 17/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0045\n",
            "Epoch 18/120\n",
            "37/37 [==============================] - 6s 149ms/step - loss: 0.0046\n",
            "Epoch 19/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0043\n",
            "Epoch 20/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0043\n",
            "Epoch 21/120\n",
            "37/37 [==============================] - 4s 122ms/step - loss: 0.0043\n",
            "Epoch 22/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0043\n",
            "Epoch 23/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0043\n",
            "Epoch 24/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0042\n",
            "Epoch 25/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0046\n",
            "Epoch 26/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0042\n",
            "Epoch 27/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0043\n",
            "Epoch 28/120\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 0.0044\n",
            "Epoch 29/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0048\n",
            "Epoch 30/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0044\n",
            "Epoch 31/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0042\n",
            "Epoch 32/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0043\n",
            "Epoch 33/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0088\n",
            "Epoch 34/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0058\n",
            "Epoch 35/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0045\n",
            "Epoch 36/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0043\n",
            "Epoch 37/120\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 0.0043\n",
            "Epoch 38/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0042\n",
            "Epoch 39/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0041\n",
            "Epoch 40/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0043\n",
            "Epoch 41/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0042\n",
            "Epoch 42/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0041\n",
            "Epoch 43/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0042\n",
            "Epoch 44/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0041\n",
            "Epoch 45/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0043\n",
            "Epoch 46/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0041\n",
            "Epoch 47/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0040\n",
            "Epoch 48/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0041\n",
            "Epoch 49/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0040\n",
            "Epoch 50/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0040\n",
            "Epoch 51/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0042\n",
            "Epoch 52/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0039\n",
            "Epoch 53/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0040\n",
            "Epoch 54/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0039\n",
            "Epoch 55/120\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 0.0040\n",
            "Epoch 56/120\n",
            "37/37 [==============================] - 5s 148ms/step - loss: 0.0043\n",
            "Epoch 57/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0040\n",
            "Epoch 58/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0039\n",
            "Epoch 59/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0042\n",
            "Epoch 60/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0039\n",
            "Epoch 61/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0040\n",
            "Epoch 62/120\n",
            "37/37 [==============================] - 6s 148ms/step - loss: 0.0039\n",
            "Epoch 63/120\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 0.0039\n",
            "Epoch 64/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0039\n",
            "Epoch 65/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0038\n",
            "Epoch 66/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0039\n",
            "Epoch 67/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0041\n",
            "Epoch 68/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0039\n",
            "Epoch 69/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0038\n",
            "Epoch 70/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0039\n",
            "Epoch 71/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0037\n",
            "Epoch 72/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0039\n",
            "Epoch 73/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0039\n",
            "Epoch 74/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0037\n",
            "Epoch 75/120\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.0038\n",
            "Epoch 76/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0038\n",
            "Epoch 77/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0041\n",
            "Epoch 78/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0038\n",
            "Epoch 79/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0040\n",
            "Epoch 80/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0039\n",
            "Epoch 81/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0037\n",
            "Epoch 82/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0039\n",
            "Epoch 83/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0038\n",
            "Epoch 84/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0038\n",
            "Epoch 85/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0040\n",
            "Epoch 86/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0038\n",
            "Epoch 87/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0038\n",
            "Epoch 88/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0037\n",
            "Epoch 89/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0038\n",
            "Epoch 90/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0037\n",
            "Epoch 91/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0037\n",
            "Epoch 92/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0037\n",
            "Epoch 93/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0037\n",
            "Epoch 94/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0038\n",
            "Epoch 95/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0039\n",
            "Epoch 96/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0036\n",
            "Epoch 97/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0036\n",
            "Epoch 98/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0037\n",
            "Epoch 99/120\n",
            "37/37 [==============================] - 4s 122ms/step - loss: 0.0037\n",
            "Epoch 100/120\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 0.0037\n",
            "Epoch 101/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0036\n",
            "Epoch 102/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0044\n",
            "Epoch 103/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0044\n",
            "Epoch 104/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0038\n",
            "Epoch 105/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0038\n",
            "Epoch 106/120\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.0038\n",
            "Epoch 107/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0037\n",
            "Epoch 108/120\n",
            "37/37 [==============================] - 6s 160ms/step - loss: 0.0037\n",
            "Epoch 109/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0038\n",
            "Epoch 110/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0038\n",
            "Epoch 111/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0038\n",
            "Epoch 112/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0038\n",
            "Epoch 113/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0037\n",
            "Epoch 114/120\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 0.0036\n",
            "Epoch 115/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0039\n",
            "Epoch 116/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0036\n",
            "Epoch 117/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0039\n",
            "Epoch 118/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0036\n",
            "Epoch 119/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0036\n",
            "Epoch 120/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0037\n",
            "50/50 [==============================] - 3s 19ms/step\n",
            "Epoch 1/120\n",
            "37/37 [==============================] - 20s 128ms/step - loss: 0.0162\n",
            "Epoch 2/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0062\n",
            "Epoch 3/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0058\n",
            "Epoch 4/120\n",
            "37/37 [==============================] - 4s 122ms/step - loss: 0.0053\n",
            "Epoch 5/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0055\n",
            "Epoch 6/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0052\n",
            "Epoch 7/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0053\n",
            "Epoch 8/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0049\n",
            "Epoch 9/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0050\n",
            "Epoch 10/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0048\n",
            "Epoch 11/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0046\n",
            "Epoch 12/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0046\n",
            "Epoch 13/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0044\n",
            "Epoch 14/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0043\n",
            "Epoch 15/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0044\n",
            "Epoch 16/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0043\n",
            "Epoch 17/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0046\n",
            "Epoch 18/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0044\n",
            "Epoch 19/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0044\n",
            "Epoch 20/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0043\n",
            "Epoch 21/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0042\n",
            "Epoch 22/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0045\n",
            "Epoch 23/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0044\n",
            "Epoch 24/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0042\n",
            "Epoch 25/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0042\n",
            "Epoch 26/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0045\n",
            "Epoch 27/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0044\n",
            "Epoch 28/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0045\n",
            "Epoch 29/120\n",
            "37/37 [==============================] - 7s 190ms/step - loss: 0.0041\n",
            "Epoch 30/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0044\n",
            "Epoch 31/120\n",
            "37/37 [==============================] - 6s 160ms/step - loss: 0.0042\n",
            "Epoch 32/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0042\n",
            "Epoch 33/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0041\n",
            "Epoch 34/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0042\n",
            "Epoch 35/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0041\n",
            "Epoch 36/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0042\n",
            "Epoch 37/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0041\n",
            "Epoch 38/120\n",
            "37/37 [==============================] - 4s 122ms/step - loss: 0.0040\n",
            "Epoch 39/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0040\n",
            "Epoch 40/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0041\n",
            "Epoch 41/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0040\n",
            "Epoch 42/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0040\n",
            "Epoch 43/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0040\n",
            "Epoch 44/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0040\n",
            "Epoch 45/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0040\n",
            "Epoch 46/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0040\n",
            "Epoch 47/120\n",
            "37/37 [==============================] - 6s 147ms/step - loss: 0.0039\n",
            "Epoch 48/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0042\n",
            "Epoch 49/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0041\n",
            "Epoch 50/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0039\n",
            "Epoch 51/120\n",
            "37/37 [==============================] - 4s 122ms/step - loss: 0.0039\n",
            "Epoch 52/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0039\n",
            "Epoch 53/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0040\n",
            "Epoch 54/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0039\n",
            "Epoch 55/120\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 0.0039\n",
            "Epoch 56/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0041\n",
            "Epoch 57/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0040\n",
            "Epoch 58/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0038\n",
            "Epoch 59/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0039\n",
            "Epoch 60/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0040\n",
            "Epoch 61/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0039\n",
            "Epoch 62/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0040\n",
            "Epoch 63/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0038\n",
            "Epoch 64/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0039\n",
            "Epoch 65/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0043\n",
            "Epoch 66/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0040\n",
            "Epoch 67/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0039\n",
            "Epoch 68/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0038\n",
            "Epoch 69/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0040\n",
            "Epoch 70/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0038\n",
            "Epoch 71/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0037\n",
            "Epoch 72/120\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 0.0038\n",
            "Epoch 73/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0038\n",
            "Epoch 74/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0037\n",
            "Epoch 75/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0038\n",
            "Epoch 76/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0038\n",
            "Epoch 77/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0039\n",
            "Epoch 78/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0039\n",
            "Epoch 79/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0037\n",
            "Epoch 80/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0043\n",
            "Epoch 81/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0037\n",
            "Epoch 82/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0039\n",
            "Epoch 83/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0039\n",
            "Epoch 84/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0038\n",
            "Epoch 85/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0036\n",
            "Epoch 86/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0038\n",
            "Epoch 87/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0035\n",
            "Epoch 88/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0035\n",
            "Epoch 89/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0039\n",
            "Epoch 90/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0038\n",
            "Epoch 91/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0039\n",
            "Epoch 92/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0037\n",
            "Epoch 93/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0038\n",
            "Epoch 94/120\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 0.0038\n",
            "Epoch 95/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0037\n",
            "Epoch 96/120\n",
            "37/37 [==============================] - 6s 148ms/step - loss: 0.0037\n",
            "Epoch 97/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0037\n",
            "Epoch 98/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0037\n",
            "Epoch 99/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0037\n",
            "Epoch 100/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0037\n",
            "Epoch 101/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0036\n",
            "Epoch 102/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0035\n",
            "Epoch 103/120\n",
            "37/37 [==============================] - 6s 160ms/step - loss: 0.0036\n",
            "Epoch 104/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0036\n",
            "Epoch 105/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0036\n",
            "Epoch 106/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0035\n",
            "Epoch 107/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0035\n",
            "Epoch 108/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0036\n",
            "Epoch 109/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0036\n",
            "Epoch 110/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0036\n",
            "Epoch 111/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0036\n",
            "Epoch 112/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0036\n",
            "Epoch 113/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0035\n",
            "Epoch 114/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0037\n",
            "Epoch 115/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0035\n",
            "Epoch 116/120\n",
            "37/37 [==============================] - 6s 171ms/step - loss: 0.0035\n",
            "Epoch 117/120\n",
            "37/37 [==============================] - 5s 146ms/step - loss: 0.0035\n",
            "Epoch 118/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0035\n",
            "Epoch 119/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0037\n",
            "Epoch 120/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0035\n",
            "50/50 [==============================] - 4s 20ms/step\n",
            "Epoch 1/120\n",
            "37/37 [==============================] - 19s 125ms/step - loss: 0.0138\n",
            "Epoch 2/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0063\n",
            "Epoch 3/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0061\n",
            "Epoch 4/120\n",
            "37/37 [==============================] - 6s 160ms/step - loss: 0.0057\n",
            "Epoch 5/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0059\n",
            "Epoch 6/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0052\n",
            "Epoch 7/120\n",
            "37/37 [==============================] - 6s 160ms/step - loss: 0.0050\n",
            "Epoch 8/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0053\n",
            "Epoch 9/120\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 0.0047\n",
            "Epoch 10/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0046\n",
            "Epoch 11/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0049\n",
            "Epoch 12/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0047\n",
            "Epoch 13/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0046\n",
            "Epoch 14/120\n",
            "37/37 [==============================] - 6s 149ms/step - loss: 0.0046\n",
            "Epoch 15/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0044\n",
            "Epoch 16/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0044\n",
            "Epoch 17/120\n",
            "37/37 [==============================] - 6s 160ms/step - loss: 0.0044\n",
            "Epoch 18/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0044\n",
            "Epoch 19/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0043\n",
            "Epoch 20/120\n",
            "37/37 [==============================] - 5s 143ms/step - loss: 0.0042\n",
            "Epoch 21/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0042\n",
            "Epoch 22/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0043\n",
            "Epoch 23/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0042\n",
            "Epoch 24/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0044\n",
            "Epoch 25/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0041\n",
            "Epoch 26/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0042\n",
            "Epoch 27/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0043\n",
            "Epoch 28/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0042\n",
            "Epoch 29/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0041\n",
            "Epoch 30/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0041\n",
            "Epoch 31/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0044\n",
            "Epoch 32/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0044\n",
            "Epoch 33/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0043\n",
            "Epoch 34/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0042\n",
            "Epoch 35/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0045\n",
            "Epoch 36/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0042\n",
            "Epoch 37/120\n",
            "37/37 [==============================] - 7s 179ms/step - loss: 0.0041\n",
            "Epoch 38/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0042\n",
            "Epoch 39/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0041\n",
            "Epoch 40/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0039\n",
            "Epoch 41/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0041\n",
            "Epoch 42/120\n",
            "37/37 [==============================] - 6s 160ms/step - loss: 0.0040\n",
            "Epoch 43/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0041\n",
            "Epoch 44/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0039\n",
            "Epoch 45/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0041\n",
            "Epoch 46/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0040\n",
            "Epoch 47/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0041\n",
            "Epoch 48/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0041\n",
            "Epoch 49/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0040\n",
            "Epoch 50/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0039\n",
            "Epoch 51/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0039\n",
            "Epoch 52/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0039\n",
            "Epoch 53/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0039\n",
            "Epoch 54/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0039\n",
            "Epoch 55/120\n",
            "37/37 [==============================] - 6s 160ms/step - loss: 0.0042\n",
            "Epoch 56/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0038\n",
            "Epoch 57/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0041\n",
            "Epoch 58/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0040\n",
            "Epoch 59/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0040\n",
            "Epoch 60/120\n",
            "37/37 [==============================] - 6s 160ms/step - loss: 0.0040\n",
            "Epoch 61/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0039\n",
            "Epoch 62/120\n",
            "37/37 [==============================] - 5s 147ms/step - loss: 0.0039\n",
            "Epoch 63/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0039\n",
            "Epoch 64/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0039\n",
            "Epoch 65/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0039\n",
            "Epoch 66/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0039\n",
            "Epoch 67/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0039\n",
            "Epoch 68/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0040\n",
            "Epoch 69/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0040\n",
            "Epoch 70/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0040\n",
            "Epoch 71/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0042\n",
            "Epoch 72/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0039\n",
            "Epoch 73/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0039\n",
            "Epoch 74/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0039\n",
            "Epoch 75/120\n",
            "37/37 [==============================] - 6s 160ms/step - loss: 0.0038\n",
            "Epoch 76/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0039\n",
            "Epoch 77/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0037\n",
            "Epoch 78/120\n",
            "37/37 [==============================] - 6s 147ms/step - loss: 0.0038\n",
            "Epoch 79/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0038\n",
            "Epoch 80/120\n",
            "37/37 [==============================] - 7s 198ms/step - loss: 0.0041\n",
            "Epoch 81/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0038\n",
            "Epoch 82/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0038\n",
            "Epoch 83/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0037\n",
            "Epoch 84/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0038\n",
            "Epoch 85/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0038\n",
            "Epoch 86/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0037\n",
            "Epoch 87/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0038\n",
            "Epoch 88/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0037\n",
            "Epoch 89/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0037\n",
            "Epoch 90/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0038\n",
            "Epoch 91/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0041\n",
            "Epoch 92/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0038\n",
            "Epoch 93/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0039\n",
            "Epoch 94/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0037\n",
            "Epoch 95/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0037\n",
            "Epoch 96/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0036\n",
            "Epoch 97/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0037\n",
            "Epoch 98/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0038\n",
            "Epoch 99/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0037\n",
            "Epoch 100/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0038\n",
            "Epoch 101/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0037\n",
            "Epoch 102/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0038\n",
            "Epoch 103/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0037\n",
            "Epoch 104/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0036\n",
            "Epoch 105/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0036\n",
            "Epoch 106/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0037\n",
            "Epoch 107/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0037\n",
            "Epoch 108/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0036\n",
            "Epoch 109/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0037\n",
            "Epoch 110/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0035\n",
            "Epoch 111/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0036\n",
            "Epoch 112/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0037\n",
            "Epoch 113/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0036\n",
            "Epoch 114/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0037\n",
            "Epoch 115/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0036\n",
            "Epoch 116/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0036\n",
            "Epoch 117/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0035\n",
            "Epoch 118/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0035\n",
            "Epoch 119/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0038\n",
            "Epoch 120/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0039\n",
            "50/50 [==============================] - 3s 21ms/step\n",
            "Epoch 1/120\n",
            "37/37 [==============================] - 22s 157ms/step - loss: 0.0137\n",
            "Epoch 2/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0063\n",
            "Epoch 3/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0056\n",
            "Epoch 4/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0055\n",
            "Epoch 5/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0065\n",
            "Epoch 6/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0051\n",
            "Epoch 7/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0051\n",
            "Epoch 8/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0052\n",
            "Epoch 9/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0049\n",
            "Epoch 10/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0047\n",
            "Epoch 11/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0047\n",
            "Epoch 12/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0047\n",
            "Epoch 13/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0044\n",
            "Epoch 14/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0045\n",
            "Epoch 15/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0046\n",
            "Epoch 16/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0046\n",
            "Epoch 17/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0045\n",
            "Epoch 18/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0044\n",
            "Epoch 19/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0048\n",
            "Epoch 20/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0044\n",
            "Epoch 21/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0043\n",
            "Epoch 22/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0046\n",
            "Epoch 23/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0042\n",
            "Epoch 24/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0041\n",
            "Epoch 25/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0042\n",
            "Epoch 26/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0041\n",
            "Epoch 27/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0043\n",
            "Epoch 28/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0046\n",
            "Epoch 29/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0042\n",
            "Epoch 30/120\n",
            "37/37 [==============================] - 7s 185ms/step - loss: 0.0042\n",
            "Epoch 31/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0042\n",
            "Epoch 32/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0041\n",
            "Epoch 33/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0041\n",
            "Epoch 34/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0041\n",
            "Epoch 35/120\n",
            "37/37 [==============================] - 5s 146ms/step - loss: 0.0045\n",
            "Epoch 36/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0040\n",
            "Epoch 37/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0039\n",
            "Epoch 38/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0042\n",
            "Epoch 39/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0042\n",
            "Epoch 40/120\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 0.0040\n",
            "Epoch 41/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0040\n",
            "Epoch 42/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0040\n",
            "Epoch 43/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0039\n",
            "Epoch 44/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0040\n",
            "Epoch 45/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0040\n",
            "Epoch 46/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0040\n",
            "Epoch 47/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0042\n",
            "Epoch 48/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0039\n",
            "Epoch 49/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0039\n",
            "Epoch 50/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0039\n",
            "Epoch 51/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0040\n",
            "Epoch 52/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0038\n",
            "Epoch 53/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0041\n",
            "Epoch 54/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0040\n",
            "Epoch 55/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0040\n",
            "Epoch 56/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0041\n",
            "Epoch 57/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0039\n",
            "Epoch 58/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0038\n",
            "Epoch 59/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0039\n",
            "Epoch 60/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0041\n",
            "Epoch 61/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0039\n",
            "Epoch 62/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0038\n",
            "Epoch 63/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0039\n",
            "Epoch 64/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0040\n",
            "Epoch 65/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0040\n",
            "Epoch 66/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0039\n",
            "Epoch 67/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0039\n",
            "Epoch 68/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0038\n",
            "Epoch 69/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0039\n",
            "Epoch 70/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0039\n",
            "Epoch 71/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0037\n",
            "Epoch 72/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0037\n",
            "Epoch 73/120\n",
            "37/37 [==============================] - 7s 188ms/step - loss: 0.0039\n",
            "Epoch 74/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0038\n",
            "Epoch 75/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0039\n",
            "Epoch 76/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0039\n",
            "Epoch 77/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0038\n",
            "Epoch 78/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0038\n",
            "Epoch 79/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0038\n",
            "Epoch 80/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0036\n",
            "Epoch 81/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0038\n",
            "Epoch 82/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0038\n",
            "Epoch 83/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0037\n",
            "Epoch 84/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0038\n",
            "Epoch 85/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0038\n",
            "Epoch 86/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0038\n",
            "Epoch 87/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0037\n",
            "Epoch 88/120\n",
            "37/37 [==============================] - 6s 160ms/step - loss: 0.0037\n",
            "Epoch 89/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0037\n",
            "Epoch 90/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0036\n",
            "Epoch 91/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0039\n",
            "Epoch 92/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0037\n",
            "Epoch 93/120\n",
            "37/37 [==============================] - 6s 160ms/step - loss: 0.0036\n",
            "Epoch 94/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0037\n",
            "Epoch 95/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0039\n",
            "Epoch 96/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0036\n",
            "Epoch 97/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0036\n",
            "Epoch 98/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0041\n",
            "Epoch 99/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0038\n",
            "Epoch 100/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0039\n",
            "Epoch 101/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0038\n",
            "Epoch 102/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0040\n",
            "Epoch 103/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0038\n",
            "Epoch 104/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0037\n",
            "Epoch 105/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0036\n",
            "Epoch 106/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0036\n",
            "Epoch 107/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0037\n",
            "Epoch 108/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0036\n",
            "Epoch 109/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0036\n",
            "Epoch 110/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0036\n",
            "Epoch 111/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0037\n",
            "Epoch 112/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0036\n",
            "Epoch 113/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0037\n",
            "Epoch 114/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0037\n",
            "Epoch 115/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0035\n",
            "Epoch 116/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0037\n",
            "Epoch 117/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0035\n",
            "Epoch 118/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0047\n",
            "Epoch 119/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0046\n",
            "Epoch 120/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0041\n",
            "50/50 [==============================] - 3s 21ms/step\n",
            "Epoch 1/120\n",
            "37/37 [==============================] - 20s 128ms/step - loss: 0.0149\n",
            "Epoch 2/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0064\n",
            "Epoch 3/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0061\n",
            "Epoch 4/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0056\n",
            "Epoch 5/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0051\n",
            "Epoch 6/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0050\n",
            "Epoch 7/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0049\n",
            "Epoch 8/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0049\n",
            "Epoch 9/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0048\n",
            "Epoch 10/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0047\n",
            "Epoch 11/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0046\n",
            "Epoch 12/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0045\n",
            "Epoch 13/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0045\n",
            "Epoch 14/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0045\n",
            "Epoch 15/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0044\n",
            "Epoch 16/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0045\n",
            "Epoch 17/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0046\n",
            "Epoch 18/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0045\n",
            "Epoch 19/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0149\n",
            "Epoch 20/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0050\n",
            "Epoch 21/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0045\n",
            "Epoch 22/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0045\n",
            "Epoch 23/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0044\n",
            "Epoch 24/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0044\n",
            "Epoch 25/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0043\n",
            "Epoch 26/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0045\n",
            "Epoch 27/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0043\n",
            "Epoch 28/120\n",
            "37/37 [==============================] - 6s 149ms/step - loss: 0.0043\n",
            "Epoch 29/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0041\n",
            "Epoch 30/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0041\n",
            "Epoch 31/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0041\n",
            "Epoch 32/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0042\n",
            "Epoch 33/120\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.0047\n",
            "Epoch 34/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0042\n",
            "Epoch 35/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0042\n",
            "Epoch 36/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0041\n",
            "Epoch 37/120\n",
            "37/37 [==============================] - 5s 143ms/step - loss: 0.0042\n",
            "Epoch 38/120\n",
            "37/37 [==============================] - 5s 146ms/step - loss: 0.0041\n",
            "Epoch 39/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0040\n",
            "Epoch 40/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0039\n",
            "Epoch 41/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0040\n",
            "Epoch 42/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0040\n",
            "Epoch 43/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0042\n",
            "Epoch 44/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0039\n",
            "Epoch 45/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0038\n",
            "Epoch 46/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0041\n",
            "Epoch 47/120\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.0041\n",
            "Epoch 48/120\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.0040\n",
            "Epoch 49/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0042\n",
            "Epoch 50/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0042\n",
            "Epoch 51/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0041\n",
            "Epoch 52/120\n",
            "37/37 [==============================] - 6s 149ms/step - loss: 0.0041\n",
            "Epoch 53/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0040\n",
            "Epoch 54/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0039\n",
            "Epoch 55/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0039\n",
            "Epoch 56/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0039\n",
            "Epoch 57/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0041\n",
            "Epoch 58/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0039\n",
            "Epoch 59/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0038\n",
            "Epoch 60/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0039\n",
            "Epoch 61/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0038\n",
            "Epoch 62/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0040\n",
            "Epoch 63/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0039\n",
            "Epoch 64/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0041\n",
            "Epoch 65/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0039\n",
            "Epoch 66/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0039\n",
            "Epoch 67/120\n",
            "37/37 [==============================] - 7s 204ms/step - loss: 0.0038\n",
            "Epoch 68/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0038\n",
            "Epoch 69/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0039\n",
            "Epoch 70/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0038\n",
            "Epoch 71/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0038\n",
            "Epoch 72/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0038\n",
            "Epoch 73/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0041\n",
            "Epoch 74/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0037\n",
            "Epoch 75/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0038\n",
            "Epoch 76/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0040\n",
            "Epoch 77/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0039\n",
            "Epoch 78/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0039\n",
            "Epoch 79/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0039\n",
            "Epoch 80/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0039\n",
            "Epoch 81/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0038\n",
            "Epoch 82/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0037\n",
            "Epoch 83/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0038\n",
            "Epoch 84/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0038\n",
            "Epoch 85/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0037\n",
            "Epoch 86/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0038\n",
            "Epoch 87/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0038\n",
            "Epoch 88/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0039\n",
            "Epoch 89/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0040\n",
            "Epoch 90/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0038\n",
            "Epoch 91/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0037\n",
            "Epoch 92/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0038\n",
            "Epoch 93/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0039\n",
            "Epoch 94/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0037\n",
            "Epoch 95/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0038\n",
            "Epoch 96/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0039\n",
            "Epoch 97/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0037\n",
            "Epoch 98/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0038\n",
            "Epoch 99/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0037\n",
            "Epoch 100/120\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 0.0036\n",
            "Epoch 101/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0037\n",
            "Epoch 102/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0038\n",
            "Epoch 103/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0036\n",
            "Epoch 104/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0036\n",
            "Epoch 105/120\n",
            "37/37 [==============================] - 6s 149ms/step - loss: 0.0038\n",
            "Epoch 106/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0036\n",
            "Epoch 107/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0037\n",
            "Epoch 108/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0040\n",
            "Epoch 109/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0036\n",
            "Epoch 110/120\n",
            "37/37 [==============================] - 7s 184ms/step - loss: 0.0038\n",
            "Epoch 111/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0037\n",
            "Epoch 112/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0037\n",
            "Epoch 113/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0036\n",
            "Epoch 114/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0036\n",
            "Epoch 115/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0035\n",
            "Epoch 116/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0036\n",
            "Epoch 117/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0037\n",
            "Epoch 118/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0037\n",
            "Epoch 119/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0038\n",
            "Epoch 120/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0036\n",
            "50/50 [==============================] - 3s 21ms/step\n",
            "Epoch 1/120\n",
            "37/37 [==============================] - 22s 131ms/step - loss: 0.0135\n",
            "Epoch 2/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0064\n",
            "Epoch 3/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0057\n",
            "Epoch 4/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0057\n",
            "Epoch 5/120\n",
            "37/37 [==============================] - 6s 166ms/step - loss: 0.0055\n",
            "Epoch 6/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0052\n",
            "Epoch 7/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0050\n",
            "Epoch 8/120\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 0.0050\n",
            "Epoch 9/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0047\n",
            "Epoch 10/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0048\n",
            "Epoch 11/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0051\n",
            "Epoch 12/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0044\n",
            "Epoch 13/120\n",
            "37/37 [==============================] - 6s 149ms/step - loss: 0.0045\n",
            "Epoch 14/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0044\n",
            "Epoch 15/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0044\n",
            "Epoch 16/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0044\n",
            "Epoch 17/120\n",
            "37/37 [==============================] - 5s 146ms/step - loss: 0.0045\n",
            "Epoch 18/120\n",
            "37/37 [==============================] - 5s 147ms/step - loss: 0.0044\n",
            "Epoch 19/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0044\n",
            "Epoch 20/120\n",
            "37/37 [==============================] - 7s 179ms/step - loss: 0.0043\n",
            "Epoch 21/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0044\n",
            "Epoch 22/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0044\n",
            "Epoch 23/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0043\n",
            "Epoch 24/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0047\n",
            "Epoch 25/120\n",
            "37/37 [==============================] - 6s 166ms/step - loss: 0.0042\n",
            "Epoch 26/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0041\n",
            "Epoch 27/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0042\n",
            "Epoch 28/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0042\n",
            "Epoch 29/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0045\n",
            "Epoch 30/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0041\n",
            "Epoch 31/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0042\n",
            "Epoch 32/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0041\n",
            "Epoch 33/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0041\n",
            "Epoch 34/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0041\n",
            "Epoch 35/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0041\n",
            "Epoch 36/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0041\n",
            "Epoch 37/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0039\n",
            "Epoch 38/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0042\n",
            "Epoch 39/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0041\n",
            "Epoch 40/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0041\n",
            "Epoch 41/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0042\n",
            "Epoch 42/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0041\n",
            "Epoch 43/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0045\n",
            "Epoch 44/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0040\n",
            "Epoch 45/120\n",
            "37/37 [==============================] - 6s 160ms/step - loss: 0.0040\n",
            "Epoch 46/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0041\n",
            "Epoch 47/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0041\n",
            "Epoch 48/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0041\n",
            "Epoch 49/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0039\n",
            "Epoch 50/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0041\n",
            "Epoch 51/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0042\n",
            "Epoch 52/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0042\n",
            "Epoch 53/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0039\n",
            "Epoch 54/120\n",
            "37/37 [==============================] - 5s 147ms/step - loss: 0.0040\n",
            "Epoch 55/120\n",
            "37/37 [==============================] - 6s 148ms/step - loss: 0.0038\n",
            "Epoch 56/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0039\n",
            "Epoch 57/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0039\n",
            "Epoch 58/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0039\n",
            "Epoch 59/120\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 0.0039\n",
            "Epoch 60/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0039\n",
            "Epoch 61/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0038\n",
            "Epoch 62/120\n",
            "37/37 [==============================] - 7s 199ms/step - loss: 0.0040\n",
            "Epoch 63/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0038\n",
            "Epoch 64/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0039\n",
            "Epoch 65/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0039\n",
            "Epoch 66/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0039\n",
            "Epoch 67/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0038\n",
            "Epoch 68/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0039\n",
            "Epoch 69/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0037\n",
            "Epoch 70/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0038\n",
            "Epoch 71/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0038\n",
            "Epoch 72/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0037\n",
            "Epoch 73/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0038\n",
            "Epoch 74/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0038\n",
            "Epoch 75/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0038\n",
            "Epoch 76/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0039\n",
            "Epoch 77/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0041\n",
            "Epoch 78/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0038\n",
            "Epoch 79/120\n",
            "37/37 [==============================] - 6s 166ms/step - loss: 0.0037\n",
            "Epoch 80/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0037\n",
            "Epoch 81/120\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.0037\n",
            "Epoch 82/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0037\n",
            "Epoch 83/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0041\n",
            "Epoch 84/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0037\n",
            "Epoch 85/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0037\n",
            "Epoch 86/120\n",
            "37/37 [==============================] - 5s 143ms/step - loss: 0.0037\n",
            "Epoch 87/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0037\n",
            "Epoch 88/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0037\n",
            "Epoch 89/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0037\n",
            "Epoch 90/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0036\n",
            "Epoch 91/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0037\n",
            "Epoch 92/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0037\n",
            "Epoch 93/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0037\n",
            "Epoch 94/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0038\n",
            "Epoch 95/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0038\n",
            "Epoch 96/120\n",
            "37/37 [==============================] - 6s 149ms/step - loss: 0.0036\n",
            "Epoch 97/120\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.0037\n",
            "Epoch 98/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0036\n",
            "Epoch 99/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0036\n",
            "Epoch 100/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0037\n",
            "Epoch 101/120\n",
            "37/37 [==============================] - 6s 149ms/step - loss: 0.0039\n",
            "Epoch 102/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0037\n",
            "Epoch 103/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0036\n",
            "Epoch 104/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0036\n",
            "Epoch 105/120\n",
            "37/37 [==============================] - 6s 167ms/step - loss: 0.0035\n",
            "Epoch 106/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0037\n",
            "Epoch 107/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0037\n",
            "Epoch 108/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0038\n",
            "Epoch 109/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0036\n",
            "Epoch 110/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0038\n",
            "Epoch 111/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0037\n",
            "Epoch 112/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0036\n",
            "Epoch 113/120\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.0035\n",
            "Epoch 114/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0035\n",
            "Epoch 115/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0037\n",
            "Epoch 116/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0039\n",
            "Epoch 117/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0035\n",
            "Epoch 118/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0035\n",
            "Epoch 119/120\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 0.0034\n",
            "Epoch 120/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0035\n",
            "50/50 [==============================] - 4s 36ms/step\n",
            "Epoch 1/120\n",
            "37/37 [==============================] - 20s 128ms/step - loss: 0.0144\n",
            "Epoch 2/120\n",
            "37/37 [==============================] - 6s 166ms/step - loss: 0.0065\n",
            "Epoch 3/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0062\n",
            "Epoch 4/120\n",
            "37/37 [==============================] - 5s 148ms/step - loss: 0.0057\n",
            "Epoch 5/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0054\n",
            "Epoch 6/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0054\n",
            "Epoch 7/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0050\n",
            "Epoch 8/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0048\n",
            "Epoch 9/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0046\n",
            "Epoch 10/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0047\n",
            "Epoch 11/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0046\n",
            "Epoch 12/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0049\n",
            "Epoch 13/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0046\n",
            "Epoch 14/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0044\n",
            "Epoch 15/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0045\n",
            "Epoch 16/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0047\n",
            "Epoch 17/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0043\n",
            "Epoch 18/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0043\n",
            "Epoch 19/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0044\n",
            "Epoch 20/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0043\n",
            "Epoch 21/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0044\n",
            "Epoch 22/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0046\n",
            "Epoch 23/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0043\n",
            "Epoch 24/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0044\n",
            "Epoch 25/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0043\n",
            "Epoch 26/120\n",
            "37/37 [==============================] - 6s 166ms/step - loss: 0.0042\n",
            "Epoch 27/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0043\n",
            "Epoch 28/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0042\n",
            "Epoch 29/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0043\n",
            "Epoch 30/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0042\n",
            "Epoch 31/120\n",
            "37/37 [==============================] - 6s 166ms/step - loss: 0.0042\n",
            "Epoch 32/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0041\n",
            "Epoch 33/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0045\n",
            "Epoch 34/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0040\n",
            "Epoch 35/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0041\n",
            "Epoch 36/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0045\n",
            "Epoch 37/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0040\n",
            "Epoch 38/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0042\n",
            "Epoch 39/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0041\n",
            "Epoch 40/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0040\n",
            "Epoch 41/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0041\n",
            "Epoch 42/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0040\n",
            "Epoch 43/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0042\n",
            "Epoch 44/120\n",
            "37/37 [==============================] - 6s 148ms/step - loss: 0.0042\n",
            "Epoch 45/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0039\n",
            "Epoch 46/120\n",
            "37/37 [==============================] - 6s 169ms/step - loss: 0.0040\n",
            "Epoch 47/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0040\n",
            "Epoch 48/120\n",
            "37/37 [==============================] - 6s 169ms/step - loss: 0.0039\n",
            "Epoch 49/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0041\n",
            "Epoch 50/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0040\n",
            "Epoch 51/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0039\n",
            "Epoch 52/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0039\n",
            "Epoch 53/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0039\n",
            "Epoch 54/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0039\n",
            "Epoch 55/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0041\n",
            "Epoch 56/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0039\n",
            "Epoch 57/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0040\n",
            "Epoch 58/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0042\n",
            "Epoch 59/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0040\n",
            "Epoch 60/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0039\n",
            "Epoch 61/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0039\n",
            "Epoch 62/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0041\n",
            "Epoch 63/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0039\n",
            "Epoch 64/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0038\n",
            "Epoch 65/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0038\n",
            "Epoch 66/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0038\n",
            "Epoch 67/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0039\n",
            "Epoch 68/120\n",
            "37/37 [==============================] - 7s 186ms/step - loss: 0.0038\n",
            "Epoch 69/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0039\n",
            "Epoch 70/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0038\n",
            "Epoch 71/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0041\n",
            "Epoch 72/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0038\n",
            "Epoch 73/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0039\n",
            "Epoch 74/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0038\n",
            "Epoch 75/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0038\n",
            "Epoch 76/120\n",
            "37/37 [==============================] - 6s 166ms/step - loss: 0.0038\n",
            "Epoch 77/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0038\n",
            "Epoch 78/120\n",
            "37/37 [==============================] - 6s 166ms/step - loss: 0.0039\n",
            "Epoch 79/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0037\n",
            "Epoch 80/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0038\n",
            "Epoch 81/120\n",
            "37/37 [==============================] - 6s 167ms/step - loss: 0.0038\n",
            "Epoch 82/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0038\n",
            "Epoch 83/120\n",
            "37/37 [==============================] - 6s 167ms/step - loss: 0.0040\n",
            "Epoch 84/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0040\n",
            "Epoch 85/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0038\n",
            "Epoch 86/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0039\n",
            "Epoch 87/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0039\n",
            "Epoch 88/120\n",
            "37/37 [==============================] - 6s 166ms/step - loss: 0.0040\n",
            "Epoch 89/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0041\n",
            "Epoch 90/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0039\n",
            "Epoch 91/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0038\n",
            "Epoch 92/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0037\n",
            "Epoch 93/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0039\n",
            "Epoch 94/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0037\n",
            "Epoch 95/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0038\n",
            "Epoch 96/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0036\n",
            "Epoch 97/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0037\n",
            "Epoch 98/120\n",
            "37/37 [==============================] - 6s 167ms/step - loss: 0.0037\n",
            "Epoch 99/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0037\n",
            "Epoch 100/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0037\n",
            "Epoch 101/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0038\n",
            "Epoch 102/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0039\n",
            "Epoch 103/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0037\n",
            "Epoch 104/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0036\n",
            "Epoch 105/120\n",
            "37/37 [==============================] - 6s 167ms/step - loss: 0.0038\n",
            "Epoch 106/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0037\n",
            "Epoch 107/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0040\n",
            "Epoch 108/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0038\n",
            "Epoch 109/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0037\n",
            "Epoch 110/120\n",
            "37/37 [==============================] - 6s 172ms/step - loss: 0.0037\n",
            "Epoch 111/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0036\n",
            "Epoch 112/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0037\n",
            "Epoch 113/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0036\n",
            "Epoch 114/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0036\n",
            "Epoch 115/120\n",
            "37/37 [==============================] - 6s 168ms/step - loss: 0.0036\n",
            "Epoch 116/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0036\n",
            "Epoch 117/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0037\n",
            "Epoch 118/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0036\n",
            "Epoch 119/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0036\n",
            "Epoch 120/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0036\n",
            "50/50 [==============================] - 3s 23ms/step\n",
            "Epoch 1/120\n",
            "37/37 [==============================] - 22s 151ms/step - loss: 0.0147\n",
            "Epoch 2/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0064\n",
            "Epoch 3/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0056\n",
            "Epoch 4/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0056\n",
            "Epoch 5/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0051\n",
            "Epoch 6/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0053\n",
            "Epoch 7/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0050\n",
            "Epoch 8/120\n",
            "37/37 [==============================] - 6s 166ms/step - loss: 0.0049\n",
            "Epoch 9/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0047\n",
            "Epoch 10/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0049\n",
            "Epoch 11/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0046\n",
            "Epoch 12/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0048\n",
            "Epoch 13/120\n",
            "37/37 [==============================] - 6s 166ms/step - loss: 0.0046\n",
            "Epoch 14/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0046\n",
            "Epoch 15/120\n",
            "37/37 [==============================] - 6s 166ms/step - loss: 0.0045\n",
            "Epoch 16/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0045\n",
            "Epoch 17/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0042\n",
            "Epoch 18/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0047\n",
            "Epoch 19/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0044\n",
            "Epoch 20/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0043\n",
            "Epoch 21/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0044\n",
            "Epoch 22/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0043\n",
            "Epoch 23/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0045\n",
            "Epoch 24/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0043\n",
            "Epoch 25/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0042\n",
            "Epoch 26/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0045\n",
            "Epoch 27/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0544\n",
            "Epoch 28/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0054\n",
            "Epoch 29/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0049\n",
            "Epoch 30/120\n",
            "37/37 [==============================] - 7s 202ms/step - loss: 0.0047\n",
            "Epoch 31/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0044\n",
            "Epoch 32/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0044\n",
            "Epoch 33/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0045\n",
            "Epoch 34/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0044\n",
            "Epoch 35/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0043\n",
            "Epoch 36/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0044\n",
            "Epoch 37/120\n",
            "37/37 [==============================] - 5s 147ms/step - loss: 0.0042\n",
            "Epoch 38/120\n",
            "37/37 [==============================] - 5s 143ms/step - loss: 0.0043\n",
            "Epoch 39/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0049\n",
            "Epoch 40/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0043\n",
            "Epoch 41/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0041\n",
            "Epoch 42/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0041\n",
            "Epoch 43/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0041\n",
            "Epoch 44/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0042\n",
            "Epoch 45/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0041\n",
            "Epoch 46/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0040\n",
            "Epoch 47/120\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 0.0040\n",
            "Epoch 48/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0042\n",
            "Epoch 49/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0040\n",
            "Epoch 50/120\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 0.0040\n",
            "Epoch 51/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0043\n",
            "Epoch 52/120\n",
            "37/37 [==============================] - 7s 181ms/step - loss: 0.0040\n",
            "Epoch 53/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0041\n",
            "Epoch 54/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0039\n",
            "Epoch 55/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0040\n",
            "Epoch 56/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0040\n",
            "Epoch 57/120\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 0.0039\n",
            "Epoch 58/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0041\n",
            "Epoch 59/120\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 0.0041\n",
            "Epoch 60/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0040\n",
            "Epoch 61/120\n",
            "37/37 [==============================] - 5s 146ms/step - loss: 0.0040\n",
            "Epoch 62/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0041\n",
            "Epoch 63/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0039\n",
            "Epoch 64/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0040\n",
            "Epoch 65/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0038\n",
            "Epoch 66/120\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 0.0038\n",
            "Epoch 67/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0040\n",
            "Epoch 68/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0039\n",
            "Epoch 69/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0039\n",
            "Epoch 70/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0040\n",
            "Epoch 71/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0039\n",
            "Epoch 72/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0041\n",
            "Epoch 73/120\n",
            "37/37 [==============================] - 7s 183ms/step - loss: 0.0041\n",
            "Epoch 74/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0038\n",
            "Epoch 75/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0038\n",
            "Epoch 76/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0041\n",
            "Epoch 77/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0038\n",
            "Epoch 78/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0038\n",
            "Epoch 79/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0039\n",
            "Epoch 80/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0039\n",
            "Epoch 81/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0038\n",
            "Epoch 82/120\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 0.0038\n",
            "Epoch 83/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0040\n",
            "Epoch 84/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0041\n",
            "Epoch 85/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0040\n",
            "Epoch 86/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0039\n",
            "Epoch 87/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0037\n",
            "Epoch 88/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0038\n",
            "Epoch 89/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0038\n",
            "Epoch 90/120\n",
            "35/37 [===========================>..] - ETA: 0s - loss: 0.0038"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-24-e17d81e7f30f>\", line 1, in <module>\n",
            "    GlobalMinimaSearch(mdl.get_weights())\n",
            "  File \"<ipython-input-23-034c438657e3>\", line 22, in GlobalMinimaSearch\n",
            "    GlobalMinimaSearch(params_2)\n",
            "  File \"<ipython-input-23-034c438657e3>\", line 22, in GlobalMinimaSearch\n",
            "    GlobalMinimaSearch(params_2)\n",
            "  File \"<ipython-input-23-034c438657e3>\", line 22, in GlobalMinimaSearch\n",
            "    GlobalMinimaSearch(params_2)\n",
            "  [Previous line repeated 6 more times]\n",
            "  File \"<ipython-input-23-034c438657e3>\", line 9, in GlobalMinimaSearch\n",
            "    model.fit(X_train, y_train, epochs=120, batch_size=128)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1409, in fit\n",
            "    tmp_logs = self.train_function(iterator)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\", line 915, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\", line 947, in _call\n",
            "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\", line 2453, in __call__\n",
            "    return graph_function._call_flat(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\", line 1860, in _call_flat\n",
            "    return self._build_call_outputs(self._inference_function.call(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\", line 497, in call\n",
            "    outputs = execute.execute(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\", line 54, in quick_execute\n",
            "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.8/inspect.py\", line 749, in getmodule\n",
            "    continue\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss)"
      ],
      "metadata": {
        "id": "MnuUdKWaqgaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e37b64e-834a-4393-e5b9-87cf68968539"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.060616088219998185, 0.05943120479275409, 0.05884901618445452, 0.060872089020045504, 0.063401862625748, 0.059261478010521895, 0.056735016898965325, 0.06015491522694189, 0.06006550520660739]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(min(loss))"
      ],
      "metadata": {
        "id": "56ykd7kawkvX",
        "outputId": "9fd5989e-772c-4578-9c2a-fbe97a80cd6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.056735016898965325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "5KwbVjdXKn01"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss)"
      ],
      "metadata": {
        "id": "O622nEj3Krt7",
        "outputId": "1d8cd40d-70ca-4c72-b801-17cbb09edacc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7feeb7183a30>]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}