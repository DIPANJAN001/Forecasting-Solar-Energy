{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DIPANJAN001/Forecasting-Solar-Energy/blob/master/final_gsm_bestresult7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzs_vH9vlX74",
        "outputId": "7e77de1f-27b9-49b6-8cbf-2e35d3e2e038"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Boruta in /usr/local/lib/python3.8/dist-packages (0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.17.1->Boruta) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.17.1->Boruta) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install Boruta\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from boruta import BorutaPy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import concatenate\n",
        "from keras import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Bidirectional\n",
        "from keras import layers\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import load_model\n",
        "from keras.layers import Input\n",
        "from sklearn.decomposition import PCA "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "lDilv4v2lz-w"
      },
      "outputs": [],
      "source": [
        "def lstm_data_transform(x_data, y_data, num_steps):\n",
        "    \"\"\" Changes data to the format for LSTM training \n",
        "for sliding window approach \"\"\"\n",
        "    # Prepare the list for the transformed data\n",
        "    X, y = list(), list()\n",
        "    # Loop of the entire data set\n",
        "    for i in range(x_data.shape[0]):\n",
        "        # compute a new (sliding window) index\n",
        "        end_ix = i + num_steps\n",
        "        # if index is larger than the size of the dataset, we stop\n",
        "        if end_ix >= x_data.shape[0]:\n",
        "            break\n",
        "        # Get a sequence of data for x\n",
        "        seq_X = x_data[i:end_ix]\n",
        "        # Get only the last element of the sequency for y\n",
        "        seq_y = y_data[end_ix]\n",
        "        # Append the list with sequencies\n",
        "        X.append(seq_X)\n",
        "        y.append(seq_y)\n",
        "    # Make final arrays\n",
        "    x_array = np.array(X)\n",
        "    y_array = np.array(y)\n",
        "    return x_array, y_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "iQt_oZP7QczL"
      },
      "outputs": [],
      "source": [
        "df=pd.read_excel(\"/content/pv_10.xlsx\")\n",
        "weather_input1=df.drop('power_normed',axis=1)\n",
        "weather_input=weather_input1.drop('time_idx',axis=1)\n",
        "solpow=df['power_normed']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoPnMw4oQQlc",
        "outputId": "df6dcfed-fc9b-4bde-d0fd-3a0842bcc2e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: \t1 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t2 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t3 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t4 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t5 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t6 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t7 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t8 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t10\n",
            "Rejected: \t23\n",
            "Iteration: \t9 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t10\n",
            "Rejected: \t23\n",
            "Iteration: \t10 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t10\n",
            "Rejected: \t23\n",
            "Iteration: \t11 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t10\n",
            "Rejected: \t23\n",
            "Iteration: \t12 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t10\n",
            "Rejected: \t23\n",
            "Iteration: \t13 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t10\n",
            "Rejected: \t23\n",
            "Iteration: \t14 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t10\n",
            "Rejected: \t23\n",
            "Iteration: \t15 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t10\n",
            "Rejected: \t23\n",
            "Iteration: \t16 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t10\n",
            "Rejected: \t23\n",
            "Iteration: \t17 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t10\n",
            "Rejected: \t23\n",
            "Iteration: \t18 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t10\n",
            "Rejected: \t23\n",
            "Iteration: \t19 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t10\n",
            "Rejected: \t23\n",
            "Iteration: \t20 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t10\n",
            "Rejected: \t23\n",
            "Iteration: \t21 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t10\n",
            "Rejected: \t23\n",
            "Iteration: \t22 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t10\n",
            "Rejected: \t23\n",
            "Iteration: \t23 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t10\n",
            "Rejected: \t23\n",
            "Iteration: \t24 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t10\n",
            "Rejected: \t23\n",
            "Iteration: \t25 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t10\n",
            "Rejected: \t23\n",
            "Iteration: \t26 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t10\n",
            "Rejected: \t23\n",
            "Iteration: \t27 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t10\n",
            "Rejected: \t23\n",
            "Iteration: \t28 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t10\n",
            "Rejected: \t23\n",
            "Iteration: \t29 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t9\n",
            "Rejected: \t23\n",
            "Iteration: \t30 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t9\n",
            "Rejected: \t23\n",
            "Iteration: \t31 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t9\n",
            "Rejected: \t23\n",
            "Iteration: \t32 / 100\n",
            "Confirmed: \t18\n",
            "Tentative: \t8\n",
            "Rejected: \t23\n",
            "Iteration: \t33 / 100\n",
            "Confirmed: \t18\n",
            "Tentative: \t8\n",
            "Rejected: \t23\n",
            "Iteration: \t34 / 100\n",
            "Confirmed: \t20\n",
            "Tentative: \t6\n",
            "Rejected: \t23\n",
            "Iteration: \t35 / 100\n",
            "Confirmed: \t20\n",
            "Tentative: \t6\n",
            "Rejected: \t23\n",
            "Iteration: \t36 / 100\n",
            "Confirmed: \t20\n",
            "Tentative: \t6\n",
            "Rejected: \t23\n",
            "Iteration: \t37 / 100\n",
            "Confirmed: \t20\n",
            "Tentative: \t5\n",
            "Rejected: \t24\n",
            "Iteration: \t38 / 100\n",
            "Confirmed: \t20\n",
            "Tentative: \t5\n",
            "Rejected: \t24\n",
            "Iteration: \t39 / 100\n",
            "Confirmed: \t20\n",
            "Tentative: \t5\n",
            "Rejected: \t24\n",
            "Iteration: \t40 / 100\n",
            "Confirmed: \t20\n",
            "Tentative: \t5\n",
            "Rejected: \t24\n",
            "Iteration: \t41 / 100\n",
            "Confirmed: \t20\n",
            "Tentative: \t5\n",
            "Rejected: \t24\n",
            "Iteration: \t42 / 100\n",
            "Confirmed: \t20\n",
            "Tentative: \t5\n",
            "Rejected: \t24\n",
            "Iteration: \t43 / 100\n",
            "Confirmed: \t20\n",
            "Tentative: \t5\n",
            "Rejected: \t24\n",
            "Iteration: \t44 / 100\n",
            "Confirmed: \t20\n",
            "Tentative: \t5\n",
            "Rejected: \t24\n",
            "Iteration: \t45 / 100\n",
            "Confirmed: \t20\n",
            "Tentative: \t5\n",
            "Rejected: \t24\n",
            "Iteration: \t46 / 100\n",
            "Confirmed: \t21\n",
            "Tentative: \t4\n",
            "Rejected: \t24\n",
            "Iteration: \t47 / 100\n",
            "Confirmed: \t21\n",
            "Tentative: \t4\n",
            "Rejected: \t24\n",
            "Iteration: \t48 / 100\n",
            "Confirmed: \t21\n",
            "Tentative: \t4\n",
            "Rejected: \t24\n",
            "Iteration: \t49 / 100\n",
            "Confirmed: \t21\n",
            "Tentative: \t4\n",
            "Rejected: \t24\n",
            "Iteration: \t50 / 100\n",
            "Confirmed: \t21\n",
            "Tentative: \t4\n",
            "Rejected: \t24\n",
            "Iteration: \t51 / 100\n",
            "Confirmed: \t21\n",
            "Tentative: \t4\n",
            "Rejected: \t24\n",
            "Iteration: \t52 / 100\n",
            "Confirmed: \t21\n",
            "Tentative: \t4\n",
            "Rejected: \t24\n",
            "Iteration: \t53 / 100\n",
            "Confirmed: \t21\n",
            "Tentative: \t4\n",
            "Rejected: \t24\n",
            "Iteration: \t54 / 100\n",
            "Confirmed: \t21\n",
            "Tentative: \t4\n",
            "Rejected: \t24\n",
            "Iteration: \t55 / 100\n",
            "Confirmed: \t21\n",
            "Tentative: \t4\n",
            "Rejected: \t24\n",
            "Iteration: \t56 / 100\n",
            "Confirmed: \t21\n",
            "Tentative: \t4\n",
            "Rejected: \t24\n",
            "Iteration: \t57 / 100\n",
            "Confirmed: \t21\n",
            "Tentative: \t4\n",
            "Rejected: \t24\n",
            "Iteration: \t58 / 100\n",
            "Confirmed: \t21\n",
            "Tentative: \t4\n",
            "Rejected: \t24\n",
            "Iteration: \t59 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t60 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t61 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t62 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t63 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t64 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t65 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t66 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t67 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t68 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t69 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t70 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t71 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t72 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t73 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t74 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t75 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t76 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t77 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t78 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t79 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t80 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t81 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t82 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t83 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t84 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t85 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t86 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t87 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t88 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t89 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t90 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t91 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t92 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t93 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t94 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t95 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t96 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t97 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t98 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "Iteration: \t99 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n",
            "\n",
            "\n",
            "BorutaPy finished running.\n",
            "\n",
            "Iteration: \t100 / 100\n",
            "Confirmed: \t22\n",
            "Tentative: \t3\n",
            "Rejected: \t24\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BorutaPy(estimator=RandomForestRegressor(max_depth=7, n_estimators=101,\n",
              "                                         random_state=RandomState(MT19937) at 0x7F75624C4D40),\n",
              "         n_estimators='auto',\n",
              "         random_state=RandomState(MT19937) at 0x7F75624C4D40, verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "rfc = RandomForestRegressor(random_state=1, n_estimators=1000, max_depth=7)\n",
        "boruta_selector = BorutaPy(rfc, n_estimators='auto', verbose=2, random_state=1)\n",
        "boruta_selector.fit(np.array(weather_input), np.array(solpow)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "u2NoSDCGUFNU"
      },
      "outputs": [],
      "source": [
        "X_important_train = boruta_selector.transform(np.array(weather_input))\n",
        "num_steps = 3\n",
        "# training set\n",
        "(x_transformed_train,\n",
        " y_transformed_train) = lstm_data_transform(X_important_train,solpow , num_steps=num_steps)\n",
        "assert x_transformed_train.shape[0] == y_transformed_train.shape[0]\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_transformed_train,y_transformed_train,test_size=0.25, random_state=42,shuffle=False)\n",
        "#X_train_,X_val,y_train_,y_val=train_test_split(X_train,y_train,test_size=0.2, random_state=42,shuffle=False)\n",
        "inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdKjqiCK5m_T",
        "outputId": "69a4749f-3ccf-4077-d32c-c85171531c6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 3, 22) dtype=float32 (created by layer 'input_3')>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "inputs1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "V27z-GjNapD4"
      },
      "outputs": [],
      "source": [
        "from keras import optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "uxD0diT8a4c2"
      },
      "outputs": [],
      "source": [
        "opt=optimizers.Adam(learning_rate=0.003)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "YM0Epc0yvWnJ"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "t0f48T0zsiAs"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "class HalvAdam(Adam):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.prev_gradients = None\n",
        "\n",
        "    @tf.function\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [math_ops.cast(x, \"float32\") for x in grads]\n",
        "\n",
        "        if self.prev_gradients is not None:\n",
        "            for i in range(len(grads)):\n",
        "                if (grads[i] * self.prev_gradients[i] < 0):\n",
        "                    self.updates[i] = self.updates[i] / 2\n",
        "\n",
        "        self.prev_gradients = grads\n",
        "        return self.updates"
      ],
      "metadata": {
        "id": "MpStRslgCRBO"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "cSM9vzEq3G3U"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "nq9ZwBIrI_qj"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "18n5dRvpuI5T"
      },
      "outputs": [],
      "source": [
        "def define_model():\n",
        "\n",
        "\n",
        "  fe2_0 = Bidirectional(LSTM(256, activation='relu',return_sequences = True))(inputs1)\n",
        "  fe2_1 = Dropout(0.6)(fe2_0)\n",
        "  fe2_2 = Bidirectional(LSTM(64, activation='relu',return_sequences = True))(fe2_1)\n",
        "  fe2_3= Dropout(0.5)(fe2_2)\n",
        "  fe2_4=Bidirectional(LSTM(4, activation='relu'))(fe2_3)\n",
        "  out2_1=Dense(1, activation='relu')(fe2_4)\n",
        "\n",
        "  fe3_0 =Bidirectional(LSTM(128, activation='relu',return_sequences = True))(inputs1)\n",
        "  fe3_1 = Dropout(0.6)(fe3_0)\n",
        "  fe3_2 = Bidirectional(LSTM(96, activation='relu',return_sequences = True))(fe3_1)\n",
        "  fe3_3= Dropout(0.5)(fe3_2)\n",
        "  fe3_4=Bidirectional(LSTM(8, activation='relu'))(fe3_3)#16\n",
        "  out3_1=Dense(1, activation='relu')(fe3_4)\n",
        " \n",
        " \n",
        "\n",
        "  output = layers.average([out2_1, out3_1])\n",
        "  #merged3 = concatenate([out2_1,out3_1], name='concat3')\n",
        "  #output = Dense(1, activation='relu')( merged3)\n",
        "  \n",
        "\n",
        "  model = Model(inputs=[inputs1], outputs=[output])\n",
        "  \n",
        " \n",
        "  return model\n",
        "mdl=define_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss=[]"
      ],
      "metadata": {
        "id": "P5UqekV1_q7F"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import clone_model"
      ],
      "metadata": {
        "id": "9zy5UX8p_zSl"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "dAICp2p5OCER"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "9iwWrmDs0z7O"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GlobalMinimaSearch(weights):\n",
        "  if len(loss)>9:\n",
        "   return\n",
        "  \n",
        "  initial_weights =weights\n",
        "  model=clone_model(mdl)\n",
        "  model.set_weights(weights)\n",
        "  model.compile(optimizer=HalvAdam(learning_rate=0.002), loss='mean_squared_error')\n",
        "  model.fit(X_train, y_train, epochs=75, batch_size=64)\n",
        "  y= model.predict(X_test)\n",
        "  loss.append(np.sqrt(mean_squared_error(y,y_test)))\n",
        "  best_weights= model.get_weights()\n",
        "\n",
        "\n",
        "  params_2 =[final_weight - (final_weight - initial_weight) for initial_weight, final_weight in zip(initial_weights, best_weights)]\n",
        "  GlobalMinimaSearch(params_2)\n",
        "  \n",
        " "
      ],
      "metadata": {
        "id": "FxpviTJb_nUR"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GlobalMinimaSearch(mdl.get_weights())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuddmGCf_1dR",
        "outputId": "aaea8078-4c25-4b92-edfb-19b072bfbaf0"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "72/72 [==============================] - 20s 79ms/step - loss: 0.0104\n",
            "Epoch 2/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0043\n",
            "Epoch 3/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0036\n",
            "Epoch 4/75\n",
            "72/72 [==============================] - 6s 78ms/step - loss: 0.0035\n",
            "Epoch 5/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0032\n",
            "Epoch 6/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0032\n",
            "Epoch 7/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0031\n",
            "Epoch 8/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0032\n",
            "Epoch 9/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0031\n",
            "Epoch 10/75\n",
            "72/72 [==============================] - 6s 78ms/step - loss: 0.0032\n",
            "Epoch 11/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0031\n",
            "Epoch 12/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0029\n",
            "Epoch 13/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0028\n",
            "Epoch 14/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0029\n",
            "Epoch 15/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0027\n",
            "Epoch 16/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0029\n",
            "Epoch 17/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0029\n",
            "Epoch 18/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0027\n",
            "Epoch 19/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0027\n",
            "Epoch 20/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0028\n",
            "Epoch 21/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0026\n",
            "Epoch 22/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0026\n",
            "Epoch 23/75\n",
            "72/72 [==============================] - 10s 134ms/step - loss: 0.0027\n",
            "Epoch 24/75\n",
            "72/72 [==============================] - 6s 87ms/step - loss: 0.0027\n",
            "Epoch 25/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0027\n",
            "Epoch 26/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0026\n",
            "Epoch 27/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0028\n",
            "Epoch 28/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0026\n",
            "Epoch 29/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0026\n",
            "Epoch 30/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0026\n",
            "Epoch 31/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0026\n",
            "Epoch 32/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0026\n",
            "Epoch 33/75\n",
            "72/72 [==============================] - 7s 95ms/step - loss: 0.0025\n",
            "Epoch 34/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0026\n",
            "Epoch 35/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0026\n",
            "Epoch 36/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0027\n",
            "Epoch 37/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0025\n",
            "Epoch 38/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0025\n",
            "Epoch 39/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0025\n",
            "Epoch 40/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0025\n",
            "Epoch 41/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0026\n",
            "Epoch 42/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0026\n",
            "Epoch 43/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0025\n",
            "Epoch 44/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0025\n",
            "Epoch 45/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0026\n",
            "Epoch 46/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0025\n",
            "Epoch 47/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0024\n",
            "Epoch 48/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0024\n",
            "Epoch 49/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0025\n",
            "Epoch 50/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0025\n",
            "Epoch 51/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0024\n",
            "Epoch 52/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0024\n",
            "Epoch 53/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0025\n",
            "Epoch 54/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0023\n",
            "Epoch 55/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0026\n",
            "Epoch 56/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0024\n",
            "Epoch 57/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0024\n",
            "Epoch 58/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0024\n",
            "Epoch 59/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0023\n",
            "Epoch 60/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0023\n",
            "Epoch 61/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0023\n",
            "Epoch 62/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0024\n",
            "Epoch 63/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0023\n",
            "Epoch 64/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0023\n",
            "Epoch 65/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0024\n",
            "Epoch 66/75\n",
            "72/72 [==============================] - 6s 78ms/step - loss: 0.0023\n",
            "Epoch 67/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0023\n",
            "Epoch 68/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0023\n",
            "Epoch 69/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0023\n",
            "Epoch 70/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0023\n",
            "Epoch 71/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0023\n",
            "Epoch 72/75\n",
            "72/72 [==============================] - 7s 96ms/step - loss: 0.0023\n",
            "Epoch 73/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0023\n",
            "Epoch 74/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0024\n",
            "Epoch 75/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0022\n",
            "48/48 [==============================] - 2s 17ms/step\n",
            "Epoch 1/75\n",
            "72/72 [==============================] - 29s 80ms/step - loss: 0.0110\n",
            "Epoch 2/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0045\n",
            "Epoch 3/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0039\n",
            "Epoch 4/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0037\n",
            "Epoch 5/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0034\n",
            "Epoch 6/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0032\n",
            "Epoch 7/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0034\n",
            "Epoch 8/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0033\n",
            "Epoch 9/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0032\n",
            "Epoch 10/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0029\n",
            "Epoch 11/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0030\n",
            "Epoch 12/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0030\n",
            "Epoch 13/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0029\n",
            "Epoch 14/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0029\n",
            "Epoch 15/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0029\n",
            "Epoch 16/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0031\n",
            "Epoch 17/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0028\n",
            "Epoch 18/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0029\n",
            "Epoch 19/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0029\n",
            "Epoch 20/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0029\n",
            "Epoch 21/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0026\n",
            "Epoch 22/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0031\n",
            "Epoch 23/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0027\n",
            "Epoch 24/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0027\n",
            "Epoch 25/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0028\n",
            "Epoch 26/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0027\n",
            "Epoch 27/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0028\n",
            "Epoch 28/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0027\n",
            "Epoch 29/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0026\n",
            "Epoch 30/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0027\n",
            "Epoch 31/75\n",
            "72/72 [==============================] - 7s 91ms/step - loss: 0.0026\n",
            "Epoch 32/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0026\n",
            "Epoch 33/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0029\n",
            "Epoch 34/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0027\n",
            "Epoch 35/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0027\n",
            "Epoch 36/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0027\n",
            "Epoch 37/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0027\n",
            "Epoch 38/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0025\n",
            "Epoch 39/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0026\n",
            "Epoch 40/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0026\n",
            "Epoch 41/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0026\n",
            "Epoch 42/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0026\n",
            "Epoch 43/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0026\n",
            "Epoch 44/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0028\n",
            "Epoch 45/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0025\n",
            "Epoch 46/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0026\n",
            "Epoch 47/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0026\n",
            "Epoch 48/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0026\n",
            "Epoch 49/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0024\n",
            "Epoch 50/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0025\n",
            "Epoch 51/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0026\n",
            "Epoch 52/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0025\n",
            "Epoch 53/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0025\n",
            "Epoch 54/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0026\n",
            "Epoch 55/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0025\n",
            "Epoch 56/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0025\n",
            "Epoch 57/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0026\n",
            "Epoch 58/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0024\n",
            "Epoch 59/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0025\n",
            "Epoch 60/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0025\n",
            "Epoch 61/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0025\n",
            "Epoch 62/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0024\n",
            "Epoch 63/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0025\n",
            "Epoch 64/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0024\n",
            "Epoch 65/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0024\n",
            "Epoch 66/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0024\n",
            "Epoch 67/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0024\n",
            "Epoch 68/75\n",
            "72/72 [==============================] - 6s 79ms/step - loss: 0.0024\n",
            "Epoch 69/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0024\n",
            "Epoch 70/75\n",
            "72/72 [==============================] - 7s 98ms/step - loss: 0.0024\n",
            "Epoch 71/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0024\n",
            "Epoch 72/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0025\n",
            "Epoch 73/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0025\n",
            "Epoch 74/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0024\n",
            "Epoch 75/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0024\n",
            "48/48 [==============================] - 3s 16ms/step\n",
            "Epoch 1/75\n",
            "72/72 [==============================] - 20s 82ms/step - loss: 0.0106\n",
            "Epoch 2/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0046\n",
            "Epoch 3/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0038\n",
            "Epoch 4/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0036\n",
            "Epoch 5/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0037\n",
            "Epoch 6/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0032\n",
            "Epoch 7/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0032\n",
            "Epoch 8/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0032\n",
            "Epoch 9/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0032\n",
            "Epoch 10/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0031\n",
            "Epoch 11/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0030\n",
            "Epoch 12/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0030\n",
            "Epoch 13/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0030\n",
            "Epoch 14/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0029\n",
            "Epoch 15/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0028\n",
            "Epoch 16/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0029\n",
            "Epoch 17/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0030\n",
            "Epoch 18/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0030\n",
            "Epoch 19/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0028\n",
            "Epoch 20/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0028\n",
            "Epoch 21/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0029\n",
            "Epoch 22/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0028\n",
            "Epoch 23/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0027\n",
            "Epoch 24/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0029\n",
            "Epoch 25/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0026\n",
            "Epoch 26/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0027\n",
            "Epoch 27/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0026\n",
            "Epoch 28/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0026\n",
            "Epoch 29/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0027\n",
            "Epoch 30/75\n",
            "72/72 [==============================] - 7s 97ms/step - loss: 0.0027\n",
            "Epoch 31/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0027\n",
            "Epoch 32/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0026\n",
            "Epoch 33/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0026\n",
            "Epoch 34/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0026\n",
            "Epoch 35/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0026\n",
            "Epoch 36/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0027\n",
            "Epoch 37/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0027\n",
            "Epoch 38/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0026\n",
            "Epoch 39/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0026\n",
            "Epoch 40/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0025\n",
            "Epoch 41/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0026\n",
            "Epoch 42/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0026\n",
            "Epoch 43/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0025\n",
            "Epoch 44/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0025\n",
            "Epoch 45/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0025\n",
            "Epoch 46/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0027\n",
            "Epoch 47/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0026\n",
            "Epoch 48/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0026\n",
            "Epoch 49/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0025\n",
            "Epoch 50/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0025\n",
            "Epoch 51/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0025\n",
            "Epoch 52/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0025\n",
            "Epoch 53/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0025\n",
            "Epoch 54/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0025\n",
            "Epoch 55/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0025\n",
            "Epoch 56/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0025\n",
            "Epoch 57/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0024\n",
            "Epoch 58/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0025\n",
            "Epoch 59/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0026\n",
            "Epoch 60/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0025\n",
            "Epoch 61/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0025\n",
            "Epoch 62/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0024\n",
            "Epoch 63/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0024\n",
            "Epoch 64/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0024\n",
            "Epoch 65/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0025\n",
            "Epoch 66/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0023\n",
            "Epoch 67/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0023\n",
            "Epoch 68/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0024\n",
            "Epoch 69/75\n",
            "72/72 [==============================] - 7s 100ms/step - loss: 0.0024\n",
            "Epoch 70/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0025\n",
            "Epoch 71/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0025\n",
            "Epoch 72/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0023\n",
            "Epoch 73/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0024\n",
            "Epoch 74/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0024\n",
            "Epoch 75/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0023\n",
            "48/48 [==============================] - 2s 16ms/step\n",
            "Epoch 1/75\n",
            "72/72 [==============================] - 20s 82ms/step - loss: 0.0095\n",
            "Epoch 2/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0042\n",
            "Epoch 3/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0042\n",
            "Epoch 4/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0034\n",
            "Epoch 5/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0033\n",
            "Epoch 6/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0034\n",
            "Epoch 7/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0032\n",
            "Epoch 8/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0031\n",
            "Epoch 9/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0030\n",
            "Epoch 10/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0030\n",
            "Epoch 11/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0029\n",
            "Epoch 12/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0030\n",
            "Epoch 13/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0029\n",
            "Epoch 14/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0031\n",
            "Epoch 15/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0029\n",
            "Epoch 16/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0028\n",
            "Epoch 17/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0029\n",
            "Epoch 18/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0028\n",
            "Epoch 19/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0028\n",
            "Epoch 20/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0028\n",
            "Epoch 21/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0027\n",
            "Epoch 22/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0028\n",
            "Epoch 23/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0028\n",
            "Epoch 24/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0027\n",
            "Epoch 25/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0027\n",
            "Epoch 26/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0027\n",
            "Epoch 27/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0027\n",
            "Epoch 28/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0026\n",
            "Epoch 29/75\n",
            "72/72 [==============================] - 7s 95ms/step - loss: 0.0027\n",
            "Epoch 30/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0026\n",
            "Epoch 31/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0028\n",
            "Epoch 32/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0027\n",
            "Epoch 33/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0026\n",
            "Epoch 34/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0026\n",
            "Epoch 35/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0027\n",
            "Epoch 36/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0026\n",
            "Epoch 37/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0026\n",
            "Epoch 38/75\n",
            "72/72 [==============================] - 6s 80ms/step - loss: 0.0026\n",
            "Epoch 39/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0026\n",
            "Epoch 40/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0025\n",
            "Epoch 41/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0026\n",
            "Epoch 42/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0025\n",
            "Epoch 43/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0026\n",
            "Epoch 44/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0025\n",
            "Epoch 45/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0025\n",
            "Epoch 46/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0025\n",
            "Epoch 47/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0024\n",
            "Epoch 48/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0025\n",
            "Epoch 49/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0026\n",
            "Epoch 50/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0024\n",
            "Epoch 51/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0024\n",
            "Epoch 52/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0024\n",
            "Epoch 53/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0024\n",
            "Epoch 54/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0024\n",
            "Epoch 55/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0024\n",
            "Epoch 56/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0024\n",
            "Epoch 57/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0024\n",
            "Epoch 58/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0025\n",
            "Epoch 59/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0024\n",
            "Epoch 60/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0023\n",
            "Epoch 61/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0024\n",
            "Epoch 62/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0025\n",
            "Epoch 63/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0024\n",
            "Epoch 64/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0024\n",
            "Epoch 65/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0024\n",
            "Epoch 66/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0024\n",
            "Epoch 67/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0026\n",
            "Epoch 68/75\n",
            "72/72 [==============================] - 6s 90ms/step - loss: 0.0024\n",
            "Epoch 69/75\n",
            "72/72 [==============================] - 6s 88ms/step - loss: 0.0024\n",
            "Epoch 70/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0023\n",
            "Epoch 71/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0023\n",
            "Epoch 72/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0024\n",
            "Epoch 73/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0024\n",
            "Epoch 74/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0024\n",
            "Epoch 75/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0024\n",
            "48/48 [==============================] - 3s 17ms/step\n",
            "Epoch 1/75\n",
            "72/72 [==============================] - 21s 81ms/step - loss: 0.0099\n",
            "Epoch 2/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0044\n",
            "Epoch 3/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0038\n",
            "Epoch 4/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0036\n",
            "Epoch 5/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0038\n",
            "Epoch 6/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0032\n",
            "Epoch 7/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0032\n",
            "Epoch 8/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0032\n",
            "Epoch 9/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0032\n",
            "Epoch 10/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0031\n",
            "Epoch 11/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0032\n",
            "Epoch 12/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0031\n",
            "Epoch 13/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0031\n",
            "Epoch 14/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0029\n",
            "Epoch 15/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0030\n",
            "Epoch 16/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0028\n",
            "Epoch 17/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0028\n",
            "Epoch 18/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0029\n",
            "Epoch 19/75\n",
            "72/72 [==============================] - 7s 100ms/step - loss: 0.0028\n",
            "Epoch 20/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0028\n",
            "Epoch 21/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0027\n",
            "Epoch 22/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0029\n",
            "Epoch 23/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0028\n",
            "Epoch 24/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0027\n",
            "Epoch 25/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0028\n",
            "Epoch 26/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0027\n",
            "Epoch 27/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0029\n",
            "Epoch 28/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0027\n",
            "Epoch 29/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0026\n",
            "Epoch 30/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0026\n",
            "Epoch 31/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0028\n",
            "Epoch 32/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0028\n",
            "Epoch 33/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0028\n",
            "Epoch 34/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0027\n",
            "Epoch 35/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0026\n",
            "Epoch 36/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0027\n",
            "Epoch 37/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0026\n",
            "Epoch 38/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0026\n",
            "Epoch 39/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0027\n",
            "Epoch 40/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0026\n",
            "Epoch 41/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0025\n",
            "Epoch 42/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0026\n",
            "Epoch 43/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0025\n",
            "Epoch 44/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0025\n",
            "Epoch 45/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0026\n",
            "Epoch 46/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0025\n",
            "Epoch 47/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0026\n",
            "Epoch 48/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0026\n",
            "Epoch 49/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0025\n",
            "Epoch 50/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0025\n",
            "Epoch 51/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0025\n",
            "Epoch 52/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0025\n",
            "Epoch 53/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0025\n",
            "Epoch 54/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0024\n",
            "Epoch 55/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0025\n",
            "Epoch 56/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0025\n",
            "Epoch 57/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0024\n",
            "Epoch 58/75\n",
            "72/72 [==============================] - 7s 97ms/step - loss: 0.0024\n",
            "Epoch 59/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0025\n",
            "Epoch 60/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0024\n",
            "Epoch 61/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0024\n",
            "Epoch 62/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0024\n",
            "Epoch 63/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0026\n",
            "Epoch 64/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0023\n",
            "Epoch 65/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0024\n",
            "Epoch 66/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0025\n",
            "Epoch 67/75\n",
            "72/72 [==============================] - 6s 88ms/step - loss: 0.0024\n",
            "Epoch 68/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0024\n",
            "Epoch 69/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0023\n",
            "Epoch 70/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0024\n",
            "Epoch 71/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0023\n",
            "Epoch 72/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0024\n",
            "Epoch 73/75\n",
            "72/72 [==============================] - 7s 94ms/step - loss: 0.0023\n",
            "Epoch 74/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0024\n",
            "Epoch 75/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0024\n",
            "48/48 [==============================] - 3s 18ms/step\n",
            "Epoch 1/75\n",
            "72/72 [==============================] - 21s 83ms/step - loss: 0.0095\n",
            "Epoch 2/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0040\n",
            "Epoch 3/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0041\n",
            "Epoch 4/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0034\n",
            "Epoch 5/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0034\n",
            "Epoch 6/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0032\n",
            "Epoch 7/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0033\n",
            "Epoch 8/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0030\n",
            "Epoch 9/75\n",
            "72/72 [==============================] - 7s 99ms/step - loss: 0.0029\n",
            "Epoch 10/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0029\n",
            "Epoch 11/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0031\n",
            "Epoch 12/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0029\n",
            "Epoch 13/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0029\n",
            "Epoch 14/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0028\n",
            "Epoch 15/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0029\n",
            "Epoch 16/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0029\n",
            "Epoch 17/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0028\n",
            "Epoch 18/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0029\n",
            "Epoch 19/75\n",
            "72/72 [==============================] - 6s 81ms/step - loss: 0.0029\n",
            "Epoch 20/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0028\n",
            "Epoch 21/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0027\n",
            "Epoch 22/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0028\n",
            "Epoch 23/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0027\n",
            "Epoch 24/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0027\n",
            "Epoch 25/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0027\n",
            "Epoch 26/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0028\n",
            "Epoch 27/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0027\n",
            "Epoch 28/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0027\n",
            "Epoch 29/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0026\n",
            "Epoch 30/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0026\n",
            "Epoch 31/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0026\n",
            "Epoch 32/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0026\n",
            "Epoch 33/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0027\n",
            "Epoch 34/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0027\n",
            "Epoch 35/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0027\n",
            "Epoch 36/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0027\n",
            "Epoch 37/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0026\n",
            "Epoch 38/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0026\n",
            "Epoch 39/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0025\n",
            "Epoch 40/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0029\n",
            "Epoch 41/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0025\n",
            "Epoch 42/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0028\n",
            "Epoch 43/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0027\n",
            "Epoch 44/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0028\n",
            "Epoch 45/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0026\n",
            "Epoch 46/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0025\n",
            "Epoch 47/75\n",
            "72/72 [==============================] - 7s 100ms/step - loss: 0.0025\n",
            "Epoch 48/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0026\n",
            "Epoch 49/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0025\n",
            "Epoch 50/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0025\n",
            "Epoch 51/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0026\n",
            "Epoch 52/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0025\n",
            "Epoch 53/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0024\n",
            "Epoch 54/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0025\n",
            "Epoch 55/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0026\n",
            "Epoch 56/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0025\n",
            "Epoch 57/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0024\n",
            "Epoch 58/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0024\n",
            "Epoch 59/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0026\n",
            "Epoch 60/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0024\n",
            "Epoch 61/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0024\n",
            "Epoch 62/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0025\n",
            "Epoch 63/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0025\n",
            "Epoch 64/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0024\n",
            "Epoch 65/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0025\n",
            "Epoch 66/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0024\n",
            "Epoch 67/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0024\n",
            "Epoch 68/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0025\n",
            "Epoch 69/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0023\n",
            "Epoch 70/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0023\n",
            "Epoch 71/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0024\n",
            "Epoch 72/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0024\n",
            "Epoch 73/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0024\n",
            "Epoch 74/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0024\n",
            "Epoch 75/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0023\n",
            "48/48 [==============================] - 3s 19ms/step\n",
            "Epoch 1/75\n",
            "72/72 [==============================] - 20s 83ms/step - loss: 0.0103\n",
            "Epoch 2/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0041\n",
            "Epoch 3/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0039\n",
            "Epoch 4/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0034\n",
            "Epoch 5/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0033\n",
            "Epoch 6/75\n",
            "72/72 [==============================] - 7s 99ms/step - loss: 0.0034\n",
            "Epoch 7/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0032\n",
            "Epoch 8/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0032\n",
            "Epoch 9/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0032\n",
            "Epoch 10/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0029\n",
            "Epoch 11/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0031\n",
            "Epoch 12/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0029\n",
            "Epoch 13/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0029\n",
            "Epoch 14/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0029\n",
            "Epoch 15/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0028\n",
            "Epoch 16/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0029\n",
            "Epoch 17/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0030\n",
            "Epoch 18/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0028\n",
            "Epoch 19/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0028\n",
            "Epoch 20/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0029\n",
            "Epoch 21/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0027\n",
            "Epoch 22/75\n",
            "72/72 [==============================] - 6s 89ms/step - loss: 0.0028\n",
            "Epoch 23/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0027\n",
            "Epoch 24/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0027\n",
            "Epoch 25/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0027\n",
            "Epoch 26/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0027\n",
            "Epoch 27/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0027\n",
            "Epoch 28/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0027\n",
            "Epoch 29/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0027\n",
            "Epoch 30/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0027\n",
            "Epoch 31/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0027\n",
            "Epoch 32/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0027\n",
            "Epoch 33/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0026\n",
            "Epoch 34/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0025\n",
            "Epoch 35/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0026\n",
            "Epoch 36/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0026\n",
            "Epoch 37/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0026\n",
            "Epoch 38/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0026\n",
            "Epoch 39/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0026\n",
            "Epoch 40/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0025\n",
            "Epoch 41/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0025\n",
            "Epoch 42/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0026\n",
            "Epoch 43/75\n",
            "72/72 [==============================] - 7s 101ms/step - loss: 0.0026\n",
            "Epoch 44/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0025\n",
            "Epoch 45/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0025\n",
            "Epoch 46/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0026\n",
            "Epoch 47/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0025\n",
            "Epoch 48/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0026\n",
            "Epoch 49/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0025\n",
            "Epoch 50/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0025\n",
            "Epoch 51/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0025\n",
            "Epoch 52/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0026\n",
            "Epoch 53/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0025\n",
            "Epoch 54/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0026\n",
            "Epoch 55/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0025\n",
            "Epoch 56/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0024\n",
            "Epoch 57/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0023\n",
            "Epoch 58/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0024\n",
            "Epoch 59/75\n",
            "72/72 [==============================] - 6s 88ms/step - loss: 0.0025\n",
            "Epoch 60/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0024\n",
            "Epoch 61/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0023\n",
            "Epoch 62/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0023\n",
            "Epoch 63/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0025\n",
            "Epoch 64/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0024\n",
            "Epoch 65/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0023\n",
            "Epoch 66/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0024\n",
            "Epoch 67/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0024\n",
            "Epoch 68/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0024\n",
            "Epoch 69/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0023\n",
            "Epoch 70/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0024\n",
            "Epoch 71/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0024\n",
            "Epoch 72/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0023\n",
            "Epoch 73/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0024\n",
            "Epoch 74/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0023\n",
            "Epoch 75/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0023\n",
            "48/48 [==============================] - 3s 19ms/step\n",
            "Epoch 1/75\n",
            "72/72 [==============================] - 21s 85ms/step - loss: 0.0106\n",
            "Epoch 2/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0043\n",
            "Epoch 3/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0036\n",
            "Epoch 4/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0036\n",
            "Epoch 5/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0037\n",
            "Epoch 6/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0032\n",
            "Epoch 7/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0033\n",
            "Epoch 8/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0034\n",
            "Epoch 9/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0031\n",
            "Epoch 10/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0030\n",
            "Epoch 11/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0030\n",
            "Epoch 12/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0029\n",
            "Epoch 13/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0029\n",
            "Epoch 14/75\n",
            "72/72 [==============================] - 6s 82ms/step - loss: 0.0028\n",
            "Epoch 15/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0029\n",
            "Epoch 16/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0029\n",
            "Epoch 17/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0029\n",
            "Epoch 18/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0028\n",
            "Epoch 19/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0027\n",
            "Epoch 20/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0028\n",
            "Epoch 21/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0027\n",
            "Epoch 22/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0027\n",
            "Epoch 23/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0028\n",
            "Epoch 24/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0027\n",
            "Epoch 25/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0026\n",
            "Epoch 26/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0026\n",
            "Epoch 27/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0026\n",
            "Epoch 28/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0026\n",
            "Epoch 29/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0027\n",
            "Epoch 30/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0027\n",
            "Epoch 31/75\n",
            "72/72 [==============================] - 7s 100ms/step - loss: 0.0026\n",
            "Epoch 32/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0026\n",
            "Epoch 33/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0026\n",
            "Epoch 34/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0027\n",
            "Epoch 35/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0025\n",
            "Epoch 36/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0025\n",
            "Epoch 37/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0026\n",
            "Epoch 38/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0026\n",
            "Epoch 39/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0026\n",
            "Epoch 40/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0026\n",
            "Epoch 41/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0025\n",
            "Epoch 42/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0026\n",
            "Epoch 43/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0025\n",
            "Epoch 44/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0026\n",
            "Epoch 45/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0025\n",
            "Epoch 46/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0026\n",
            "Epoch 47/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0025\n",
            "Epoch 48/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0024\n",
            "Epoch 49/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0026\n",
            "Epoch 50/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0025\n",
            "Epoch 51/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0025\n",
            "Epoch 52/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0024\n",
            "Epoch 53/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0025\n",
            "Epoch 54/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0024\n",
            "Epoch 55/75\n",
            "72/72 [==============================] - 6s 87ms/step - loss: 0.0024\n",
            "Epoch 56/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0024\n",
            "Epoch 57/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0024\n",
            "Epoch 58/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0025\n",
            "Epoch 59/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0024\n",
            "Epoch 60/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0024\n",
            "Epoch 61/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0024\n",
            "Epoch 62/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0024\n",
            "Epoch 63/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0025\n",
            "Epoch 64/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0023\n",
            "Epoch 65/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0023\n",
            "Epoch 66/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0024\n",
            "Epoch 67/75\n",
            "72/72 [==============================] - 7s 93ms/step - loss: 0.0024\n",
            "Epoch 68/75\n",
            "72/72 [==============================] - 7s 93ms/step - loss: 0.0023\n",
            "Epoch 69/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0092\n",
            "Epoch 70/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0033\n",
            "Epoch 71/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0027\n",
            "Epoch 72/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0025\n",
            "Epoch 73/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0026\n",
            "Epoch 74/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0025\n",
            "Epoch 75/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0024\n",
            "48/48 [==============================] - 3s 19ms/step\n",
            "Epoch 1/75\n",
            "72/72 [==============================] - 20s 84ms/step - loss: 0.0101\n",
            "Epoch 2/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0044\n",
            "Epoch 3/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0039\n",
            "Epoch 4/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0039\n",
            "Epoch 5/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0037\n",
            "Epoch 6/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0034\n",
            "Epoch 7/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0033\n",
            "Epoch 8/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0032\n",
            "Epoch 9/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0030\n",
            "Epoch 10/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0031\n",
            "Epoch 11/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0032\n",
            "Epoch 12/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0030\n",
            "Epoch 13/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0031\n",
            "Epoch 14/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0029\n",
            "Epoch 15/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0029\n",
            "Epoch 16/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0029\n",
            "Epoch 17/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0029\n",
            "Epoch 18/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0028\n",
            "Epoch 19/75\n",
            "72/72 [==============================] - 7s 102ms/step - loss: 0.0027\n",
            "Epoch 20/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0029\n",
            "Epoch 21/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0028\n",
            "Epoch 22/75\n",
            "72/72 [==============================] - 6s 83ms/step - loss: 0.0027\n",
            "Epoch 23/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0027\n",
            "Epoch 24/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0026\n",
            "Epoch 25/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0027\n",
            "Epoch 26/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0028\n",
            "Epoch 27/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0027\n",
            "Epoch 28/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0026\n",
            "Epoch 29/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0028\n",
            "Epoch 30/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0026\n",
            "Epoch 31/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0026\n",
            "Epoch 32/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0026\n",
            "Epoch 33/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0028\n",
            "Epoch 34/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0026\n",
            "Epoch 35/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0027\n",
            "Epoch 36/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0026\n",
            "Epoch 37/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0026\n",
            "Epoch 38/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0025\n",
            "Epoch 39/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0027\n",
            "Epoch 40/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0025\n",
            "Epoch 41/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0025\n",
            "Epoch 42/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0025\n",
            "Epoch 43/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0026\n",
            "Epoch 44/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0026\n",
            "Epoch 45/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0024\n",
            "Epoch 46/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0025\n",
            "Epoch 47/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0025\n",
            "Epoch 48/75\n",
            "72/72 [==============================] - 6s 89ms/step - loss: 0.0025\n",
            "Epoch 49/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0026\n",
            "Epoch 50/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0025\n",
            "Epoch 51/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0025\n",
            "Epoch 52/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0025\n",
            "Epoch 53/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0024\n",
            "Epoch 54/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0025\n",
            "Epoch 55/75\n",
            "72/72 [==============================] - 7s 102ms/step - loss: 0.0025\n",
            "Epoch 56/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0024\n",
            "Epoch 57/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0025\n",
            "Epoch 58/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0024\n",
            "Epoch 59/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0025\n",
            "Epoch 60/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0024\n",
            "Epoch 61/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0023\n",
            "Epoch 62/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0025\n",
            "Epoch 63/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0024\n",
            "Epoch 64/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0025\n",
            "Epoch 65/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0025\n",
            "Epoch 66/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0023\n",
            "Epoch 67/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0024\n",
            "Epoch 68/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0023\n",
            "Epoch 69/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0024\n",
            "Epoch 70/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0025\n",
            "Epoch 71/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0023\n",
            "Epoch 72/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0024\n",
            "Epoch 73/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0024\n",
            "Epoch 74/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0023\n",
            "Epoch 75/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0023\n",
            "48/48 [==============================] - 3s 19ms/step\n",
            "Epoch 1/75\n",
            "72/72 [==============================] - 20s 84ms/step - loss: 0.0101\n",
            "Epoch 2/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0040\n",
            "Epoch 3/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0039\n",
            "Epoch 4/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0036\n",
            "Epoch 5/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0035\n",
            "Epoch 6/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0031\n",
            "Epoch 7/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0034\n",
            "Epoch 8/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0031\n",
            "Epoch 9/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0030\n",
            "Epoch 10/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0029\n",
            "Epoch 11/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0029\n",
            "Epoch 12/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0030\n",
            "Epoch 13/75\n",
            "72/72 [==============================] - 7s 102ms/step - loss: 0.0028\n",
            "Epoch 14/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0028\n",
            "Epoch 15/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0032\n",
            "Epoch 16/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0029\n",
            "Epoch 17/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0029\n",
            "Epoch 18/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0027\n",
            "Epoch 19/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0029\n",
            "Epoch 20/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0028\n",
            "Epoch 21/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0026\n",
            "Epoch 22/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0027\n",
            "Epoch 23/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0027\n",
            "Epoch 24/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0027\n",
            "Epoch 25/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0027\n",
            "Epoch 26/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0026\n",
            "Epoch 27/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0026\n",
            "Epoch 28/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0026\n",
            "Epoch 29/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0027\n",
            "Epoch 30/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0028\n",
            "Epoch 31/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0027\n",
            "Epoch 32/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0026\n",
            "Epoch 33/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0026\n",
            "Epoch 34/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0026\n",
            "Epoch 35/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0026\n",
            "Epoch 36/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0027\n",
            "Epoch 37/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0026\n",
            "Epoch 38/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0026\n",
            "Epoch 39/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0026\n",
            "Epoch 40/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0025\n",
            "Epoch 41/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0026\n",
            "Epoch 42/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0025\n",
            "Epoch 43/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0025\n",
            "Epoch 44/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0025\n",
            "Epoch 45/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0025\n",
            "Epoch 46/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0025\n",
            "Epoch 47/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0025\n",
            "Epoch 48/75\n",
            "72/72 [==============================] - 6s 87ms/step - loss: 0.0025\n",
            "Epoch 49/75\n",
            "72/72 [==============================] - 7s 100ms/step - loss: 0.0025\n",
            "Epoch 50/75\n",
            "72/72 [==============================] - 6s 87ms/step - loss: 0.0024\n",
            "Epoch 51/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0023\n",
            "Epoch 52/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0025\n",
            "Epoch 53/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0025\n",
            "Epoch 54/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0024\n",
            "Epoch 55/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0024\n",
            "Epoch 56/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0023\n",
            "Epoch 57/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0024\n",
            "Epoch 58/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0023\n",
            "Epoch 59/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0024\n",
            "Epoch 60/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0024\n",
            "Epoch 61/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0024\n",
            "Epoch 62/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0024\n",
            "Epoch 63/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0024\n",
            "Epoch 64/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0023\n",
            "Epoch 65/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0023\n",
            "Epoch 66/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0024\n",
            "Epoch 67/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0024\n",
            "Epoch 68/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0024\n",
            "Epoch 69/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0024\n",
            "Epoch 70/75\n",
            "72/72 [==============================] - 6s 84ms/step - loss: 0.0024\n",
            "Epoch 71/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0023\n",
            "Epoch 72/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0023\n",
            "Epoch 73/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0025\n",
            "Epoch 74/75\n",
            "72/72 [==============================] - 6s 85ms/step - loss: 0.0023\n",
            "Epoch 75/75\n",
            "72/72 [==============================] - 6s 86ms/step - loss: 0.0023\n",
            "48/48 [==============================] - 3s 20ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss)"
      ],
      "metadata": {
        "id": "MnuUdKWaqgaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7737a207-66e9-4a1f-808b-7df3527d4e33"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.06779776260800986, 0.06896513359146345, 0.06802779759479717, 0.07112246441719568, 0.06679400377818481, 0.06621448902891185, 0.0660056397829108, 0.06616260641250477, 0.06941338091281565, 0.06803623453007619]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(min(loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56ykd7kawkvX",
        "outputId": "991b579a-0ea2-4c83-997c-9db9846870af"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0660056397829108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "5KwbVjdXKn01"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss)"
      ],
      "metadata": {
        "id": "O622nEj3Krt7",
        "outputId": "8271b48a-46cd-46f3-9c3c-6e9a9d7480b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f756cc52d30>]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}