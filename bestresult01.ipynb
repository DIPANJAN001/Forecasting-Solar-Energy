{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DIPANJAN001/Forecasting-Solar-Energy/blob/master/bestresult01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzs_vH9vlX74",
        "outputId": "073a9910-eb45-470e-e7bf-56b71e8604e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Boruta in /usr/local/lib/python3.8/dist-packages (0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.0.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.17.1->Boruta) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.17.1->Boruta) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install Boruta\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from boruta import BorutaPy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import concatenate\n",
        "from keras import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Bidirectional\n",
        "from keras import layers\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import load_model\n",
        "from keras.layers import Input\n",
        "from sklearn.decomposition import PCA "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "lDilv4v2lz-w"
      },
      "outputs": [],
      "source": [
        "def lstm_data_transform(x_data, y_data, num_steps):\n",
        "    \"\"\" Changes data to the format for LSTM training \n",
        "for sliding window approach \"\"\"\n",
        "    # Prepare the list for the transformed data\n",
        "    X, y = list(), list()\n",
        "    # Loop of the entire data set\n",
        "    for i in range(x_data.shape[0]):\n",
        "        # compute a new (sliding window) index\n",
        "        end_ix = i + num_steps\n",
        "        # if index is larger than the size of the dataset, we stop\n",
        "        if end_ix >= x_data.shape[0]:\n",
        "            break\n",
        "        # Get a sequence of data for x\n",
        "        seq_X = x_data[i:end_ix]\n",
        "        # Get only the last element of the sequency for y\n",
        "        seq_y = y_data[end_ix]\n",
        "        # Append the list with sequencies\n",
        "        X.append(seq_X)\n",
        "        y.append(seq_y)\n",
        "    # Make final arrays\n",
        "    x_array = np.array(X)\n",
        "    y_array = np.array(y)\n",
        "    return x_array, y_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "iQt_oZP7QczL"
      },
      "outputs": [],
      "source": [
        "df=pd.read_excel(\"/content/pv_01.xlsx\")\n",
        "weather_input1=df.drop('power_normed',axis=1)\n",
        "weather_input=weather_input1.drop('time_idx',axis=1)\n",
        "solpow=df['power_normed']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoPnMw4oQQlc",
        "outputId": "e6bb3e52-be73-49c2-ef69-9462cf94e115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: \t1 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t2 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t3 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t4 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t5 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t6 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t7 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t8 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t11\n",
            "Rejected: \t27\n",
            "Iteration: \t9 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t11\n",
            "Rejected: \t27\n",
            "Iteration: \t10 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t11\n",
            "Rejected: \t27\n",
            "Iteration: \t11 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t11\n",
            "Rejected: \t27\n",
            "Iteration: \t12 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t9\n",
            "Rejected: \t27\n",
            "Iteration: \t13 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t8\n",
            "Rejected: \t28\n",
            "Iteration: \t14 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t8\n",
            "Rejected: \t28\n",
            "Iteration: \t15 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t8\n",
            "Rejected: \t28\n",
            "Iteration: \t16 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t8\n",
            "Rejected: \t28\n",
            "Iteration: \t17 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t8\n",
            "Rejected: \t28\n",
            "Iteration: \t18 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t8\n",
            "Rejected: \t28\n",
            "Iteration: \t19 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t8\n",
            "Rejected: \t28\n",
            "Iteration: \t20 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t8\n",
            "Rejected: \t28\n",
            "Iteration: \t21 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t8\n",
            "Rejected: \t28\n",
            "Iteration: \t22 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t7\n",
            "Rejected: \t29\n",
            "Iteration: \t23 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t7\n",
            "Rejected: \t29\n",
            "Iteration: \t24 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t7\n",
            "Rejected: \t29\n",
            "Iteration: \t25 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t7\n",
            "Rejected: \t29\n",
            "Iteration: \t26 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t27 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t28 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t29 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t30 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t31 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t6\n",
            "Rejected: \t29\n",
            "Iteration: \t32 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t33 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t34 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t35 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t36 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t37 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t38 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t39 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t40 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t41 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t42 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t43 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t44 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t45 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t46 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t47 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t48 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t49 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t50 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t51 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t52 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t53 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t5\n",
            "Rejected: \t29\n",
            "Iteration: \t54 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t55 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t56 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t57 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t58 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t59 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t60 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t61 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t62 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t63 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t64 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t65 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t66 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t67 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t68 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t69 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t70 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t71 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t72 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t73 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t74 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t75 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t76 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t77 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t78 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t79 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t80 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t81 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t82 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t83 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t84 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t85 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t86 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t87 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t88 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t89 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t90 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t91 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t92 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t4\n",
            "Rejected: \t30\n",
            "Iteration: \t93 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t94 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t95 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t96 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t97 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t98 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t99 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "\n",
            "\n",
            "BorutaPy finished running.\n",
            "\n",
            "Iteration: \t100 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BorutaPy(estimator=RandomForestRegressor(max_depth=7, n_estimators=88,\n",
              "                                         random_state=RandomState(MT19937) at 0x7F95C2625D40),\n",
              "         n_estimators='auto',\n",
              "         random_state=RandomState(MT19937) at 0x7F95C2625D40, verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ],
      "source": [
        "rfc = RandomForestRegressor(random_state=1, n_estimators=1000, max_depth=7)\n",
        "boruta_selector = BorutaPy(rfc, n_estimators='auto', verbose=2, random_state=1)\n",
        "boruta_selector.fit(np.array(weather_input), np.array(solpow)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "u2NoSDCGUFNU"
      },
      "outputs": [],
      "source": [
        "X_important_train = boruta_selector.transform(np.array(weather_input))\n",
        "num_steps = 3\n",
        "# training set\n",
        "(x_transformed_train,\n",
        " y_transformed_train) = lstm_data_transform(X_important_train,solpow , num_steps=num_steps)\n",
        "assert x_transformed_train.shape[0] == y_transformed_train.shape[0]\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_transformed_train,y_transformed_train,test_size=0.25, random_state=42,shuffle=False)\n",
        "#X_train_,X_val,y_train_,y_val=train_test_split(X_train,y_train,test_size=0.2, random_state=42,shuffle=False)\n",
        "inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdKjqiCK5m_T",
        "outputId": "f8ab40a4-6305-4f9f-a3da-2513c0928a1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 3, 16) dtype=float32 (created by layer 'input_5')>"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ],
      "source": [
        "inputs1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "V27z-GjNapD4"
      },
      "outputs": [],
      "source": [
        "from keras import optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "uxD0diT8a4c2"
      },
      "outputs": [],
      "source": [
        "opt=optimizers.Adam(learning_rate=0.003)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "YM0Epc0yvWnJ"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "\n",
        "class CustomAdam(optimizers.Adam):\n",
        "    def __init__(self, new_idea_param=0.1, *args, **kwargs):\n",
        "        self.new_idea_param = new_idea_param\n",
        "        super(CustomAdam, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [K.update_add(self.iterations, 1)]\n",
        "\n",
        "        lr = self.lr\n",
        "        if self.initial_decay > 0:\n",
        "            lr *= (1. / (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n",
        "\n",
        "        t = K.cast(self.iterations, K.floatx()) + 1\n",
        "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        new_idea_t = self.new_idea_param * (K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        self.weights = [self.iterations] + ms + vs\n",
        "\n",
        "        for p, g, m, v in zip(params, grads, ms, vs):\n",
        "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
        "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
        "            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon) - new_idea_t * g\n",
        "\n",
        "            self.updates.append(K.update(m, m_t))\n",
        "            self.updates.append(K.update(v, v_t))\n",
        "            self.updates.append(K.update(p, p_t))\n",
        "        return self.updates"
      ],
      "metadata": {
        "id": "g8F6yCGl21Sz"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "\n",
        "class GradientAdam(optimizers.Adam):\n",
        "    def __init__(self, gradient_param=0.1, *args, **kwargs):\n",
        "        self.gradient_param = gradient_param\n",
        "        super(GradientAdam, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [K.update_add(self.iterations, 1)]\n",
        "\n",
        "        lr = self.lr\n",
        "        if self.initial_decay > 0:\n",
        "            lr *= (1. / (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n",
        "\n",
        "        t = K.cast(self.iterations, K.floatx()) + 1\n",
        "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        gradient_t = self.gradient_param * grads\n",
        "\n",
        "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        self.weights = [self.iterations] + ms + vs\n",
        "\n",
        "        for p, g, m, v, g_t in zip(params, grads, ms, vs, gradient_t):\n",
        "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
        "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
        "            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon) + g_t\n",
        "\n",
        "            self.updates.append(K.update(m, m_t))\n",
        "            self.updates.append(K.update(v, v_t))\n",
        "            self.updates.append(K.update(p, p_t))\n",
        "        return self.updates\n"
      ],
      "metadata": {
        "id": "J_gyZaJU8f4W"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "t0f48T0zsiAs"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "class HalvAdam(Adam):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.prev_gradients = None\n",
        "\n",
        "    @tf.function\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [math_ops.cast(x, \"float32\") for x in grads]\n",
        "\n",
        "        if self.prev_gradients is not None:\n",
        "            for i in range(len(grads)):\n",
        "                if (grads[i] * self.prev_gradients[i] < 0):\n",
        "                    self.updates[i] = self.updates[i] / 2\n",
        "\n",
        "        self.prev_gradients = grads\n",
        "        return self.updates"
      ],
      "metadata": {
        "id": "MpStRslgCRBO"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "class AdaptiveAdam(Adam):\n",
        "    def __init__(self, *args, factor=0.5, patience=5, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.wait = 0\n",
        "        self.best_loss = float('inf')\n",
        "        self.best_weights = None\n",
        "\n",
        "    @tf.function\n",
        "    def get_updates(self, loss, params):\n",
        "        current_loss = loss()\n",
        "        if current_loss < self.best_loss:\n",
        "            self.best_loss = current_loss\n",
        "            self.best_weights = params\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.wait = 0\n",
        "                self.lr = self.lr * self.factor\n",
        "                params = self.best_weights\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [math_ops.cast(g, \"float32\") for g in grads]\n",
        "        return self.updates\n"
      ],
      "metadata": {
        "id": "PmHcGR7JJLo_"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "class MomentumAdam(Adam):\n",
        "    def __init__(self, *args, momentum=0.9, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.momentum = momentum\n",
        "        self.velocities = [tf.Variable(tf.zeros_like(p), trainable=False) for p in self.weights]\n",
        "\n",
        "    @tf.function\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = []\n",
        "        for p, g, v in zip(params, grads, self.velocities):\n",
        "            v_t = self.momentum * v - self.lr * g\n",
        "            p_t = p + v_t\n",
        "            self.updates.append(p_t)\n",
        "            self.updates.append(v_t)\n",
        "        return self.updates\n"
      ],
      "metadata": {
        "id": "Zqo9SvzjbTtq"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "cSM9vzEq3G3U"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "nq9ZwBIrI_qj"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "18n5dRvpuI5T"
      },
      "outputs": [],
      "source": [
        "def define_model():\n",
        "\n",
        "\n",
        "  fe2_0 = Bidirectional(LSTM(256, activation='LeakyReLU',return_sequences = True))(inputs1)\n",
        "  fe2_1 = Dropout(0.6)(fe2_0)\n",
        "  fe2_2 = Bidirectional(LSTM(64, activation='LeakyReLU',return_sequences = True))(fe2_1)\n",
        "  fe2_3= Dropout(0.5)(fe2_2)\n",
        "  fe2_4=Bidirectional(LSTM(4, activation='LeakyReLU'))(fe2_3)\n",
        "  out2_1=Dense(1, activation='relu')(fe2_4)\n",
        "\n",
        "  fe3_0 =Bidirectional(LSTM(128, activation='LeakyReLU',return_sequences = True))(inputs1)\n",
        "  fe3_1 = Dropout(0.6)(fe3_0)\n",
        "  fe3_2 = Bidirectional(LSTM(96, activation='LeakyReLU',return_sequences = True))(fe3_1)\n",
        "  fe3_3= Dropout(0.5)(fe3_2)\n",
        "  fe3_4=Bidirectional(LSTM(8, activation='LeakyReLU'))(fe3_3)#16\n",
        "  out3_1=Dense(1, activation='relu')(fe3_4)\n",
        " \n",
        " \n",
        "\n",
        "  output = layers.average([out2_1, out3_1])\n",
        "  #merged3 = concatenate([out2_1,out3_1], name='concat3')\n",
        "  #output = Dense(1, activation='relu')( merged3)\n",
        "  \n",
        "\n",
        "  model = Model(inputs=[inputs1], outputs=[output])\n",
        "  \n",
        " \n",
        "  return model\n",
        "mdl=define_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss=[]"
      ],
      "metadata": {
        "id": "P5UqekV1_q7F"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import clone_model"
      ],
      "metadata": {
        "id": "9zy5UX8p_zSl"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "dAICp2p5OCER"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "9iwWrmDs0z7O"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GlobalMinimaSearch(weights):\n",
        "  if len(loss)>9:\n",
        "   return\n",
        "  \n",
        "  initial_weights =weights\n",
        "  model=clone_model(mdl)\n",
        "  model.set_weights(weights)\n",
        "  model.compile(optimizer=HalvAdam(learning_rate=0.003), loss='mean_squared_error')\n",
        "  model.fit(X_train, y_train, epochs=120, batch_size=128)\n",
        "  y= model.predict(X_test)\n",
        "  loss.append(np.sqrt(mean_squared_error(y,y_test)))\n",
        "  best_weights= model.get_weights()\n",
        "  \n",
        "\n",
        "     \n",
        "\n",
        "  params_1 =[final_weight + (final_weight - initial_weight) for initial_weight, final_weight in zip(initial_weights, best_weights)]\n",
        "  #GlobalMinimaSearch(params_1)\n",
        "\n",
        "\n",
        "  params_2 =[final_weight - (final_weight - initial_weight) for initial_weight, final_weight in zip(initial_weights, best_weights)]\n",
        "  GlobalMinimaSearch(params_2)\n",
        "  \n",
        " "
      ],
      "metadata": {
        "id": "FxpviTJb_nUR"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GlobalMinimaSearch(mdl.get_weights())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XuddmGCf_1dR",
        "outputId": "5b469bb2-27ef-4f25-f311-e3cb8f5a3951"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "37/37 [==============================] - 18s 142ms/step - loss: 0.0173\n",
            "Epoch 2/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0074\n",
            "Epoch 3/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0070\n",
            "Epoch 4/120\n",
            "37/37 [==============================] - 5s 149ms/step - loss: 0.0066\n",
            "Epoch 5/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0060\n",
            "Epoch 6/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0066\n",
            "Epoch 7/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0060\n",
            "Epoch 8/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0057\n",
            "Epoch 9/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0056\n",
            "Epoch 10/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0053\n",
            "Epoch 11/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0054\n",
            "Epoch 12/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0050\n",
            "Epoch 13/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0051\n",
            "Epoch 14/120\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 0.0048\n",
            "Epoch 15/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0051\n",
            "Epoch 16/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0051\n",
            "Epoch 17/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0051\n",
            "Epoch 18/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0053\n",
            "Epoch 19/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0051\n",
            "Epoch 20/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0048\n",
            "Epoch 21/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0049\n",
            "Epoch 22/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0048\n",
            "Epoch 23/120\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.0051\n",
            "Epoch 24/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0048\n",
            "Epoch 25/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0052\n",
            "Epoch 26/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0050\n",
            "Epoch 27/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0049\n",
            "Epoch 28/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0047\n",
            "Epoch 29/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0048\n",
            "Epoch 30/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0047\n",
            "Epoch 31/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0046\n",
            "Epoch 32/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0045\n",
            "Epoch 33/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0050\n",
            "Epoch 34/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0047\n",
            "Epoch 35/120\n",
            "37/37 [==============================] - 5s 143ms/step - loss: 0.0046\n",
            "Epoch 36/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0045\n",
            "Epoch 37/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0046\n",
            "Epoch 38/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0047\n",
            "Epoch 39/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0046\n",
            "Epoch 40/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0049\n",
            "Epoch 41/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0044\n",
            "Epoch 42/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0046\n",
            "Epoch 43/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0049\n",
            "Epoch 44/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0044\n",
            "Epoch 45/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0046\n",
            "Epoch 46/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0044\n",
            "Epoch 47/120\n",
            "37/37 [==============================] - 5s 146ms/step - loss: 0.0044\n",
            "Epoch 48/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0044\n",
            "Epoch 49/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0043\n",
            "Epoch 50/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0042\n",
            "Epoch 51/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0045\n",
            "Epoch 52/120\n",
            "37/37 [==============================] - 7s 184ms/step - loss: 0.0045\n",
            "Epoch 53/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0043\n",
            "Epoch 54/120\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.0043\n",
            "Epoch 55/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0043\n",
            "Epoch 56/120\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.0047\n",
            "Epoch 57/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0045\n",
            "Epoch 58/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0042\n",
            "Epoch 59/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0042\n",
            "Epoch 60/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0044\n",
            "Epoch 61/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0042\n",
            "Epoch 62/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0044\n",
            "Epoch 63/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0043\n",
            "Epoch 64/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0041\n",
            "Epoch 65/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0043\n",
            "Epoch 66/120\n",
            "37/37 [==============================] - 5s 143ms/step - loss: 0.0044\n",
            "Epoch 67/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0045\n",
            "Epoch 68/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0046\n",
            "Epoch 69/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0044\n",
            "Epoch 70/120\n",
            "37/37 [==============================] - 5s 146ms/step - loss: 0.0045\n",
            "Epoch 71/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0044\n",
            "Epoch 72/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0041\n",
            "Epoch 73/120\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.0040\n",
            "Epoch 74/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0042\n",
            "Epoch 75/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0041\n",
            "Epoch 76/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0041\n",
            "Epoch 77/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0042\n",
            "Epoch 78/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0041\n",
            "Epoch 79/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0042\n",
            "Epoch 80/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0041\n",
            "Epoch 81/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0041\n",
            "Epoch 82/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0041\n",
            "Epoch 83/120\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 0.0043\n",
            "Epoch 84/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0040\n",
            "Epoch 85/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0041\n",
            "Epoch 86/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0042\n",
            "Epoch 87/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0039\n",
            "Epoch 88/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0041\n",
            "Epoch 89/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0041\n",
            "Epoch 90/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0043\n",
            "Epoch 91/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0039\n",
            "Epoch 92/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0040\n",
            "Epoch 93/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0039\n",
            "Epoch 94/120\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.0038\n",
            "Epoch 95/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0039\n",
            "Epoch 96/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0039\n",
            "Epoch 97/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0040\n",
            "Epoch 98/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0037\n",
            "Epoch 99/120\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.0039\n",
            "Epoch 100/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0038\n",
            "Epoch 101/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0039\n",
            "Epoch 102/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0039\n",
            "Epoch 103/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0040\n",
            "Epoch 104/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0036\n",
            "Epoch 105/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0038\n",
            "Epoch 106/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0036\n",
            "Epoch 107/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0037\n",
            "Epoch 108/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0038\n",
            "Epoch 109/120\n",
            "37/37 [==============================] - 5s 143ms/step - loss: 0.0037\n",
            "Epoch 110/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0039\n",
            "Epoch 111/120\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.0039\n",
            "Epoch 112/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0038\n",
            "Epoch 113/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0041\n",
            "Epoch 114/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0039\n",
            "Epoch 115/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0037\n",
            "Epoch 116/120\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.0035\n",
            "Epoch 117/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0037\n",
            "Epoch 118/120\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.0038\n",
            "Epoch 119/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0038\n",
            "Epoch 120/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0039\n",
            "49/49 [==============================] - 3s 21ms/step\n",
            "Epoch 1/120\n",
            "37/37 [==============================] - 17s 125ms/step - loss: 0.0162\n",
            "Epoch 2/120\n",
            "37/37 [==============================] - 5s 148ms/step - loss: 0.0070\n",
            "Epoch 3/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0074\n",
            "Epoch 4/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0065\n",
            "Epoch 5/120\n",
            "37/37 [==============================] - 6s 167ms/step - loss: 0.0061\n",
            "Epoch 6/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0057\n",
            "Epoch 7/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0060\n",
            "Epoch 8/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0053\n",
            "Epoch 9/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0060\n",
            "Epoch 10/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0064\n",
            "Epoch 11/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0055\n",
            "Epoch 12/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0051\n",
            "Epoch 13/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0050\n",
            "Epoch 14/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0053\n",
            "Epoch 15/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0052\n",
            "Epoch 16/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0049\n",
            "Epoch 17/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0052\n",
            "Epoch 18/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0050\n",
            "Epoch 19/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0053\n",
            "Epoch 20/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0053\n",
            "Epoch 21/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0050\n",
            "Epoch 22/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0048\n",
            "Epoch 23/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0055\n",
            "Epoch 24/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0052\n",
            "Epoch 25/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0048\n",
            "Epoch 26/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0048\n",
            "Epoch 27/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0048\n",
            "Epoch 28/120\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.0048\n",
            "Epoch 29/120\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 0.0049\n",
            "Epoch 30/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0047\n",
            "Epoch 31/120\n",
            "37/37 [==============================] - 5s 143ms/step - loss: 0.0049\n",
            "Epoch 32/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0047\n",
            "Epoch 33/120\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.0049\n",
            "Epoch 34/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0048\n",
            "Epoch 35/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0047\n",
            "Epoch 36/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0044\n",
            "Epoch 37/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0045\n",
            "Epoch 38/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0046\n",
            "Epoch 39/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0045\n",
            "Epoch 40/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0046\n",
            "Epoch 41/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0047\n",
            "Epoch 42/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0048\n",
            "Epoch 43/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0046\n",
            "Epoch 44/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0044\n",
            "Epoch 45/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0045\n",
            "Epoch 46/120\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.0046\n",
            "Epoch 47/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0046\n",
            "Epoch 48/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0045\n",
            "Epoch 49/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0045\n",
            "Epoch 50/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0043\n",
            "Epoch 51/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0044\n",
            "Epoch 52/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0043\n",
            "Epoch 53/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0044\n",
            "Epoch 54/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0043\n",
            "Epoch 55/120\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.0041\n",
            "Epoch 56/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0044\n",
            "Epoch 57/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0049\n",
            "Epoch 58/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0045\n",
            "Epoch 59/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0044\n",
            "Epoch 60/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0044\n",
            "Epoch 61/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0041\n",
            "Epoch 62/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0043\n",
            "Epoch 63/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0041\n",
            "Epoch 64/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0041\n",
            "Epoch 65/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0043\n",
            "Epoch 66/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0043\n",
            "Epoch 67/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0042\n",
            "Epoch 68/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0041\n",
            "Epoch 69/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0043\n",
            "Epoch 70/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0043\n",
            "Epoch 71/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0042\n",
            "Epoch 72/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0042\n",
            "Epoch 73/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0041\n",
            "Epoch 74/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0041\n",
            "Epoch 75/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0042\n",
            "Epoch 76/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0042\n",
            "Epoch 77/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0041\n",
            "Epoch 78/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0040\n",
            "Epoch 79/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0041\n",
            "Epoch 80/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0039\n",
            "Epoch 81/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0039\n",
            "Epoch 82/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0040\n",
            "Epoch 83/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0041\n",
            "Epoch 84/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0040\n",
            "Epoch 85/120\n",
            "37/37 [==============================] - 7s 183ms/step - loss: 0.0040\n",
            "Epoch 86/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0040\n",
            "Epoch 87/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0044\n",
            "Epoch 88/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0041\n",
            "Epoch 89/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0040\n",
            "Epoch 90/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0038\n",
            "Epoch 91/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0040\n",
            "Epoch 92/120\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.0040\n",
            "Epoch 93/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0040\n",
            "Epoch 94/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0039\n",
            "Epoch 95/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0039\n",
            "Epoch 96/120\n",
            "37/37 [==============================] - 4s 122ms/step - loss: 0.0040\n",
            "Epoch 97/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0043\n",
            "Epoch 98/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0041\n",
            "Epoch 99/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0038\n",
            "Epoch 100/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0039\n",
            "Epoch 101/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0037\n",
            "Epoch 102/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0040\n",
            "Epoch 103/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0040\n",
            "Epoch 104/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0038\n",
            "Epoch 105/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0038\n",
            "Epoch 106/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0038\n",
            "Epoch 107/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0038\n",
            "Epoch 108/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0038\n",
            "Epoch 109/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0037\n",
            "Epoch 110/120\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 0.0037\n",
            "Epoch 111/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0037\n",
            "Epoch 112/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0039\n",
            "Epoch 113/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0038\n",
            "Epoch 114/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0038\n",
            "Epoch 115/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0039\n",
            "Epoch 116/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0039\n",
            "Epoch 117/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0038\n",
            "Epoch 118/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0037\n",
            "Epoch 119/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0036\n",
            "Epoch 120/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0035\n",
            "49/49 [==============================] - 2s 19ms/step\n",
            "Epoch 1/120\n",
            "37/37 [==============================] - 17s 122ms/step - loss: 0.0208\n",
            "Epoch 2/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0080\n",
            "Epoch 3/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0066\n",
            "Epoch 4/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0068\n",
            "Epoch 5/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0065\n",
            "Epoch 6/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0059\n",
            "Epoch 7/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0059\n",
            "Epoch 8/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0057\n",
            "Epoch 9/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0053\n",
            "Epoch 10/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0056\n",
            "Epoch 11/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0052\n",
            "Epoch 12/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0058\n",
            "Epoch 13/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0051\n",
            "Epoch 14/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0050\n",
            "Epoch 15/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0053\n",
            "Epoch 16/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0049\n",
            "Epoch 17/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0048\n",
            "Epoch 18/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0048\n",
            "Epoch 19/120\n",
            "37/37 [==============================] - 4s 122ms/step - loss: 0.0050\n",
            "Epoch 20/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0049\n",
            "Epoch 21/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0047\n",
            "Epoch 22/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0048\n",
            "Epoch 23/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0050\n",
            "Epoch 24/120\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 0.0048\n",
            "Epoch 25/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0047\n",
            "Epoch 26/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0047\n",
            "Epoch 27/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0050\n",
            "Epoch 28/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0049\n",
            "Epoch 29/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0048\n",
            "Epoch 30/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0045\n",
            "Epoch 31/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0046\n",
            "Epoch 32/120\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 0.0046\n",
            "Epoch 33/120\n",
            "37/37 [==============================] - 5s 146ms/step - loss: 0.0046\n",
            "Epoch 34/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0047\n",
            "Epoch 35/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0045\n",
            "Epoch 36/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0047\n",
            "Epoch 37/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0045\n",
            "Epoch 38/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0046\n",
            "Epoch 39/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0049\n",
            "Epoch 40/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0045\n",
            "Epoch 41/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0047\n",
            "Epoch 42/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0046\n",
            "Epoch 43/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0046\n",
            "Epoch 44/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0049\n",
            "Epoch 45/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0044\n",
            "Epoch 46/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0043\n",
            "Epoch 47/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0043\n",
            "Epoch 48/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0045\n",
            "Epoch 49/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0043\n",
            "Epoch 50/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0045\n",
            "Epoch 51/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0042\n",
            "Epoch 52/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0045\n",
            "Epoch 53/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0043\n",
            "Epoch 54/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0044\n",
            "Epoch 55/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0045\n",
            "Epoch 56/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0044\n",
            "Epoch 57/120\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.0042\n",
            "Epoch 58/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0041\n",
            "Epoch 59/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0043\n",
            "Epoch 60/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0042\n",
            "Epoch 61/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0042\n",
            "Epoch 62/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0042\n",
            "Epoch 63/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0042\n",
            "Epoch 64/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0042\n",
            "Epoch 65/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0042\n",
            "Epoch 66/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0045\n",
            "Epoch 67/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0044\n",
            "Epoch 68/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0043\n",
            "Epoch 69/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0042\n",
            "Epoch 70/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0045\n",
            "Epoch 71/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0042\n",
            "Epoch 72/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0047\n",
            "Epoch 73/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0041\n",
            "Epoch 74/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0041\n",
            "Epoch 75/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0041\n",
            "Epoch 76/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0041\n",
            "Epoch 77/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0044\n",
            "Epoch 78/120\n",
            "37/37 [==============================] - 4s 122ms/step - loss: 0.0040\n",
            "Epoch 79/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0040\n",
            "Epoch 80/120\n",
            "37/37 [==============================] - 5s 119ms/step - loss: 0.0041\n",
            "Epoch 81/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0040\n",
            "Epoch 82/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0041\n",
            "Epoch 83/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0040\n",
            "Epoch 84/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0044\n",
            "Epoch 85/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0043\n",
            "Epoch 86/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0041\n",
            "Epoch 87/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0039\n",
            "Epoch 88/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0039\n",
            "Epoch 89/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0040\n",
            "Epoch 90/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0039\n",
            "Epoch 91/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0039\n",
            "Epoch 92/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0042\n",
            "Epoch 93/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0040\n",
            "Epoch 94/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0038\n",
            "Epoch 95/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0042\n",
            "Epoch 96/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0064\n",
            "Epoch 97/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0056\n",
            "Epoch 98/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0047\n",
            "Epoch 99/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0047\n",
            "Epoch 100/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0048\n",
            "Epoch 101/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0045\n",
            "Epoch 102/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0046\n",
            "Epoch 103/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0051\n",
            "Epoch 104/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0046\n",
            "Epoch 105/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0046\n",
            "Epoch 106/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0045\n",
            "Epoch 107/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0042\n",
            "Epoch 108/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0046\n",
            "Epoch 109/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0043\n",
            "Epoch 110/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0042\n",
            "Epoch 111/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0042\n",
            "Epoch 112/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0041\n",
            "Epoch 113/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0041\n",
            "Epoch 114/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0041\n",
            "Epoch 115/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0041\n",
            "Epoch 116/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0042\n",
            "Epoch 117/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0040\n",
            "Epoch 118/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0042\n",
            "Epoch 119/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0040\n",
            "Epoch 120/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0040\n",
            "49/49 [==============================] - 2s 18ms/step\n",
            "Epoch 1/120\n",
            "37/37 [==============================] - 16s 135ms/step - loss: 0.0162\n",
            "Epoch 2/120\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0075\n",
            "Epoch 3/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0067\n",
            "Epoch 4/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0063\n",
            "Epoch 5/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0064\n",
            "Epoch 6/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0056\n",
            "Epoch 7/120\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0060\n",
            "Epoch 8/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0056\n",
            "Epoch 9/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0053\n",
            "Epoch 10/120\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0053\n",
            "Epoch 11/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0054\n",
            "Epoch 12/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0051\n",
            "Epoch 13/120\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0052\n",
            "Epoch 14/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0051\n",
            "Epoch 15/120\n",
            "37/37 [==============================] - 4s 113ms/step - loss: 0.0054\n",
            "Epoch 16/120\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0054\n",
            "Epoch 17/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0058\n",
            "Epoch 18/120\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0054\n",
            "Epoch 19/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0050\n",
            "Epoch 20/120\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0050\n",
            "Epoch 21/120\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0047\n",
            "Epoch 22/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0049\n",
            "Epoch 23/120\n",
            "37/37 [==============================] - 4s 113ms/step - loss: 0.0051\n",
            "Epoch 24/120\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0052\n",
            "Epoch 25/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0049\n",
            "Epoch 26/120\n",
            "37/37 [==============================] - 4s 113ms/step - loss: 0.0046\n",
            "Epoch 27/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0048\n",
            "Epoch 28/120\n",
            "37/37 [==============================] - 4s 112ms/step - loss: 0.0046\n",
            "Epoch 29/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0052\n",
            "Epoch 30/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0049\n",
            "Epoch 31/120\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0047\n",
            "Epoch 32/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0048\n",
            "Epoch 33/120\n",
            "37/37 [==============================] - 4s 117ms/step - loss: 0.0046\n",
            "Epoch 34/120\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0045\n",
            "Epoch 35/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0045\n",
            "Epoch 36/120\n",
            "37/37 [==============================] - 4s 117ms/step - loss: 0.0046\n",
            "Epoch 37/120\n",
            "37/37 [==============================] - 4s 117ms/step - loss: 0.0046\n",
            "Epoch 38/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0044\n",
            "Epoch 39/120\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0044\n",
            "Epoch 40/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0047\n",
            "Epoch 41/120\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0045\n",
            "Epoch 42/120\n",
            "37/37 [==============================] - 4s 112ms/step - loss: 0.0044\n",
            "Epoch 43/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0045\n",
            "Epoch 44/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0053\n",
            "Epoch 45/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0043\n",
            "Epoch 46/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0044\n",
            "Epoch 47/120\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0049\n",
            "Epoch 48/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0045\n",
            "Epoch 49/120\n",
            "37/37 [==============================] - 4s 113ms/step - loss: 0.0044\n",
            "Epoch 50/120\n",
            "37/37 [==============================] - 4s 113ms/step - loss: 0.0044\n",
            "Epoch 51/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0045\n",
            "Epoch 52/120\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0042\n",
            "Epoch 53/120\n",
            "37/37 [==============================] - 6s 173ms/step - loss: 0.0045\n",
            "Epoch 54/120\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0046\n",
            "Epoch 55/120\n",
            "37/37 [==============================] - 4s 113ms/step - loss: 0.0042\n",
            "Epoch 56/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0045\n",
            "Epoch 57/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0047\n",
            "Epoch 58/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0043\n",
            "Epoch 59/120\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0042\n",
            "Epoch 60/120\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0043\n",
            "Epoch 61/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0043\n",
            "Epoch 62/120\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0042\n",
            "Epoch 63/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0041\n",
            "Epoch 64/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0041\n",
            "Epoch 65/120\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0043\n",
            "Epoch 66/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0043\n",
            "Epoch 67/120\n",
            "37/37 [==============================] - 4s 113ms/step - loss: 0.0043\n",
            "Epoch 68/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0044\n",
            "Epoch 69/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0041\n",
            "Epoch 70/120\n",
            "37/37 [==============================] - 4s 112ms/step - loss: 0.0040\n",
            "Epoch 71/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0044\n",
            "Epoch 72/120\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0041\n",
            "Epoch 73/120\n",
            "37/37 [==============================] - 4s 117ms/step - loss: 0.0044\n",
            "Epoch 74/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0044\n",
            "Epoch 75/120\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0040\n",
            "Epoch 76/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0041\n",
            "Epoch 77/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0043\n",
            "Epoch 78/120\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0040\n",
            "Epoch 79/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0042\n",
            "Epoch 80/120\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0041\n",
            "Epoch 81/120\n",
            "37/37 [==============================] - 4s 112ms/step - loss: 0.0040\n",
            "Epoch 82/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0042\n",
            "Epoch 83/120\n",
            "37/37 [==============================] - 4s 113ms/step - loss: 0.0044\n",
            "Epoch 84/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0040\n",
            "Epoch 85/120\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0038\n",
            "Epoch 86/120\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0038\n",
            "Epoch 87/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0039\n",
            "Epoch 88/120\n",
            "37/37 [==============================] - 4s 117ms/step - loss: 0.0042\n",
            "Epoch 89/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0041\n",
            "Epoch 90/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0039\n",
            "Epoch 91/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0040\n",
            "Epoch 92/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0038\n",
            "Epoch 93/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0038\n",
            "Epoch 94/120\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0039\n",
            "Epoch 95/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0038\n",
            "Epoch 96/120\n",
            "37/37 [==============================] - 4s 117ms/step - loss: 0.0039\n",
            "Epoch 97/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0039\n",
            "Epoch 98/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0038\n",
            "Epoch 99/120\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0039\n",
            "Epoch 100/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0038\n",
            "Epoch 101/120\n",
            "37/37 [==============================] - 4s 117ms/step - loss: 0.0039\n",
            "Epoch 102/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0037\n",
            "Epoch 103/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0037\n",
            "Epoch 104/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0037\n",
            "Epoch 105/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0037\n",
            "Epoch 106/120\n",
            "37/37 [==============================] - 4s 117ms/step - loss: 0.0036\n",
            "Epoch 107/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0039\n",
            "Epoch 108/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0040\n",
            "Epoch 109/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0043\n",
            "Epoch 110/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0041\n",
            "Epoch 111/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0037\n",
            "Epoch 112/120\n",
            "37/37 [==============================] - 4s 117ms/step - loss: 0.0037\n",
            "Epoch 113/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0038\n",
            "Epoch 114/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0036\n",
            "Epoch 115/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0037\n",
            "Epoch 116/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0037\n",
            "Epoch 117/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0035\n",
            "Epoch 118/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0037\n",
            "Epoch 119/120\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0035\n",
            "Epoch 120/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0037\n",
            "49/49 [==============================] - 2s 17ms/step\n",
            "Epoch 1/120\n",
            "37/37 [==============================] - 16s 107ms/step - loss: 0.0191\n",
            "Epoch 2/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0076\n",
            "Epoch 3/120\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0065\n",
            "Epoch 4/120\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0059\n",
            "Epoch 5/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0057\n",
            "Epoch 6/120\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0058\n",
            "Epoch 7/120\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0058\n",
            "Epoch 8/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0056\n",
            "Epoch 9/120\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0058\n",
            "Epoch 10/120\n",
            "37/37 [==============================] - 4s 111ms/step - loss: 0.0058\n",
            "Epoch 11/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0052\n",
            "Epoch 12/120\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0050\n",
            "Epoch 13/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0054\n",
            "Epoch 14/120\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.0050\n",
            "Epoch 15/120\n",
            "37/37 [==============================] - 5s 148ms/step - loss: 0.0051\n",
            "Epoch 16/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0051\n",
            "Epoch 17/120\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0049\n",
            "Epoch 18/120\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0049\n",
            "Epoch 19/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0049\n",
            "Epoch 20/120\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0051\n",
            "Epoch 21/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0052\n",
            "Epoch 22/120\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0052\n",
            "Epoch 23/120\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0048\n",
            "Epoch 24/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0049\n",
            "Epoch 25/120\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0049\n",
            "Epoch 26/120\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0048\n",
            "Epoch 27/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0048\n",
            "Epoch 28/120\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0046\n",
            "Epoch 29/120\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0046\n",
            "Epoch 30/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0045\n",
            "Epoch 31/120\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0046\n",
            "Epoch 32/120\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0048\n",
            "Epoch 33/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0046\n",
            "Epoch 34/120\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0048\n",
            "Epoch 35/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0047\n",
            "Epoch 36/120\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0046\n",
            "Epoch 37/120\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0045\n",
            "Epoch 38/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0047\n",
            "Epoch 39/120\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0044\n",
            "Epoch 40/120\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0045\n",
            "Epoch 41/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0046\n",
            "Epoch 42/120\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0046\n",
            "Epoch 43/120\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0044\n",
            "Epoch 44/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0046\n",
            "Epoch 45/120\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0043\n",
            "Epoch 46/120\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0050\n",
            "Epoch 47/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0046\n",
            "Epoch 48/120\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0053\n",
            "Epoch 49/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0051\n",
            "Epoch 50/120\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0047\n",
            "Epoch 51/120\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0045\n",
            "Epoch 52/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0044\n",
            "Epoch 53/120\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0048\n",
            "Epoch 54/120\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0045\n",
            "Epoch 55/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0045\n",
            "Epoch 56/120\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.0045\n",
            "Epoch 57/120\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0046\n",
            "Epoch 58/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0044\n",
            "Epoch 59/120\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0045\n",
            "Epoch 60/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0050\n",
            "Epoch 61/120\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0047\n",
            "Epoch 62/120\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0045\n",
            "Epoch 63/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0044\n",
            "Epoch 64/120\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0046\n",
            "Epoch 65/120\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0043\n",
            "Epoch 66/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0043\n",
            "Epoch 67/120\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0044\n",
            "Epoch 68/120\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.0044\n",
            "Epoch 69/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0042\n",
            "Epoch 70/120\n",
            "37/37 [==============================] - 4s 110ms/step - loss: 0.0041\n",
            "Epoch 71/120\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0044\n",
            "Epoch 72/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0048\n",
            "Epoch 73/120\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0043\n",
            "Epoch 74/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0044\n",
            "Epoch 75/120\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.0044\n",
            "Epoch 76/120\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.0044\n",
            "Epoch 77/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0042\n",
            "Epoch 78/120\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0041\n",
            "Epoch 79/120\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.0041\n",
            "Epoch 80/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0056\n",
            "Epoch 81/120\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.0048\n",
            "Epoch 82/120\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0046\n",
            "Epoch 83/120\n",
            "37/37 [==============================] - 4s 117ms/step - loss: 0.0043\n",
            "Epoch 84/120\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0043\n",
            "Epoch 85/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0044\n",
            "Epoch 86/120\n",
            "37/37 [==============================] - 4s 110ms/step - loss: 0.0043\n",
            "Epoch 87/120\n",
            "37/37 [==============================] - 4s 111ms/step - loss: 0.0042\n",
            "Epoch 88/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0049\n",
            "Epoch 89/120\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.0043\n",
            "Epoch 90/120\n",
            "37/37 [==============================] - 4s 110ms/step - loss: 0.0043\n",
            "Epoch 91/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0042\n",
            "Epoch 92/120\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.0044\n",
            "Epoch 93/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0044\n",
            "Epoch 94/120\n",
            "37/37 [==============================] - 4s 111ms/step - loss: 0.0042\n",
            "Epoch 95/120\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0041\n",
            "Epoch 96/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0044\n",
            "Epoch 97/120\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0042\n",
            "Epoch 98/120\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0040\n",
            "Epoch 99/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0042\n",
            "Epoch 100/120\n",
            "37/37 [==============================] - 4s 112ms/step - loss: 0.0041\n",
            "Epoch 101/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0042\n",
            "Epoch 102/120\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0040\n",
            "Epoch 103/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0039\n",
            "Epoch 104/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0039\n",
            "Epoch 105/120\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0041\n",
            "Epoch 106/120\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0038\n",
            "Epoch 107/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0038\n",
            "Epoch 108/120\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0039\n",
            "Epoch 109/120\n",
            "37/37 [==============================] - 4s 112ms/step - loss: 0.0039\n",
            "Epoch 110/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0039\n",
            "Epoch 111/120\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0040\n",
            "Epoch 112/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0039\n",
            "Epoch 113/120\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0040\n",
            "Epoch 114/120\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0038\n",
            "Epoch 115/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0040\n",
            "Epoch 116/120\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0039\n",
            "Epoch 117/120\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0040\n",
            "Epoch 118/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0041\n",
            "Epoch 119/120\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0041\n",
            "Epoch 120/120\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0040\n",
            "49/49 [==============================] - 2s 17ms/step\n",
            "Epoch 1/120\n",
            "37/37 [==============================] - 15s 107ms/step - loss: 0.0159\n",
            "Epoch 2/120\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0073\n",
            "Epoch 3/120\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0068\n",
            "Epoch 4/120\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0062\n",
            "Epoch 5/120\n",
            "37/37 [==============================] - 4s 113ms/step - loss: 0.0061\n",
            "Epoch 6/120\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.0059\n",
            "Epoch 7/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0056\n",
            "Epoch 8/120\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0058\n",
            "Epoch 9/120\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0055\n",
            "Epoch 10/120\n",
            "37/37 [==============================] - 4s 112ms/step - loss: 0.0053\n",
            "Epoch 11/120\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0052\n",
            "Epoch 12/120\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.0051\n",
            "Epoch 13/120\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0059\n",
            "Epoch 14/120\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0052\n",
            "Epoch 15/120\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0050\n",
            "Epoch 16/120\n",
            "37/37 [==============================] - 4s 113ms/step - loss: 0.0051\n",
            "Epoch 17/120\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0049\n",
            "Epoch 18/120\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.0050\n",
            "Epoch 19/120\n",
            "37/37 [==============================] - 4s 112ms/step - loss: 0.0050\n",
            "Epoch 20/120\n",
            "37/37 [==============================] - 4s 109ms/step - loss: 0.0051\n",
            "Epoch 21/120\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.0049\n",
            "Epoch 22/120\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0050\n",
            "Epoch 23/120\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0049\n",
            "Epoch 24/120\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0046\n",
            "Epoch 25/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0049\n",
            "Epoch 26/120\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0048\n",
            "Epoch 27/120\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0048\n",
            "Epoch 28/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0046\n",
            "Epoch 29/120\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0049\n",
            "Epoch 30/120\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0047\n",
            "Epoch 31/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0049\n",
            "Epoch 32/120\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0047\n",
            "Epoch 33/120\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0052\n",
            "Epoch 34/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0049\n",
            "Epoch 35/120\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.0047\n",
            "Epoch 36/120\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.0045\n",
            "Epoch 37/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0045\n",
            "Epoch 38/120\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.0045\n",
            "Epoch 39/120\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0045\n",
            "Epoch 40/120\n",
            "37/37 [==============================] - 4s 122ms/step - loss: 0.0045\n",
            "Epoch 41/120\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0045\n",
            "Epoch 42/120\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0046\n",
            "Epoch 43/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0049\n",
            "Epoch 44/120\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0047\n",
            "Epoch 45/120\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.0128\n",
            "Epoch 46/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0057\n",
            "Epoch 47/120\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0052\n",
            "Epoch 48/120\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0051\n",
            "Epoch 49/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0046\n",
            "Epoch 50/120\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0048\n",
            "Epoch 51/120\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.0046\n",
            "Epoch 52/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0046\n",
            "Epoch 53/120\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.0052\n",
            "Epoch 54/120\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.0047\n",
            "Epoch 55/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0045\n",
            "Epoch 56/120\n",
            "37/37 [==============================] - 5s 147ms/step - loss: 0.0047\n",
            "Epoch 57/120\n",
            "37/37 [==============================] - 4s 110ms/step - loss: 0.0046\n",
            "Epoch 58/120\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0046\n",
            "Epoch 59/120\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0047\n",
            "Epoch 60/120\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0045\n",
            "Epoch 61/120\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0049\n",
            "Epoch 62/120\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0045\n",
            "Epoch 63/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0047\n",
            "Epoch 64/120\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0046\n",
            "Epoch 65/120\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0044\n",
            "Epoch 66/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0045\n",
            "Epoch 67/120\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0045\n",
            "Epoch 68/120\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.0042\n",
            "Epoch 69/120\n",
            "37/37 [==============================] - 4s 122ms/step - loss: 0.0043\n",
            "Epoch 70/120\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.0043\n",
            "Epoch 71/120\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0043\n",
            "Epoch 72/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0042\n",
            "Epoch 73/120\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0043\n",
            "Epoch 74/120\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0042\n",
            "Epoch 75/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0044\n",
            "Epoch 76/120\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0042\n",
            "Epoch 77/120\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0044\n",
            "Epoch 78/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0043\n",
            "Epoch 79/120\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0044\n",
            "Epoch 80/120\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0041\n",
            "Epoch 81/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0041\n",
            "Epoch 82/120\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0042\n",
            "Epoch 83/120\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0043\n",
            "Epoch 84/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0045\n",
            "Epoch 85/120\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0043\n",
            "Epoch 86/120\n",
            "37/37 [==============================] - 4s 110ms/step - loss: 0.0042\n",
            "Epoch 87/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0043\n",
            "Epoch 88/120\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0044\n",
            "Epoch 89/120\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0042\n",
            "Epoch 90/120\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 0.0041\n",
            "Epoch 91/120\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0042\n",
            "Epoch 92/120\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0039\n",
            "Epoch 93/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0039\n",
            "Epoch 94/120\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0040\n",
            "Epoch 95/120\n",
            "37/37 [==============================] - 4s 112ms/step - loss: 0.0040\n",
            "Epoch 96/120\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0041\n",
            "Epoch 97/120\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0039\n",
            "Epoch 98/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0042\n",
            "Epoch 99/120\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0040\n",
            "Epoch 100/120\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0039\n",
            "Epoch 101/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0038\n",
            "Epoch 102/120\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0040\n",
            "Epoch 103/120\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0038\n",
            "Epoch 104/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0039\n",
            "Epoch 105/120\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0040\n",
            "Epoch 106/120\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0040\n",
            "Epoch 107/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0039\n",
            "Epoch 108/120\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0039\n",
            "Epoch 109/120\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0038\n",
            "Epoch 110/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0038\n",
            "Epoch 111/120\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0039\n",
            "Epoch 112/120\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0038\n",
            "Epoch 113/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0039\n",
            "Epoch 114/120\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0038\n",
            "Epoch 115/120\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.0043\n",
            "Epoch 116/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0039\n",
            "Epoch 117/120\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.0040\n",
            "Epoch 118/120\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0039\n",
            "Epoch 119/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0038\n",
            "Epoch 120/120\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0038\n",
            "49/49 [==============================] - 2s 14ms/step\n",
            "Epoch 1/120\n",
            "37/37 [==============================] - 17s 96ms/step - loss: 0.0172\n",
            "Epoch 2/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0068\n",
            "Epoch 3/120\n",
            "37/37 [==============================] - 3s 94ms/step - loss: 0.0067\n",
            "Epoch 4/120\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0067\n",
            "Epoch 5/120\n",
            "37/37 [==============================] - 4s 117ms/step - loss: 0.0057\n",
            "Epoch 6/120\n",
            "37/37 [==============================] - 3s 94ms/step - loss: 0.0060\n",
            "Epoch 7/120\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0055\n",
            "Epoch 8/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0060\n",
            "Epoch 9/120\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0056\n",
            "Epoch 10/120\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0055\n",
            "Epoch 11/120\n",
            "37/37 [==============================] - 4s 113ms/step - loss: 0.0050\n",
            "Epoch 12/120\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.0051\n",
            "Epoch 13/120\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0056\n",
            "Epoch 14/120\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0057\n",
            "Epoch 15/120\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0052\n",
            "Epoch 16/120\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0050\n",
            "Epoch 17/120\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0051\n",
            "Epoch 18/120\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0052\n",
            "Epoch 19/120\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.0051\n",
            "Epoch 20/120\n",
            "37/37 [==============================] - 3s 94ms/step - loss: 0.0052\n",
            "Epoch 21/120\n",
            "37/37 [==============================] - 4s 117ms/step - loss: 0.0049\n",
            "Epoch 22/120\n",
            "37/37 [==============================] - 3s 94ms/step - loss: 0.0047\n",
            "Epoch 23/120\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0049\n",
            "Epoch 24/120\n",
            "37/37 [==============================] - 4s 117ms/step - loss: 0.0050\n",
            "Epoch 25/120\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0048\n",
            "Epoch 26/120\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0047\n",
            "Epoch 27/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0044\n",
            "Epoch 28/120\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0046\n",
            "Epoch 29/120\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.0049\n",
            "Epoch 30/120\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0047\n",
            "Epoch 31/120\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0048\n",
            "Epoch 32/120\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.0046\n",
            "Epoch 33/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0046\n",
            "Epoch 34/120\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.0045\n",
            "Epoch 35/120\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0045\n",
            "Epoch 36/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0050\n",
            "Epoch 37/120\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0045\n",
            "Epoch 38/120\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0045\n",
            "Epoch 39/120\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 0.0045\n",
            "Epoch 40/120\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0049\n",
            "Epoch 41/120\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.0046\n",
            "Epoch 42/120\n",
            "37/37 [==============================] - 4s 107ms/step - loss: 0.0044\n",
            "Epoch 43/120\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0045\n",
            "Epoch 44/120\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0044\n",
            "Epoch 45/120\n",
            "37/37 [==============================] - 4s 103ms/step - loss: 0.0045\n",
            "Epoch 46/120\n",
            "37/37 [==============================] - 4s 110ms/step - loss: 0.0044\n",
            "Epoch 47/120\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0046\n",
            "Epoch 48/120\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0045\n",
            "Epoch 49/120\n",
            "37/37 [==============================] - 4s 117ms/step - loss: 0.0044\n",
            "Epoch 50/120\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0044\n",
            "Epoch 51/120\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0045\n",
            "Epoch 52/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0043\n",
            "Epoch 53/120\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0044\n",
            "Epoch 54/120\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.0044\n",
            "Epoch 55/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0042\n",
            "Epoch 56/120\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0046\n",
            "Epoch 57/120\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.0046\n",
            "Epoch 58/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0043\n",
            "Epoch 59/120\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.0044\n",
            "Epoch 60/120\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0044\n",
            "Epoch 61/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0045\n",
            "Epoch 62/120\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.0042\n",
            "Epoch 63/120\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0046\n",
            "Epoch 64/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0042\n",
            "Epoch 65/120\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.0046\n",
            "Epoch 66/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0043\n",
            "Epoch 67/120\n",
            "37/37 [==============================] - 4s 117ms/step - loss: 0.0041\n",
            "Epoch 68/120\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0041\n",
            "Epoch 69/120\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0042\n",
            "Epoch 70/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0041\n",
            "Epoch 71/120\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.0042\n",
            "Epoch 72/120\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.0043\n",
            "Epoch 73/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0042\n",
            "Epoch 74/120\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.0042\n",
            "Epoch 75/120\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.0041\n",
            "Epoch 76/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0043\n",
            "Epoch 77/120\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0063\n",
            "Epoch 78/120\n",
            "37/37 [==============================] - 3s 94ms/step - loss: 0.0052\n",
            "Epoch 79/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0048\n",
            "Epoch 80/120\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0048\n",
            "Epoch 81/120\n",
            "37/37 [==============================] - 3s 94ms/step - loss: 0.0045\n",
            "Epoch 82/120\n",
            "37/37 [==============================] - 4s 114ms/step - loss: 0.0045\n",
            "Epoch 83/120\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0045\n",
            "Epoch 84/120\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.0046\n",
            "Epoch 85/120\n",
            "37/37 [==============================] - 4s 105ms/step - loss: 0.0043\n",
            "Epoch 86/120\n",
            "37/37 [==============================] - 4s 110ms/step - loss: 0.0043\n",
            "Epoch 87/120\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0041\n",
            "Epoch 88/120\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0043\n",
            "Epoch 89/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0044\n",
            "Epoch 90/120\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 0.0042\n",
            "Epoch 91/120\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0045\n",
            "Epoch 92/120\n",
            "37/37 [==============================] - 4s 113ms/step - loss: 0.0042\n",
            "Epoch 93/120\n",
            "37/37 [==============================] - 4s 102ms/step - loss: 0.0042\n",
            "Epoch 94/120\n",
            "37/37 [==============================] - 4s 111ms/step - loss: 0.0044\n",
            "Epoch 95/120\n",
            "37/37 [==============================] - 4s 108ms/step - loss: 0.0043\n",
            "Epoch 96/120\n",
            "37/37 [==============================] - 4s 100ms/step - loss: 0.0044\n",
            "Epoch 97/120\n",
            "37/37 [==============================] - 4s 110ms/step - loss: 0.0041\n",
            "Epoch 98/120\n",
            "37/37 [==============================] - 4s 106ms/step - loss: 0.0040\n",
            "Epoch 99/120\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.0041\n",
            "Epoch 100/120\n",
            "37/37 [==============================] - 4s 104ms/step - loss: 0.0041\n",
            "Epoch 101/120\n",
            "37/37 [==============================] - 4s 111ms/step - loss: 0.0041\n",
            "Epoch 102/120\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.0040\n",
            "Epoch 103/120\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.0041\n",
            "Epoch 104/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0040\n",
            "Epoch 105/120\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0044\n",
            "Epoch 106/120\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.0041\n",
            "Epoch 107/120\n",
            "37/37 [==============================] - 4s 117ms/step - loss: 0.0038\n",
            "Epoch 108/120\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0039\n",
            "Epoch 109/120\n",
            "37/37 [==============================] - 4s 99ms/step - loss: 0.0039\n",
            "Epoch 110/120\n",
            "37/37 [==============================] - 4s 117ms/step - loss: 0.0042\n",
            "Epoch 111/120\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0040\n",
            "Epoch 112/120\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.0038\n",
            "Epoch 113/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0039\n",
            "Epoch 114/120\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0037\n",
            "Epoch 115/120\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 0.0039\n",
            "Epoch 116/120\n",
            "37/37 [==============================] - 4s 117ms/step - loss: 0.0039\n",
            "Epoch 117/120\n",
            "37/37 [==============================] - 4s 97ms/step - loss: 0.0042\n",
            "Epoch 118/120\n",
            "37/37 [==============================] - 4s 95ms/step - loss: 0.0038\n",
            "Epoch 119/120\n",
            "37/37 [==============================] - 4s 116ms/step - loss: 0.0038\n",
            "Epoch 120/120\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 0.0039\n",
            "49/49 [==============================] - 2s 14ms/step\n",
            "Epoch 1/120\n",
            "34/37 [==========================>...] - ETA: 0s - loss: 0.0195"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-187-e17d81e7f30f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGlobalMinimaSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-186-034c438657e3>\u001b[0m in \u001b[0;36mGlobalMinimaSearch\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mparams_2\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_weight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mGlobalMinimaSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-186-034c438657e3>\u001b[0m in \u001b[0;36mGlobalMinimaSearch\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mparams_2\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_weight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mGlobalMinimaSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-186-034c438657e3>\u001b[0m in \u001b[0;36mGlobalMinimaSearch\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mparams_2\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_weight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mGlobalMinimaSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-186-034c438657e3>\u001b[0m in \u001b[0;36mGlobalMinimaSearch\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mparams_2\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_weight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mGlobalMinimaSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-186-034c438657e3>\u001b[0m in \u001b[0;36mGlobalMinimaSearch\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mparams_2\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_weight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mGlobalMinimaSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-186-034c438657e3>\u001b[0m in \u001b[0;36mGlobalMinimaSearch\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mparams_2\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_weight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mGlobalMinimaSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-186-034c438657e3>\u001b[0m in \u001b[0;36mGlobalMinimaSearch\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mparams_2\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_weight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mGlobalMinimaSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-186-034c438657e3>\u001b[0m in \u001b[0;36mGlobalMinimaSearch\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHalvAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.003\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss)"
      ],
      "metadata": {
        "id": "MnuUdKWaqgaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08c54175-9428-435f-93c7-2ef0755f56d1"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.06743544844303341, 0.06947108734392891, 0.06572805656478348, 0.06892891732962513, 0.06523562678330531, 0.06733486771788652, 0.06561655372375998]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(min(loss))"
      ],
      "metadata": {
        "id": "56ykd7kawkvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "5KwbVjdXKn01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss)"
      ],
      "metadata": {
        "id": "O622nEj3Krt7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}