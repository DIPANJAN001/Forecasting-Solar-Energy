{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DIPANJAN001/Forecasting-Solar-Energy/blob/master/bestresult08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzs_vH9vlX74",
        "outputId": "65a39d95-6b2b-45bd-9222-f7a822efb9d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Boruta in /usr/local/lib/python3.8/dist-packages (0.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.8/dist-packages (from Boruta) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.17.1->Boruta) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.17.1->Boruta) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install Boruta\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from boruta import BorutaPy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import concatenate\n",
        "from keras import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Bidirectional\n",
        "from keras import layers\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import load_model\n",
        "from keras.layers import Input\n",
        "from sklearn.decomposition import PCA "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "lDilv4v2lz-w"
      },
      "outputs": [],
      "source": [
        "def lstm_data_transform(x_data, y_data, num_steps):\n",
        "    \"\"\" Changes data to the format for LSTM training \n",
        "for sliding window approach \"\"\"\n",
        "    # Prepare the list for the transformed data\n",
        "    X, y = list(), list()\n",
        "    # Loop of the entire data set\n",
        "    for i in range(x_data.shape[0]):\n",
        "        # compute a new (sliding window) index\n",
        "        end_ix = i + num_steps\n",
        "        # if index is larger than the size of the dataset, we stop\n",
        "        if end_ix >= x_data.shape[0]:\n",
        "            break\n",
        "        # Get a sequence of data for x\n",
        "        seq_X = x_data[i:end_ix]\n",
        "        # Get only the last element of the sequency for y\n",
        "        seq_y = y_data[end_ix]\n",
        "        # Append the list with sequencies\n",
        "        X.append(seq_X)\n",
        "        y.append(seq_y)\n",
        "    # Make final arrays\n",
        "    x_array = np.array(X)\n",
        "    y_array = np.array(y)\n",
        "    return x_array, y_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "iQt_oZP7QczL"
      },
      "outputs": [],
      "source": [
        "df=pd.read_excel(\"/content/pv_08.xlsx\")\n",
        "weather_input1=df.drop('power_normed',axis=1)\n",
        "weather_input=weather_input1.drop('time_idx',axis=1)\n",
        "solpow=df['power_normed']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoPnMw4oQQlc",
        "outputId": "875486e4-7d23-4174-d9f4-4a349ce199a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: \t1 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t2 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t3 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t4 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t5 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t6 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t7 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t8 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t15\n",
            "Rejected: \t26\n",
            "Iteration: \t9 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t15\n",
            "Rejected: \t26\n",
            "Iteration: \t10 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t15\n",
            "Rejected: \t26\n",
            "Iteration: \t11 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t15\n",
            "Rejected: \t26\n",
            "Iteration: \t12 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t10\n",
            "Rejected: \t31\n",
            "Iteration: \t13 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t10\n",
            "Rejected: \t31\n",
            "Iteration: \t14 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t10\n",
            "Rejected: \t31\n",
            "Iteration: \t15 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t10\n",
            "Rejected: \t31\n",
            "Iteration: \t16 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t9\n",
            "Rejected: \t32\n",
            "Iteration: \t17 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t9\n",
            "Rejected: \t32\n",
            "Iteration: \t18 / 100\n",
            "Confirmed: \t8\n",
            "Tentative: \t9\n",
            "Rejected: \t32\n",
            "Iteration: \t19 / 100\n",
            "Confirmed: \t9\n",
            "Tentative: \t7\n",
            "Rejected: \t33\n",
            "Iteration: \t20 / 100\n",
            "Confirmed: \t9\n",
            "Tentative: \t7\n",
            "Rejected: \t33\n",
            "Iteration: \t21 / 100\n",
            "Confirmed: \t9\n",
            "Tentative: \t7\n",
            "Rejected: \t33\n",
            "Iteration: \t22 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t33\n",
            "Iteration: \t23 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t33\n",
            "Iteration: \t24 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t33\n",
            "Iteration: \t25 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t33\n",
            "Iteration: \t26 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t33\n",
            "Iteration: \t27 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t33\n",
            "Iteration: \t28 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t33\n",
            "Iteration: \t29 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t33\n",
            "Iteration: \t30 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t33\n",
            "Iteration: \t31 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t33\n",
            "Iteration: \t32 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t33\n",
            "Iteration: \t33 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t33\n",
            "Iteration: \t34 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t35 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t36 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t37 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t38 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t39 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t40 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t41 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t42 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t43 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t44 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t45 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t46 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t47 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t48 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t49 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t50 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t51 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t52 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t53 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t54 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t55 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t56 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t57 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t58 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t5\n",
            "Rejected: \t33\n",
            "Iteration: \t59 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t60 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t61 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t62 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t63 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t64 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t65 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t66 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t67 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t68 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t69 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t70 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t71 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t72 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t73 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t74 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t75 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t76 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t77 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t78 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t79 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t80 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t81 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t82 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t83 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t84 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t85 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t86 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t87 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t88 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t89 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t90 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t91 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t92 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t93 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t94 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t95 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t96 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t97 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t98 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "Iteration: \t99 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t4\n",
            "Rejected: \t33\n",
            "\n",
            "\n",
            "BorutaPy finished running.\n",
            "\n",
            "Iteration: \t100 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t3\n",
            "Rejected: \t33\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BorutaPy(estimator=RandomForestRegressor(max_depth=7, n_estimators=80,\n",
              "                                         random_state=RandomState(MT19937) at 0x7F2F0D69F840),\n",
              "         n_estimators='auto',\n",
              "         random_state=RandomState(MT19937) at 0x7F2F0D69F840, verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "rfc = RandomForestRegressor(random_state=1, n_estimators=1000, max_depth=7)\n",
        "boruta_selector = BorutaPy(rfc, n_estimators='auto', verbose=2, random_state=1)\n",
        "boruta_selector.fit(np.array(weather_input), np.array(solpow)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "u2NoSDCGUFNU"
      },
      "outputs": [],
      "source": [
        "X_important_train = boruta_selector.transform(np.array(weather_input))\n",
        "num_steps = 3\n",
        "# training set\n",
        "(x_transformed_train,\n",
        " y_transformed_train) = lstm_data_transform(X_important_train,solpow , num_steps=num_steps)\n",
        "assert x_transformed_train.shape[0] == y_transformed_train.shape[0]\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_transformed_train,y_transformed_train,test_size=0.25, random_state=42,shuffle=False)\n",
        "#X_train_,X_val,y_train_,y_val=train_test_split(X_train,y_train,test_size=0.2, random_state=42,shuffle=False)\n",
        "inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdKjqiCK5m_T",
        "outputId": "52f92f38-ba2c-4319-ea17-ddfe843a9f25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 3, 12) dtype=float32 (created by layer 'input_2')>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "inputs1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "V27z-GjNapD4"
      },
      "outputs": [],
      "source": [
        "from keras import optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "uxD0diT8a4c2"
      },
      "outputs": [],
      "source": [
        "opt=optimizers.Adam(learning_rate=0.003)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "YM0Epc0yvWnJ"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "\n",
        "class CustomAdam(optimizers.Adam):\n",
        "    def __init__(self, new_idea_param=0.1, *args, **kwargs):\n",
        "        self.new_idea_param = new_idea_param\n",
        "        super(CustomAdam, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [K.update_add(self.iterations, 1)]\n",
        "\n",
        "        lr = self.lr\n",
        "        if self.initial_decay > 0:\n",
        "            lr *= (1. / (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n",
        "\n",
        "        t = K.cast(self.iterations, K.floatx()) + 1\n",
        "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        new_idea_t = self.new_idea_param * (K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        self.weights = [self.iterations] + ms + vs\n",
        "\n",
        "        for p, g, m, v in zip(params, grads, ms, vs):\n",
        "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
        "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
        "            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon) - new_idea_t * g\n",
        "\n",
        "            self.updates.append(K.update(m, m_t))\n",
        "            self.updates.append(K.update(v, v_t))\n",
        "            self.updates.append(K.update(p, p_t))\n",
        "        return self.updates"
      ],
      "metadata": {
        "id": "g8F6yCGl21Sz"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "\n",
        "class GradientAdam(optimizers.Adam):\n",
        "    def __init__(self, gradient_param=0.1, *args, **kwargs):\n",
        "        self.gradient_param = gradient_param\n",
        "        super(GradientAdam, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [K.update_add(self.iterations, 1)]\n",
        "\n",
        "        lr = self.lr\n",
        "        if self.initial_decay > 0:\n",
        "            lr *= (1. / (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n",
        "\n",
        "        t = K.cast(self.iterations, K.floatx()) + 1\n",
        "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        gradient_t = self.gradient_param * grads\n",
        "\n",
        "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        self.weights = [self.iterations] + ms + vs\n",
        "\n",
        "        for p, g, m, v, g_t in zip(params, grads, ms, vs, gradient_t):\n",
        "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
        "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
        "            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon) + g_t\n",
        "\n",
        "            self.updates.append(K.update(m, m_t))\n",
        "            self.updates.append(K.update(v, v_t))\n",
        "            self.updates.append(K.update(p, p_t))\n",
        "        return self.updates\n"
      ],
      "metadata": {
        "id": "J_gyZaJU8f4W"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "t0f48T0zsiAs"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "class HalvAdam(Adam):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.prev_gradients = None\n",
        "\n",
        "    @tf.function\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [math_ops.cast(x, \"float32\") for x in grads]\n",
        "\n",
        "        if self.prev_gradients is not None:\n",
        "            for i in range(len(grads)):\n",
        "                if (grads[i] * self.prev_gradients[i] < 0):\n",
        "                    self.updates[i] = self.updates[i] / 2\n",
        "\n",
        "        self.prev_gradients = grads\n",
        "        return self.updates"
      ],
      "metadata": {
        "id": "MpStRslgCRBO"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "class AdaptiveAdam(Adam):\n",
        "    def __init__(self, *args, factor=0.5, patience=5, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.wait = 0\n",
        "        self.best_loss = float('inf')\n",
        "        self.best_weights = None\n",
        "\n",
        "    @tf.function\n",
        "    def get_updates(self, loss, params):\n",
        "        current_loss = loss()\n",
        "        if current_loss < self.best_loss:\n",
        "            self.best_loss = current_loss\n",
        "            self.best_weights = params\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.wait = 0\n",
        "                self.lr = self.lr * self.factor\n",
        "                params = self.best_weights\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [math_ops.cast(g, \"float32\") for g in grads]\n",
        "        return self.updates\n"
      ],
      "metadata": {
        "id": "PmHcGR7JJLo_"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "class MomentumAdam(Adam):\n",
        "    def __init__(self, *args, momentum=0.9, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.momentum = momentum\n",
        "        self.velocities = [tf.Variable(tf.zeros_like(p), trainable=False) for p in self.weights]\n",
        "\n",
        "    @tf.function\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = []\n",
        "        for p, g, v in zip(params, grads, self.velocities):\n",
        "            v_t = self.momentum * v - self.lr * g\n",
        "            p_t = p + v_t\n",
        "            self.updates.append(p_t)\n",
        "            self.updates.append(v_t)\n",
        "        return self.updates\n"
      ],
      "metadata": {
        "id": "Zqo9SvzjbTtq"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "cSM9vzEq3G3U"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "nq9ZwBIrI_qj"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "18n5dRvpuI5T"
      },
      "outputs": [],
      "source": [
        "def define_model():\n",
        "\n",
        "\n",
        "  fe2_0 = Bidirectional(LSTM(256, activation='LeakyReLU',return_sequences = True))(inputs1)\n",
        "  fe2_1 = Dropout(0.6)(fe2_0)\n",
        "  fe2_2 = Bidirectional(LSTM(64, activation='LeakyReLU',return_sequences = True))(fe2_1)\n",
        "  fe2_3= Dropout(0.5)(fe2_2)\n",
        "  fe2_4=Bidirectional(LSTM(4, activation='LeakyReLU'))(fe2_3)\n",
        "  out2_1=Dense(1, activation='relu')(fe2_4)\n",
        "\n",
        "  fe3_0 =Bidirectional(LSTM(128, activation='LeakyReLU',return_sequences = True))(inputs1)\n",
        "  fe3_1 = Dropout(0.6)(fe3_0)\n",
        "  fe3_2 = Bidirectional(LSTM(96, activation='LeakyReLU',return_sequences = True))(fe3_1)\n",
        "  fe3_3= Dropout(0.5)(fe3_2)\n",
        "  fe3_4=Bidirectional(LSTM(8, activation='LeakyReLU'))(fe3_3)#16\n",
        "  out3_1=Dense(1, activation='relu')(fe3_4)\n",
        " \n",
        " \n",
        "\n",
        "  output = layers.average([out2_1, out3_1])\n",
        "  #merged3 = concatenate([out2_1,out3_1], name='concat3')\n",
        "  #output = Dense(1, activation='relu')( merged3)\n",
        "  \n",
        "\n",
        "  model = Model(inputs=[inputs1], outputs=[output])\n",
        "  \n",
        " \n",
        "  return model\n",
        "mdl=define_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss=[]"
      ],
      "metadata": {
        "id": "P5UqekV1_q7F"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import clone_model"
      ],
      "metadata": {
        "id": "9zy5UX8p_zSl"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "dAICp2p5OCER"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "9iwWrmDs0z7O"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GlobalMinimaSearch(weights):\n",
        "  if len(loss)>9:\n",
        "   return\n",
        "  \n",
        "  initial_weights =weights\n",
        "  model=clone_model(mdl)\n",
        "  model.set_weights(weights)\n",
        "  model.compile(optimizer=HalvAdam(learning_rate=0.003), loss='mean_squared_error')\n",
        "  model.fit(X_train, y_train, epochs=120, batch_size=128)\n",
        "  y= model.predict(X_test)\n",
        "  loss.append(np.sqrt(mean_squared_error(y,y_test)))\n",
        "  best_weights= model.get_weights()\n",
        "  \n",
        "\n",
        "     \n",
        "\n",
        "  params_1 =[final_weight + (final_weight - initial_weight) for initial_weight, final_weight in zip(initial_weights, best_weights)]\n",
        "  #GlobalMinimaSearch(params_1)\n",
        "\n",
        "\n",
        "  params_2 =[final_weight - (final_weight - initial_weight) for initial_weight, final_weight in zip(initial_weights, best_weights)]\n",
        "  GlobalMinimaSearch(params_2)\n",
        "  \n",
        " "
      ],
      "metadata": {
        "id": "FxpviTJb_nUR"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GlobalMinimaSearch(mdl.get_weights())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XuddmGCf_1dR",
        "outputId": "20f091ac-fc2e-4ad5-88d4-20f7c4bb5184"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "37/37 [==============================] - 21s 160ms/step - loss: 0.0389\n",
            "Epoch 2/120\n",
            "37/37 [==============================] - 7s 194ms/step - loss: 0.0145\n",
            "Epoch 3/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0113\n",
            "Epoch 4/120\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 0.0105\n",
            "Epoch 5/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0105\n",
            "Epoch 6/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0096\n",
            "Epoch 7/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0094\n",
            "Epoch 8/120\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.0090\n",
            "Epoch 9/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0089\n",
            "Epoch 10/120\n",
            "37/37 [==============================] - 5s 143ms/step - loss: 0.0090\n",
            "Epoch 11/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0089\n",
            "Epoch 12/120\n",
            "37/37 [==============================] - 6s 168ms/step - loss: 0.0096\n",
            "Epoch 13/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0085\n",
            "Epoch 14/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0084\n",
            "Epoch 15/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0090\n",
            "Epoch 16/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0085\n",
            "Epoch 17/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0088\n",
            "Epoch 18/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0083\n",
            "Epoch 19/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0084\n",
            "Epoch 20/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0081\n",
            "Epoch 21/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0086\n",
            "Epoch 22/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0082\n",
            "Epoch 23/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0081\n",
            "Epoch 24/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0083\n",
            "Epoch 25/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0081\n",
            "Epoch 26/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0079\n",
            "Epoch 27/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0083\n",
            "Epoch 28/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0079\n",
            "Epoch 29/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0083\n",
            "Epoch 30/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0081\n",
            "Epoch 31/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0081\n",
            "Epoch 32/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0078\n",
            "Epoch 33/120\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.0080\n",
            "Epoch 34/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0080\n",
            "Epoch 35/120\n",
            "37/37 [==============================] - 6s 147ms/step - loss: 0.0078\n",
            "Epoch 36/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0076\n",
            "Epoch 37/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0078\n",
            "Epoch 38/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0079\n",
            "Epoch 39/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0078\n",
            "Epoch 40/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0079\n",
            "Epoch 41/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0077\n",
            "Epoch 42/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0074\n",
            "Epoch 43/120\n",
            "37/37 [==============================] - 7s 181ms/step - loss: 0.0078\n",
            "Epoch 44/120\n",
            "37/37 [==============================] - 6s 172ms/step - loss: 0.0075\n",
            "Epoch 45/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0078\n",
            "Epoch 46/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0076\n",
            "Epoch 47/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0075\n",
            "Epoch 48/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0075\n",
            "Epoch 49/120\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.0075\n",
            "Epoch 50/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0077\n",
            "Epoch 51/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0077\n",
            "Epoch 52/120\n",
            "37/37 [==============================] - 6s 160ms/step - loss: 0.0074\n",
            "Epoch 53/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0076\n",
            "Epoch 54/120\n",
            "37/37 [==============================] - 7s 197ms/step - loss: 0.0079\n",
            "Epoch 55/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0074\n",
            "Epoch 56/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0074\n",
            "Epoch 57/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0074\n",
            "Epoch 58/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0076\n",
            "Epoch 59/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0076\n",
            "Epoch 60/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0077\n",
            "Epoch 61/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0075\n",
            "Epoch 62/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0074\n",
            "Epoch 63/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0075\n",
            "Epoch 64/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0073\n",
            "Epoch 65/120\n",
            "37/37 [==============================] - 7s 182ms/step - loss: 0.0076\n",
            "Epoch 66/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0076\n",
            "Epoch 67/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0076\n",
            "Epoch 68/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0072\n",
            "Epoch 69/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0076\n",
            "Epoch 70/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0074\n",
            "Epoch 71/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0077\n",
            "Epoch 72/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0073\n",
            "Epoch 73/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0075\n",
            "Epoch 74/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0074\n",
            "Epoch 75/120\n",
            "37/37 [==============================] - 7s 189ms/step - loss: 0.0076\n",
            "Epoch 76/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0071\n",
            "Epoch 77/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0073\n",
            "Epoch 78/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0071\n",
            "Epoch 79/120\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.0074\n",
            "Epoch 80/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0074\n",
            "Epoch 81/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0072\n",
            "Epoch 82/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0071\n",
            "Epoch 83/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0072\n",
            "Epoch 84/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0071\n",
            "Epoch 85/120\n",
            "37/37 [==============================] - 7s 182ms/step - loss: 0.0071\n",
            "Epoch 86/120\n",
            "37/37 [==============================] - 6s 171ms/step - loss: 0.0072\n",
            "Epoch 87/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0071\n",
            "Epoch 88/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0071\n",
            "Epoch 89/120\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 0.0072\n",
            "Epoch 90/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0070\n",
            "Epoch 91/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0071\n",
            "Epoch 92/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0072\n",
            "Epoch 93/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0072\n",
            "Epoch 94/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0074\n",
            "Epoch 95/120\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.0071\n",
            "Epoch 96/120\n",
            "37/37 [==============================] - 6s 170ms/step - loss: 0.0070\n",
            "Epoch 97/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0073\n",
            "Epoch 98/120\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 0.0070\n",
            "Epoch 99/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0068\n",
            "Epoch 100/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0070\n",
            "Epoch 101/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0075\n",
            "Epoch 102/120\n",
            "37/37 [==============================] - 4s 122ms/step - loss: 0.0073\n",
            "Epoch 103/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0070\n",
            "Epoch 104/120\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.0071\n",
            "Epoch 105/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0069\n",
            "Epoch 106/120\n",
            "37/37 [==============================] - 7s 196ms/step - loss: 0.0069\n",
            "Epoch 107/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0075\n",
            "Epoch 108/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0070\n",
            "Epoch 109/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0069\n",
            "Epoch 110/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0069\n",
            "Epoch 111/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0071\n",
            "Epoch 112/120\n",
            "37/37 [==============================] - 4s 122ms/step - loss: 0.0070\n",
            "Epoch 113/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0071\n",
            "Epoch 114/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0069\n",
            "Epoch 115/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0068\n",
            "Epoch 116/120\n",
            "37/37 [==============================] - 6s 166ms/step - loss: 0.0068\n",
            "Epoch 117/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0068\n",
            "Epoch 118/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0068\n",
            "Epoch 119/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0071\n",
            "Epoch 120/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0069\n",
            "50/50 [==============================] - 3s 19ms/step\n",
            "Epoch 1/120\n",
            "37/37 [==============================] - 22s 122ms/step - loss: 0.0352\n",
            "Epoch 2/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0126\n",
            "Epoch 3/120\n",
            "37/37 [==============================] - 7s 199ms/step - loss: 0.0110\n",
            "Epoch 4/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0109\n",
            "Epoch 5/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0102\n",
            "Epoch 6/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0099\n",
            "Epoch 7/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0098\n",
            "Epoch 8/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0089\n",
            "Epoch 9/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0094\n",
            "Epoch 10/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0085\n",
            "Epoch 11/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0088\n",
            "Epoch 12/120\n",
            "37/37 [==============================] - 6s 149ms/step - loss: 0.0087\n",
            "Epoch 13/120\n",
            "37/37 [==============================] - 6s 166ms/step - loss: 0.0086\n",
            "Epoch 14/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0085\n",
            "Epoch 15/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0083\n",
            "Epoch 16/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0082\n",
            "Epoch 17/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0084\n",
            "Epoch 18/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0081\n",
            "Epoch 19/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0084\n",
            "Epoch 20/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0084\n",
            "Epoch 21/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0080\n",
            "Epoch 22/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0081\n",
            "Epoch 23/120\n",
            "37/37 [==============================] - 7s 197ms/step - loss: 0.0082\n",
            "Epoch 24/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0084\n",
            "Epoch 25/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0081\n",
            "Epoch 26/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0080\n",
            "Epoch 27/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0080\n",
            "Epoch 28/120\n",
            "37/37 [==============================] - 5s 143ms/step - loss: 0.0078\n",
            "Epoch 29/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0082\n",
            "Epoch 30/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0081\n",
            "Epoch 31/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0079\n",
            "Epoch 32/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0078\n",
            "Epoch 33/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0080\n",
            "Epoch 34/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0079\n",
            "Epoch 35/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0082\n",
            "Epoch 36/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0079\n",
            "Epoch 37/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0077\n",
            "Epoch 38/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0078\n",
            "Epoch 39/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0076\n",
            "Epoch 40/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0075\n",
            "Epoch 41/120\n",
            "37/37 [==============================] - 5s 149ms/step - loss: 0.0076\n",
            "Epoch 42/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0077\n",
            "Epoch 43/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0078\n",
            "Epoch 44/120\n",
            "37/37 [==============================] - 6s 171ms/step - loss: 0.0076\n",
            "Epoch 45/120\n",
            "37/37 [==============================] - 6s 160ms/step - loss: 0.0077\n",
            "Epoch 46/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0076\n",
            "Epoch 47/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0079\n",
            "Epoch 48/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0076\n",
            "Epoch 49/120\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 0.0076\n",
            "Epoch 50/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0074\n",
            "Epoch 51/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0077\n",
            "Epoch 52/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0081\n",
            "Epoch 53/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0077\n",
            "Epoch 54/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0078\n",
            "Epoch 55/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0074\n",
            "Epoch 56/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0074\n",
            "Epoch 57/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0078\n",
            "Epoch 58/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0076\n",
            "Epoch 59/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0074\n",
            "Epoch 60/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0074\n",
            "Epoch 61/120\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.0077\n",
            "Epoch 62/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0072\n",
            "Epoch 63/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0073\n",
            "Epoch 64/120\n",
            "37/37 [==============================] - 7s 198ms/step - loss: 0.0073\n",
            "Epoch 65/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0074\n",
            "Epoch 66/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0074\n",
            "Epoch 67/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0074\n",
            "Epoch 68/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0073\n",
            "Epoch 69/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0073\n",
            "Epoch 70/120\n",
            "37/37 [==============================] - 5s 121ms/step - loss: 0.0075\n",
            "Epoch 71/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0077\n",
            "Epoch 72/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0074\n",
            "Epoch 73/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0073\n",
            "Epoch 74/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0076\n",
            "Epoch 75/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0073\n",
            "Epoch 76/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0076\n",
            "Epoch 77/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0072\n",
            "Epoch 78/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0073\n",
            "Epoch 79/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0829\n",
            "Epoch 80/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0086\n",
            "Epoch 81/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0080\n",
            "Epoch 82/120\n",
            "37/37 [==============================] - 5s 143ms/step - loss: 0.0082\n",
            "Epoch 83/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0080\n",
            "Epoch 84/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0082\n",
            "Epoch 85/120\n",
            "37/37 [==============================] - 7s 196ms/step - loss: 0.0076\n",
            "Epoch 86/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0077\n",
            "Epoch 87/120\n",
            "37/37 [==============================] - 7s 178ms/step - loss: 0.0077\n",
            "Epoch 88/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0078\n",
            "Epoch 89/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0075\n",
            "Epoch 90/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0077\n",
            "Epoch 91/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0074\n",
            "Epoch 92/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0073\n",
            "Epoch 93/120\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 0.0076\n",
            "Epoch 94/120\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.0072\n",
            "Epoch 95/120\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.0075\n",
            "Epoch 96/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0071\n",
            "Epoch 97/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0073\n",
            "Epoch 98/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0074\n",
            "Epoch 99/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0074\n",
            "Epoch 100/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0072\n",
            "Epoch 101/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0072\n",
            "Epoch 102/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0072\n",
            "Epoch 103/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0074\n",
            "Epoch 104/120\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.0073\n",
            "Epoch 105/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0073\n",
            "Epoch 106/120\n",
            "37/37 [==============================] - 7s 189ms/step - loss: 0.0074\n",
            "Epoch 107/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0072\n",
            "Epoch 108/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0069\n",
            "Epoch 109/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0070\n",
            "Epoch 110/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0071\n",
            "Epoch 111/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0072\n",
            "Epoch 112/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0070\n",
            "Epoch 113/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0069\n",
            "Epoch 114/120\n",
            "37/37 [==============================] - 6s 148ms/step - loss: 0.0072\n",
            "Epoch 115/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0070\n",
            "Epoch 116/120\n",
            "37/37 [==============================] - 7s 184ms/step - loss: 0.0069\n",
            "Epoch 117/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0070\n",
            "Epoch 118/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0069\n",
            "Epoch 119/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0073\n",
            "Epoch 120/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0069\n",
            "50/50 [==============================] - 4s 37ms/step\n",
            "Epoch 1/120\n",
            "37/37 [==============================] - 21s 156ms/step - loss: 0.0359\n",
            "Epoch 2/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0139\n",
            "Epoch 3/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0116\n",
            "Epoch 4/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0110\n",
            "Epoch 5/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0106\n",
            "Epoch 6/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0102\n",
            "Epoch 7/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0094\n",
            "Epoch 8/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0091\n",
            "Epoch 9/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0091\n",
            "Epoch 10/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0089\n",
            "Epoch 11/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0096\n",
            "Epoch 12/120\n",
            "37/37 [==============================] - 7s 177ms/step - loss: 0.0091\n",
            "Epoch 13/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0092\n",
            "Epoch 14/120\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 0.0090\n",
            "Epoch 15/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0086\n",
            "Epoch 16/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0088\n",
            "Epoch 17/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0087\n",
            "Epoch 18/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0087\n",
            "Epoch 19/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0086\n",
            "Epoch 20/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0084\n",
            "Epoch 21/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0081\n",
            "Epoch 22/120\n",
            "37/37 [==============================] - 7s 197ms/step - loss: 0.0082\n",
            "Epoch 23/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0080\n",
            "Epoch 24/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0083\n",
            "Epoch 25/120\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 0.0083\n",
            "Epoch 26/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0081\n",
            "Epoch 27/120\n",
            "37/37 [==============================] - 6s 160ms/step - loss: 0.0087\n",
            "Epoch 28/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0079\n",
            "Epoch 29/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0080\n",
            "Epoch 30/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0084\n",
            "Epoch 31/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0082\n",
            "Epoch 32/120\n",
            "37/37 [==============================] - 7s 190ms/step - loss: 0.0079\n",
            "Epoch 33/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0081\n",
            "Epoch 34/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0078\n",
            "Epoch 35/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0082\n",
            "Epoch 36/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0077\n",
            "Epoch 37/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0078\n",
            "Epoch 38/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0079\n",
            "Epoch 39/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0078\n",
            "Epoch 40/120\n",
            "37/37 [==============================] - 6s 160ms/step - loss: 0.0080\n",
            "Epoch 41/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0077\n",
            "Epoch 42/120\n",
            "37/37 [==============================] - 7s 199ms/step - loss: 0.0077\n",
            "Epoch 43/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0081\n",
            "Epoch 44/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0077\n",
            "Epoch 45/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0077\n",
            "Epoch 46/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0079\n",
            "Epoch 47/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0081\n",
            "Epoch 48/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0078\n",
            "Epoch 49/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0075\n",
            "Epoch 50/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0077\n",
            "Epoch 51/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0078\n",
            "Epoch 52/120\n",
            "37/37 [==============================] - 6s 173ms/step - loss: 0.0074\n",
            "Epoch 53/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0080\n",
            "Epoch 54/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0081\n",
            "Epoch 55/120\n",
            "37/37 [==============================] - 6s 160ms/step - loss: 0.0078\n",
            "Epoch 56/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0075\n",
            "Epoch 57/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0075\n",
            "Epoch 58/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0077\n",
            "Epoch 59/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0084\n",
            "Epoch 60/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0075\n",
            "Epoch 61/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0075\n",
            "Epoch 62/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0074\n",
            "Epoch 63/120\n",
            "37/37 [==============================] - 7s 178ms/step - loss: 0.0074\n",
            "Epoch 64/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0076\n",
            "Epoch 65/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0073\n",
            "Epoch 66/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0074\n",
            "Epoch 67/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0075\n",
            "Epoch 68/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0078\n",
            "Epoch 69/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0080\n",
            "Epoch 70/120\n",
            "37/37 [==============================] - 5s 147ms/step - loss: 0.0076\n",
            "Epoch 71/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0072\n",
            "Epoch 72/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0072\n",
            "Epoch 73/120\n",
            "37/37 [==============================] - 7s 197ms/step - loss: 0.0075\n",
            "Epoch 74/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0078\n",
            "Epoch 75/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0075\n",
            "Epoch 76/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0074\n",
            "Epoch 77/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0073\n",
            "Epoch 78/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0074\n",
            "Epoch 79/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0073\n",
            "Epoch 80/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0077\n",
            "Epoch 81/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0071\n",
            "Epoch 82/120\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.0071\n",
            "Epoch 83/120\n",
            "37/37 [==============================] - 7s 184ms/step - loss: 0.0071\n",
            "Epoch 84/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0074\n",
            "Epoch 85/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0076\n",
            "Epoch 86/120\n",
            "37/37 [==============================] - 6s 160ms/step - loss: 0.0071\n",
            "Epoch 87/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0072\n",
            "Epoch 88/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0071\n",
            "Epoch 89/120\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.0072\n",
            "Epoch 90/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0073\n",
            "Epoch 91/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0069\n",
            "Epoch 92/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0071\n",
            "Epoch 93/120\n",
            "37/37 [==============================] - 6s 168ms/step - loss: 0.0074\n",
            "Epoch 94/120\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 0.0074\n",
            "Epoch 95/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0074\n",
            "Epoch 96/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0070\n",
            "Epoch 97/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0100\n",
            "Epoch 98/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0083\n",
            "Epoch 99/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0081\n",
            "Epoch 100/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0080\n",
            "Epoch 101/120\n",
            "37/37 [==============================] - 6s 160ms/step - loss: 0.0078\n",
            "Epoch 102/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0076\n",
            "Epoch 103/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0078\n",
            "Epoch 104/120\n",
            "37/37 [==============================] - 7s 200ms/step - loss: 0.0076\n",
            "Epoch 105/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0073\n",
            "Epoch 106/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0074\n",
            "Epoch 107/120\n",
            "37/37 [==============================] - 6s 147ms/step - loss: 0.0076\n",
            "Epoch 108/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0074\n",
            "Epoch 109/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0074\n",
            "Epoch 110/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0074\n",
            "Epoch 111/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0072\n",
            "Epoch 112/120\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 0.0074\n",
            "Epoch 113/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0073\n",
            "Epoch 114/120\n",
            "37/37 [==============================] - 7s 182ms/step - loss: 0.0072\n",
            "Epoch 115/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0071\n",
            "Epoch 116/120\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.0077\n",
            "Epoch 117/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0071\n",
            "Epoch 118/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0073\n",
            "Epoch 119/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0074\n",
            "Epoch 120/120\n",
            "37/37 [==============================] - 7s 181ms/step - loss: 0.0073\n",
            "50/50 [==============================] - 3s 30ms/step\n",
            "Epoch 1/120\n",
            "37/37 [==============================] - 22s 163ms/step - loss: 0.0402\n",
            "Epoch 2/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0127\n",
            "Epoch 3/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0111\n",
            "Epoch 4/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0110\n",
            "Epoch 5/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0097\n",
            "Epoch 6/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0095\n",
            "Epoch 7/120\n",
            "37/37 [==============================] - 6s 160ms/step - loss: 0.0099\n",
            "Epoch 8/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0096\n",
            "Epoch 9/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0095\n",
            "Epoch 10/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0097\n",
            "Epoch 11/120\n",
            "37/37 [==============================] - 7s 184ms/step - loss: 0.0091\n",
            "Epoch 12/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0086\n",
            "Epoch 13/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0085\n",
            "Epoch 14/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0086\n",
            "Epoch 15/120\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.0084\n",
            "Epoch 16/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0082\n",
            "Epoch 17/120\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.0087\n",
            "Epoch 18/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0084\n",
            "Epoch 19/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0083\n",
            "Epoch 20/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0083\n",
            "Epoch 21/120\n",
            "37/37 [==============================] - 5s 146ms/step - loss: 0.0083\n",
            "Epoch 22/120\n",
            "37/37 [==============================] - 7s 179ms/step - loss: 0.0081\n",
            "Epoch 23/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0081\n",
            "Epoch 24/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0080\n",
            "Epoch 25/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0089\n",
            "Epoch 26/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0084\n",
            "Epoch 27/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0079\n",
            "Epoch 28/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0080\n",
            "Epoch 29/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0078\n",
            "Epoch 30/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0080\n",
            "Epoch 31/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0076\n",
            "Epoch 32/120\n",
            "37/37 [==============================] - 6s 169ms/step - loss: 0.0079\n",
            "Epoch 33/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0079\n",
            "Epoch 34/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0078\n",
            "Epoch 35/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0081\n",
            "Epoch 36/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0077\n",
            "Epoch 37/120\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 0.0077\n",
            "Epoch 38/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0079\n",
            "Epoch 39/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0077\n",
            "Epoch 40/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0078\n",
            "Epoch 41/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0077\n",
            "Epoch 42/120\n",
            "37/37 [==============================] - 7s 190ms/step - loss: 0.0080\n",
            "Epoch 43/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0080\n",
            "Epoch 44/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0076\n",
            "Epoch 45/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0076\n",
            "Epoch 46/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0074\n",
            "Epoch 47/120\n",
            "37/37 [==============================] - 6s 148ms/step - loss: 0.0075\n",
            "Epoch 48/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0076\n",
            "Epoch 49/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0076\n",
            "Epoch 50/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0076\n",
            "Epoch 51/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0078\n",
            "Epoch 52/120\n",
            "37/37 [==============================] - 7s 183ms/step - loss: 0.0074\n",
            "Epoch 53/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0075\n",
            "Epoch 54/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0074\n",
            "Epoch 55/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0076\n",
            "Epoch 56/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0078\n",
            "Epoch 57/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0073\n",
            "Epoch 58/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0080\n",
            "Epoch 59/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0079\n",
            "Epoch 60/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0074\n",
            "Epoch 61/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0073\n",
            "Epoch 62/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0074\n",
            "Epoch 63/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0074\n",
            "Epoch 64/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0073\n",
            "Epoch 65/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0073\n",
            "Epoch 66/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0074\n",
            "Epoch 67/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0074\n",
            "Epoch 68/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0072\n",
            "Epoch 69/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0071\n",
            "Epoch 70/120\n",
            "37/37 [==============================] - 7s 181ms/step - loss: 0.0074\n",
            "Epoch 71/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0073\n",
            "Epoch 72/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0079\n",
            "Epoch 73/120\n",
            "37/37 [==============================] - 6s 173ms/step - loss: 0.0072\n",
            "Epoch 74/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0072\n",
            "Epoch 75/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0074\n",
            "Epoch 76/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0074\n",
            "Epoch 77/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0074\n",
            "Epoch 78/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0074\n",
            "Epoch 79/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0074\n",
            "Epoch 80/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0073\n",
            "Epoch 81/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0073\n",
            "Epoch 82/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0072\n",
            "Epoch 83/120\n",
            "37/37 [==============================] - 7s 199ms/step - loss: 0.0070\n",
            "Epoch 84/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0071\n",
            "Epoch 85/120\n",
            "37/37 [==============================] - 5s 147ms/step - loss: 0.0073\n",
            "Epoch 86/120\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.0070\n",
            "Epoch 87/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0073\n",
            "Epoch 88/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0072\n",
            "Epoch 89/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0073\n",
            "Epoch 90/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0072\n",
            "Epoch 91/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0071\n",
            "Epoch 92/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0070\n",
            "Epoch 93/120\n",
            "37/37 [==============================] - 7s 200ms/step - loss: 0.0070\n",
            "Epoch 94/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0072\n",
            "Epoch 95/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0072\n",
            "Epoch 96/120\n",
            "37/37 [==============================] - 6s 149ms/step - loss: 0.0071\n",
            "Epoch 97/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0070\n",
            "Epoch 98/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0070\n",
            "Epoch 99/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0071\n",
            "Epoch 100/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0069\n",
            "Epoch 101/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0071\n",
            "Epoch 102/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0069\n",
            "Epoch 103/120\n",
            "37/37 [==============================] - 7s 191ms/step - loss: 0.0070\n",
            "Epoch 104/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0072\n",
            "Epoch 105/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0069\n",
            "Epoch 106/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0068\n",
            "Epoch 107/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0070\n",
            "Epoch 108/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0075\n",
            "Epoch 109/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0086\n",
            "Epoch 110/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0077\n",
            "Epoch 111/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0077\n",
            "Epoch 112/120\n",
            "37/37 [==============================] - 7s 187ms/step - loss: 0.0074\n",
            "Epoch 113/120\n",
            "37/37 [==============================] - 6s 172ms/step - loss: 0.0072\n",
            "Epoch 114/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0076\n",
            "Epoch 115/120\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 0.0072\n",
            "Epoch 116/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0072\n",
            "Epoch 117/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0070\n",
            "Epoch 118/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0070\n",
            "Epoch 119/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0072\n",
            "Epoch 120/120\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 0.0070\n",
            "50/50 [==============================] - 3s 20ms/step\n",
            "Epoch 1/120\n",
            "37/37 [==============================] - 22s 127ms/step - loss: 0.0372\n",
            "Epoch 2/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0129\n",
            "Epoch 3/120\n",
            "37/37 [==============================] - 7s 199ms/step - loss: 0.0111\n",
            "Epoch 4/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0108\n",
            "Epoch 5/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0098\n",
            "Epoch 6/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0095\n",
            "Epoch 7/120\n",
            "37/37 [==============================] - 5s 146ms/step - loss: 0.0096\n",
            "Epoch 8/120\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.0089\n",
            "Epoch 9/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0089\n",
            "Epoch 10/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0090\n",
            "Epoch 11/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0094\n",
            "Epoch 12/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0087\n",
            "Epoch 13/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0087\n",
            "Epoch 14/120\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.0087\n",
            "Epoch 15/120\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 0.0082\n",
            "Epoch 16/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0087\n",
            "Epoch 17/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0086\n",
            "Epoch 18/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0084\n",
            "Epoch 19/120\n",
            "37/37 [==============================] - 5s 143ms/step - loss: 0.0087\n",
            "Epoch 20/120\n",
            "37/37 [==============================] - 6s 149ms/step - loss: 0.0085\n",
            "Epoch 21/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0084\n",
            "Epoch 22/120\n",
            "37/37 [==============================] - 6s 168ms/step - loss: 0.0080\n",
            "Epoch 23/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0081\n",
            "Epoch 24/120\n",
            "37/37 [==============================] - 7s 200ms/step - loss: 0.0081\n",
            "Epoch 25/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0080\n",
            "Epoch 26/120\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 0.0082\n",
            "Epoch 27/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0082\n",
            "Epoch 28/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0081\n",
            "Epoch 29/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0080\n",
            "Epoch 30/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0081\n",
            "Epoch 31/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0081\n",
            "Epoch 32/120\n",
            "37/37 [==============================] - 5s 146ms/step - loss: 0.0081\n",
            "Epoch 33/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0078\n",
            "Epoch 34/120\n",
            "37/37 [==============================] - 7s 200ms/step - loss: 0.0076\n",
            "Epoch 35/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0079\n",
            "Epoch 36/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0078\n",
            "Epoch 37/120\n",
            "37/37 [==============================] - 6s 166ms/step - loss: 0.0076\n",
            "Epoch 38/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0077\n",
            "Epoch 39/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0076\n",
            "Epoch 40/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0077\n",
            "Epoch 41/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0076\n",
            "Epoch 42/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0076\n",
            "Epoch 43/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0076\n",
            "Epoch 44/120\n",
            "37/37 [==============================] - 7s 178ms/step - loss: 0.0079\n",
            "Epoch 45/120\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 0.0076\n",
            "Epoch 46/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0076\n",
            "Epoch 47/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0077\n",
            "Epoch 48/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0076\n",
            "Epoch 49/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0076\n",
            "Epoch 50/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0075\n",
            "Epoch 51/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0077\n",
            "Epoch 52/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0078\n",
            "Epoch 53/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0073\n",
            "Epoch 54/120\n",
            "37/37 [==============================] - 7s 182ms/step - loss: 0.0076\n",
            "Epoch 55/120\n",
            "37/37 [==============================] - 6s 148ms/step - loss: 0.0074\n",
            "Epoch 56/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0075\n",
            "Epoch 57/120\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 0.0074\n",
            "Epoch 58/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0073\n",
            "Epoch 59/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0075\n",
            "Epoch 60/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0075\n",
            "Epoch 61/120\n",
            "37/37 [==============================] - 5s 148ms/step - loss: 0.0074\n",
            "Epoch 62/120\n",
            "37/37 [==============================] - 5s 146ms/step - loss: 0.0076\n",
            "Epoch 63/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0077\n",
            "Epoch 64/120\n",
            "37/37 [==============================] - 7s 189ms/step - loss: 0.0073\n",
            "Epoch 65/120\n",
            "37/37 [==============================] - 7s 176ms/step - loss: 0.0071\n",
            "Epoch 66/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0077\n",
            "Epoch 67/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0072\n",
            "Epoch 68/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0076\n",
            "Epoch 69/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0079\n",
            "Epoch 70/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0077\n",
            "Epoch 71/120\n",
            "37/37 [==============================] - 6s 166ms/step - loss: 0.0073\n",
            "Epoch 72/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0074\n",
            "Epoch 73/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0074\n",
            "Epoch 74/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0073\n",
            "Epoch 75/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0076\n",
            "Epoch 76/120\n",
            "37/37 [==============================] - 5s 133ms/step - loss: 0.0073\n",
            "Epoch 77/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0073\n",
            "Epoch 78/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0072\n",
            "Epoch 79/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0073\n",
            "Epoch 80/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0072\n",
            "Epoch 81/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0070\n",
            "Epoch 82/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0073\n",
            "Epoch 83/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0073\n",
            "Epoch 84/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0073\n",
            "Epoch 85/120\n",
            "37/37 [==============================] - 7s 201ms/step - loss: 0.0074\n",
            "Epoch 86/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0071\n",
            "Epoch 87/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0072\n",
            "Epoch 88/120\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 0.0073\n",
            "Epoch 89/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0073\n",
            "Epoch 90/120\n",
            "37/37 [==============================] - 6s 166ms/step - loss: 0.0074\n",
            "Epoch 91/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0072\n",
            "Epoch 92/120\n",
            "37/37 [==============================] - 5s 146ms/step - loss: 0.0073\n",
            "Epoch 93/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0074\n",
            "Epoch 94/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0070\n",
            "Epoch 95/120\n",
            "37/37 [==============================] - 7s 203ms/step - loss: 0.0072\n",
            "Epoch 96/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0072\n",
            "Epoch 97/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0071\n",
            "Epoch 98/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0071\n",
            "Epoch 99/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0068\n",
            "Epoch 100/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0071\n",
            "Epoch 101/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0074\n",
            "Epoch 102/120\n",
            "37/37 [==============================] - 5s 146ms/step - loss: 0.0071\n",
            "Epoch 103/120\n",
            "37/37 [==============================] - 6s 149ms/step - loss: 0.0071\n",
            "Epoch 104/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0070\n",
            "Epoch 105/120\n",
            "37/37 [==============================] - 7s 204ms/step - loss: 0.0071\n",
            "Epoch 106/120\n",
            "37/37 [==============================] - 6s 169ms/step - loss: 0.0069\n",
            "Epoch 107/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0071\n",
            "Epoch 108/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0071\n",
            "Epoch 109/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0069\n",
            "Epoch 110/120\n",
            "37/37 [==============================] - 6s 166ms/step - loss: 0.0069\n",
            "Epoch 111/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0071\n",
            "Epoch 112/120\n",
            "37/37 [==============================] - 6s 166ms/step - loss: 0.0069\n",
            "Epoch 113/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0069\n",
            "Epoch 114/120\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.0072\n",
            "Epoch 115/120\n",
            "37/37 [==============================] - 7s 188ms/step - loss: 0.0069\n",
            "Epoch 116/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0068\n",
            "Epoch 117/120\n",
            "37/37 [==============================] - 6s 166ms/step - loss: 0.0068\n",
            "Epoch 118/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0070\n",
            "Epoch 119/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0070\n",
            "Epoch 120/120\n",
            "37/37 [==============================] - 6s 166ms/step - loss: 0.0069\n",
            "50/50 [==============================] - 3s 21ms/step\n",
            "Epoch 1/120\n",
            "37/37 [==============================] - 21s 127ms/step - loss: 0.0361\n",
            "Epoch 2/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0135\n",
            "Epoch 3/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0115\n",
            "Epoch 4/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0110\n",
            "Epoch 5/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0106\n",
            "Epoch 6/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0098\n",
            "Epoch 7/120\n",
            "37/37 [==============================] - 7s 200ms/step - loss: 0.0104\n",
            "Epoch 8/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0100\n",
            "Epoch 9/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0094\n",
            "Epoch 10/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0093\n",
            "Epoch 11/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0090\n",
            "Epoch 12/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0090\n",
            "Epoch 13/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0092\n",
            "Epoch 14/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0084\n",
            "Epoch 15/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0088\n",
            "Epoch 16/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0085\n",
            "Epoch 17/120\n",
            "37/37 [==============================] - 7s 203ms/step - loss: 0.0088\n",
            "Epoch 18/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0087\n",
            "Epoch 19/120\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.0084\n",
            "Epoch 20/120\n",
            "37/37 [==============================] - 7s 190ms/step - loss: 0.0083\n",
            "Epoch 21/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0086\n",
            "Epoch 22/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0082\n",
            "Epoch 23/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0083\n",
            "Epoch 24/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0081\n",
            "Epoch 25/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0082\n",
            "Epoch 26/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0082\n",
            "Epoch 27/120\n",
            "37/37 [==============================] - 7s 200ms/step - loss: 0.0081\n",
            "Epoch 28/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0078\n",
            "Epoch 29/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0085\n",
            "Epoch 30/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0086\n",
            "Epoch 31/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0081\n",
            "Epoch 32/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0081\n",
            "Epoch 33/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0081\n",
            "Epoch 34/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0078\n",
            "Epoch 35/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0082\n",
            "Epoch 36/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0077\n",
            "Epoch 37/120\n",
            "37/37 [==============================] - 7s 191ms/step - loss: 0.0082\n",
            "Epoch 38/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0078\n",
            "Epoch 39/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0078\n",
            "Epoch 40/120\n",
            "37/37 [==============================] - 6s 163ms/step - loss: 0.0079\n",
            "Epoch 41/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0079\n",
            "Epoch 42/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0077\n",
            "Epoch 43/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0077\n",
            "Epoch 44/120\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.0077\n",
            "Epoch 45/120\n",
            "37/37 [==============================] - 6s 161ms/step - loss: 0.0076\n",
            "Epoch 46/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0082\n",
            "Epoch 47/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0075\n",
            "Epoch 48/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0081\n",
            "Epoch 49/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0075\n",
            "Epoch 50/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0077\n",
            "Epoch 51/120\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.0076\n",
            "Epoch 52/120\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 0.0079\n",
            "Epoch 53/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0076\n",
            "Epoch 54/120\n",
            "37/37 [==============================] - 5s 143ms/step - loss: 0.0075\n",
            "Epoch 55/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0076\n",
            "Epoch 56/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0077\n",
            "Epoch 57/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0075\n",
            "Epoch 58/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0078\n",
            "Epoch 59/120\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 0.0078\n",
            "Epoch 60/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0074\n",
            "Epoch 61/120\n",
            "37/37 [==============================] - 5s 149ms/step - loss: 0.0074\n",
            "Epoch 62/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0078\n",
            "Epoch 63/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0074\n",
            "Epoch 64/120\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.0074\n",
            "Epoch 65/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0075\n",
            "Epoch 66/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0073\n",
            "Epoch 67/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0075\n",
            "Epoch 68/120\n",
            "37/37 [==============================] - 6s 169ms/step - loss: 0.0075\n",
            "Epoch 69/120\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 0.0074\n",
            "Epoch 70/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0080\n",
            "Epoch 71/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0074\n",
            "Epoch 72/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0075\n",
            "Epoch 73/120\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 0.0073\n",
            "Epoch 74/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0074\n",
            "Epoch 75/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0075\n",
            "Epoch 76/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0076\n",
            "Epoch 77/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0073\n",
            "Epoch 78/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0072\n",
            "Epoch 79/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0076\n",
            "Epoch 80/120\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 0.0073\n",
            "Epoch 81/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0072\n",
            "Epoch 82/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0072\n",
            "Epoch 83/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0074\n",
            "Epoch 84/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0073\n",
            "Epoch 85/120\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 0.0073\n",
            "Epoch 86/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0077\n",
            "Epoch 87/120\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 0.0072\n",
            "Epoch 88/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0072\n",
            "Epoch 89/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0075\n",
            "Epoch 90/120\n",
            "37/37 [==============================] - 6s 147ms/step - loss: 0.0074\n",
            "Epoch 91/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0074\n",
            "Epoch 92/120\n",
            "37/37 [==============================] - 6s 147ms/step - loss: 0.0073\n",
            "Epoch 93/120\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.0074\n",
            "Epoch 94/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0070\n",
            "Epoch 95/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0072\n",
            "Epoch 96/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0070\n",
            "Epoch 97/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0070\n",
            "Epoch 98/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0074\n",
            "Epoch 99/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0070\n",
            "Epoch 100/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0071\n",
            "Epoch 101/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0070\n",
            "Epoch 102/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0071\n",
            "Epoch 103/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0073\n",
            "Epoch 104/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0071\n",
            "Epoch 105/120\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.0071\n",
            "Epoch 106/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0071\n",
            "Epoch 107/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0069\n",
            "Epoch 108/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0073\n",
            "Epoch 109/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0069\n",
            "Epoch 110/120\n",
            "37/37 [==============================] - 6s 164ms/step - loss: 0.0076\n",
            "Epoch 111/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0071\n",
            "Epoch 112/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0069\n",
            "Epoch 113/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0069\n",
            "Epoch 114/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0069\n",
            "Epoch 115/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0068\n",
            "Epoch 116/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0069\n",
            "Epoch 117/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0070\n",
            "Epoch 118/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0069\n",
            "Epoch 119/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0068\n",
            "Epoch 120/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0067\n",
            "50/50 [==============================] - 3s 22ms/step\n",
            "Epoch 1/120\n",
            "37/37 [==============================] - 21s 128ms/step - loss: 0.0350\n",
            "Epoch 2/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0138\n",
            "Epoch 3/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0111\n",
            "Epoch 4/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0105\n",
            "Epoch 5/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0098\n",
            "Epoch 6/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0094\n",
            "Epoch 7/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0096\n",
            "Epoch 8/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0091\n",
            "Epoch 9/120\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.0088\n",
            "Epoch 10/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0087\n",
            "Epoch 11/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0091\n",
            "Epoch 12/120\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 0.0088\n",
            "Epoch 13/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0083\n",
            "Epoch 14/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0086\n",
            "Epoch 15/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0089\n",
            "Epoch 16/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0088\n",
            "Epoch 17/120\n",
            "37/37 [==============================] - 5s 146ms/step - loss: 0.0081\n",
            "Epoch 18/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0081\n",
            "Epoch 19/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0082\n",
            "Epoch 20/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0079\n",
            "Epoch 21/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0081\n",
            "Epoch 22/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0083\n",
            "Epoch 23/120\n",
            "37/37 [==============================] - 5s 149ms/step - loss: 0.0082\n",
            "Epoch 24/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0083\n",
            "Epoch 25/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0081\n",
            "Epoch 26/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0079\n",
            "Epoch 27/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0080\n",
            "Epoch 28/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0077\n",
            "Epoch 29/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0077\n",
            "Epoch 30/120\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.0079\n",
            "Epoch 31/120\n",
            "37/37 [==============================] - 6s 165ms/step - loss: 0.0081\n",
            "Epoch 32/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0080\n",
            "Epoch 33/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0079\n",
            "Epoch 34/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0084\n",
            "Epoch 35/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0080\n",
            "Epoch 36/120\n",
            "37/37 [==============================] - 5s 127ms/step - loss: 0.0078\n",
            "Epoch 37/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0081\n",
            "Epoch 38/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0075\n",
            "Epoch 39/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0076\n",
            "Epoch 40/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0079\n",
            "Epoch 41/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0079\n",
            "Epoch 42/120\n",
            "37/37 [==============================] - 7s 182ms/step - loss: 0.0077\n",
            "Epoch 43/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0078\n",
            "Epoch 44/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0082\n",
            "Epoch 45/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0075\n",
            "Epoch 46/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0078\n",
            "Epoch 47/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0076\n",
            "Epoch 48/120\n",
            "37/37 [==============================] - 5s 128ms/step - loss: 0.0076\n",
            "Epoch 49/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0074\n",
            "Epoch 50/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0074\n",
            "Epoch 51/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0076\n",
            "Epoch 52/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0076\n",
            "Epoch 53/120\n",
            "37/37 [==============================] - 6s 149ms/step - loss: 0.0076\n",
            "Epoch 54/120\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 0.0078\n",
            "Epoch 55/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0073\n",
            "Epoch 56/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0076\n",
            "Epoch 57/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0076\n",
            "Epoch 58/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0074\n",
            "Epoch 59/120\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.0076\n",
            "Epoch 60/120\n",
            "37/37 [==============================] - 6s 162ms/step - loss: 0.0081\n",
            "Epoch 61/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0072\n",
            "Epoch 62/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0074\n",
            "Epoch 63/120\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.0078\n",
            "Epoch 64/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0074\n",
            "Epoch 65/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0073\n",
            "Epoch 66/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0074\n",
            "Epoch 67/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0074\n",
            "Epoch 68/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0074\n",
            "Epoch 69/120\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 0.0077\n",
            "Epoch 70/120\n",
            "37/37 [==============================] - 6s 150ms/step - loss: 0.0073\n",
            "Epoch 71/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0073\n",
            "Epoch 72/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0074\n",
            "Epoch 73/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0075\n",
            "Epoch 74/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0072\n",
            "Epoch 75/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0073\n",
            "Epoch 76/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0071\n",
            "Epoch 77/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0074\n",
            "Epoch 78/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0074\n",
            "Epoch 79/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0074\n",
            "Epoch 80/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0074\n",
            "Epoch 81/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0077\n",
            "Epoch 82/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0073\n",
            "Epoch 83/120\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 0.0073\n",
            "Epoch 84/120\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 0.0075\n",
            "Epoch 85/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0071\n",
            "Epoch 86/120\n",
            "37/37 [==============================] - 6s 152ms/step - loss: 0.0074\n",
            "Epoch 87/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0072\n",
            "Epoch 88/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0072\n",
            "Epoch 89/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0070\n",
            "Epoch 90/120\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.0072\n",
            "Epoch 91/120\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.0073\n",
            "Epoch 92/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0075\n",
            "Epoch 93/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0069\n",
            "Epoch 94/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0071\n",
            "Epoch 95/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0071\n",
            "Epoch 96/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0070\n",
            "Epoch 97/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0072\n",
            "Epoch 98/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0070\n",
            "Epoch 99/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0073\n",
            "Epoch 100/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0071\n",
            "Epoch 101/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0072\n",
            "Epoch 102/120\n",
            "37/37 [==============================] - 6s 156ms/step - loss: 0.0070\n",
            "Epoch 103/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0073\n",
            "Epoch 104/120\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.0074\n",
            "Epoch 105/120\n",
            "37/37 [==============================] - 5s 132ms/step - loss: 0.0071\n",
            "Epoch 106/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0072\n",
            "Epoch 107/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0072\n",
            "Epoch 108/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0070\n",
            "Epoch 109/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0070\n",
            "Epoch 110/120\n",
            "37/37 [==============================] - 5s 129ms/step - loss: 0.0072\n",
            "Epoch 111/120\n",
            "37/37 [==============================] - 6s 155ms/step - loss: 0.0071\n",
            "Epoch 112/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0069\n",
            "Epoch 113/120\n",
            "37/37 [==============================] - 6s 151ms/step - loss: 0.0073\n",
            "Epoch 114/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0068\n",
            "Epoch 115/120\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 0.0068\n",
            "Epoch 116/120\n",
            "37/37 [==============================] - 5s 146ms/step - loss: 0.0069\n",
            "Epoch 117/120\n",
            "37/37 [==============================] - 5s 131ms/step - loss: 0.0070\n",
            "Epoch 118/120\n",
            "37/37 [==============================] - 6s 154ms/step - loss: 0.0068\n",
            "Epoch 119/120\n",
            "37/37 [==============================] - 5s 130ms/step - loss: 0.0068\n",
            "Epoch 120/120\n",
            "37/37 [==============================] - 6s 153ms/step - loss: 0.0068\n",
            "50/50 [==============================] - 3s 22ms/step\n",
            "Epoch 1/120\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m       \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_grad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_grad_fn\u001b[0;34m(ys, xs, args, func_graph)\u001b[0m\n\u001b[1;32m    743\u001b[0m   \u001b[0;31m# TODO(srbs): Mark GradientsHelper as public?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m   grad_outs = gradients_util._GradientsHelper(\n\u001b[0m\u001b[1;32m    745\u001b[0m       \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0m\u001b[1;32m    696\u001b[0m                                          lambda: grad_fn(op, *out_grads))\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    327\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    695\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 696\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    697\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_AddGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1301\u001b[0m   (sx, rx, must_reduce_x), (sy, ry, must_reduce_y) = (\n\u001b[0;32m-> 1302\u001b[0;31m       SmartBroadcastGradientArgs(x, y, grad))\n\u001b[0m\u001b[1;32m   1303\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mskip_input_indices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskip_input_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36mSmartBroadcastGradientArgs\u001b[0;34m(x, y, grad)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0msx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0msy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0mrx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_gradient_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape_internal\u001b[0;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mout_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(input, out_type, name)\u001b[0m\n\u001b[1;32m   9364\u001b[0m   \u001b[0mout_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"out_type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9365\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   9366\u001b[0m         \"Shape\", input=input, out_type=out_type, name=name)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    796\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    798\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   1024\u001b[0m             self._forward_graph)):\n\u001b[0;32m-> 1025\u001b[0;31m       return self._move_op_to_forward_graph(\n\u001b[0m\u001b[1;32m   1026\u001b[0m           \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_move_op_to_forward_graph\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   1075\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_from_scope_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m       result = self._forward_graph._create_op_internal(\n\u001b[0m\u001b[1;32m   1077\u001b[0m           \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    695\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3753\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3754\u001b[0;31m       ret = Operation(\n\u001b[0m\u001b[1;32m   3755\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2128\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2129\u001b[0;31m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[1;32m   2130\u001b[0m                                 control_input_ops, op_def)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1952\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1953\u001b[0;31m     \u001b[0mserialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1954\u001b[0m     \u001b[0;31m# TODO(skyewm): this creates and deletes a new TF_Status for every attr.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-e17d81e7f30f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGlobalMinimaSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-48-034c438657e3>\u001b[0m in \u001b[0;36mGlobalMinimaSearch\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mparams_2\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_weight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mGlobalMinimaSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-034c438657e3>\u001b[0m in \u001b[0;36mGlobalMinimaSearch\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mparams_2\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_weight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mGlobalMinimaSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-034c438657e3>\u001b[0m in \u001b[0;36mGlobalMinimaSearch\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mparams_2\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_weight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mGlobalMinimaSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-034c438657e3>\u001b[0m in \u001b[0;36mGlobalMinimaSearch\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mparams_2\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_weight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mGlobalMinimaSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-034c438657e3>\u001b[0m in \u001b[0;36mGlobalMinimaSearch\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mparams_2\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_weight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mGlobalMinimaSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-034c438657e3>\u001b[0m in \u001b[0;36mGlobalMinimaSearch\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mparams_2\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_weight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mGlobalMinimaSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-034c438657e3>\u001b[0m in \u001b[0;36mGlobalMinimaSearch\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mparams_2\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfinal_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minitial_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_weight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mGlobalMinimaSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-034c438657e3>\u001b[0m in \u001b[0;36mGlobalMinimaSearch\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHalvAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.003\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    961\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 785\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    786\u001b[0m             *args, **kwds))\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2478\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2480\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2481\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2709\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_placeholder_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2711\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2712\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   2713\u001b[0m                                    graph_function)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2625\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2626\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 2627\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   2628\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1114\u001b[0m           \u001b[0;31m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             return autograph.converted_call(\n\u001b[0m\u001b[1;32m   1117\u001b[0m                 \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             run_step, jit_compile=True, reduce_retracing=True)\n\u001b[1;32m   1039\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m   1042\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1311\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1312\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2886\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2888\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3687\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3688\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3689\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3691\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;31m# Run backwards pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     \"\"\"\n\u001b[0;32m--> 537\u001b[0;31m     grads_and_vars = self._compute_gradients(\n\u001b[0m\u001b[1;32m    538\u001b[0m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[0;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/gradients\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m       \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     self._assert_valid_dtypes([\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_get_gradients\u001b[0;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[1;32m    469\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;34m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_WhileGrad\u001b[0;34m(op, *grads)\u001b[0m\n\u001b[1;32m    382\u001b[0m       body_graph.outputs, body_graph.inputs, grads) if grad is not None])\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m   body_grad_graph, args = _create_grad_func(\n\u001b[0m\u001b[1;32m    385\u001b[0m       \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_none_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m       \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_grad_fn_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_create_grad_func\u001b[0;34m(ys, xs, grads, cond_graph, body_graph, name, while_op, maximum_iterations, stateful_parallelism)\u001b[0m\n\u001b[1;32m    684\u001b[0m   \u001b[0;31m# Note: The returned function does not have `args` in the list of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m   \u001b[0;31m# `external_captures`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m   grad_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    687\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m       \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_grad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         if x is not None)\n\u001b[1;32m   1181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m     \u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0madd_control_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[1;32m    462\u001b[0m       \u001b[0;31m# Check for any resource inputs. If we find any, we update control_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m       \u001b[0;31m# and last_write_to_resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_get_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0mis_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresource_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mResourceType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_ONLY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0minput_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36m_get_resource_inputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m   \u001b[0;34m\"\"\"Returns an iterable of resources touched by this `op`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m   \u001b[0mreads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrites\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_read_write_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m   \u001b[0msaturated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msaturated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/auto_control_deps_utils.py\u001b[0m in \u001b[0;36mget_read_write_resource_inputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mread_only_input_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREAD_ONLY_RESOURCE_INPUTS_ATTR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;31m# Attr was not set. Add all resource inputs to `writes` and return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2645\u001b[0m     \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tensor\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"func\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2647\u001b[0;31m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2648\u001b[0m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36mhelper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_GeneratorContextManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, args, kwds)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Issue 19330: ensure context manager instances have good docstrings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__doc__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss)"
      ],
      "metadata": {
        "id": "MnuUdKWaqgaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcbf5a11-2d37-46ef-a142-adca543d380c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.1098834961990239, 0.09671213309711232, 0.09240416566310078, 0.09459281231758317, 0.09135227762366496, 0.09709937975233936, 0.10310442537984658]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(min(loss))"
      ],
      "metadata": {
        "id": "56ykd7kawkvX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4e919ec-cd77-4deb-9bfa-84f1ea27fca8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.09135227762366496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "5KwbVjdXKn01"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss)"
      ],
      "metadata": {
        "id": "O622nEj3Krt7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "7e73292f-c5f4-4b70-bbad-f4ef2739eeb7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2ef4da6490>]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}